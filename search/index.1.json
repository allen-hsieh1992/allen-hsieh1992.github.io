[{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"前面已經分享了：\nFirehose 介紹 Firehose 基礎建置 Firehose Dynamic Partitioning POC 現在要分享在專案中實際使用的範例。\n地端架構 Web Application：共有兩組 Micro Service，處理不同的請求，並將需要的資料寫入本地檔案。 上傳到 Dropbox：在 Web Application 伺服器上設定 CronJob，定期將檔案上傳至 Dropbox。 下載到 Hadoop 並分析。 AWS 架構 整組地端服務遷移至 AWS 後，新架構如下：\nWeb Application：遷移至 EKS，透過 SDK 呼叫 Firehose。 Firehose：即時收集 Event，並輸出至 S3。 Hadoop：改在 EMR 上執行，並從 S3 下載檔案。 監控機制 CloudWatch：設置 CloudWatch Alert，監測 Firehose 錯誤。 SNS：當發生錯誤時，透過 SNS 發送 Email 通知 Slack，Slack 會即時收到警報。 決策考量與經驗 一個還是兩個 Firehose？ 最初考慮建立單一 Firehose Streaming，並透過 Dynamic Partitioning 將資料分類至同一個 S3，但不同的 Folder。\n然而，考量到 Firehose 的計價方式是依據處理數據量，因此開啟一個 Firehose 和兩個 Firehose 的價格相差不大。此外，Dynamic Partitioning 需額外付費，並且需要維護 Lambda Function。因此，最終選擇了較單純的雙 Firehose 架構。\nFirehose Buffer Hints 設定 Firehose 可設定 Buffer Hints，以下為 S3 目標的設定範圍（其他目標請參考官方文件）：\nBuffer Size：1 – 128 MiB Buffer Interval：0 – 900 秒 Firehose 在滿足以下任一條件時，便會將 Buffer 內的資料輸出至 S3：\n達到設定的 Buffer Size（例如 128 MiB）。 達到設定的 Buffer Interval（例如 900 秒）。 舉例來說，若流量較大，則可能在 15 分鐘內達到 128 MiB，進而提前產生檔案。反之，若流量較小，則 Firehose 會每 15 分鐘產生一個檔案。\n在地端架構時，檔案是每天上傳一次。然而，遷移至 Firehose 後，因為 Buffer Hints 機制，需特別注意跨日檔案的處理。第一個跨日檔案可能包含前一天的部分資料，因此，需抓取當日與跨日的第一個檔案，才能確保完整的數據。\n時區考量 Firehose 預設使用 UTC 時間格式來寫入 S3 Prefix。\n若系統依據日期切割檔案，則時區設定非常重要。我們最終選擇使用 'Asia/Taipei'，確保檔案時間與業務需求對應。\n這些經驗分享希望能幫助到有類似需求的開發者！\n","date":"February 13, 2025","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/firehose-part4-production-use-case/","smallImg":"","tags":[{"title":"FIREHOSE","url":"/tags/firehose/"}],"timestamp":1739404800,"title":"Firehose 專案分享"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"在上一篇中，我們有介紹到如何建立一個最基本的 Firehose，這篇主要講進階功能，使用 Dynamic Partitioning。\nS3 根據 Folder 的分類，對 performance 是有影響的，細節可以參考這篇 文章。\nFirehose 預設函式 Firehose 已經內建一些函式，可以不用透過 Dynamic Partitioning 就能做一些 S3 基本的 Prefix 分類。\n這邊是 官方文件。\n例如，在建立 Firehose 的時候，S3 Prefix 設定以下路徑：\n1!{timestamp:yyyy}/!{timestamp:MM}/!{timestamp:dd}/testing- 產生出來的檔案會有年月日的 Folder，然後檔案的 prefix 會是 testing-，後面接 Firehose 預設的檔案名稱。\nFirehose 使用 JQ 如果 Payload 是 JSON 格式，可以使用 Firehose 內建的 Dynamic Partitioning，這邊使用 JQ 1.6 作為 Parsing Payload 的工具。\n若使用 JQ，需啟用 Dynamic Partitioning，並且打開 Inline Parsing for JSON。\n接著設定 JQ 的 Key Name，這個 Key 會對應到 Firehose Prefix 的 Key Name。\n在設定 S3 Prefix 的地方，namespace 必須填 partitionKeyFromQuery，接著填 Key Name。\n這邊附上我的 S3 Prefix：\n1!{partitionKeyFromQuery:month}/!{partitionKeyFromQuery:day}/!{partitionKeyFromQuery:s3_prefix}- 如果配上圖片上的設定，加上我用以下 Payload 打 Firehose：\n1aws firehose put-record \\ 2 --cli-binary-format raw-in-base64-out \\ 3 --delivery-stream-name JQ-Example \\ 4 --record \u0026#34;{\\\u0026#34;Data\\\u0026#34;: \\\u0026#34;{\\\\\\\u0026#34;month\\\\\\\u0026#34;:12, \\\\\\\u0026#34;day\\\\\\\u0026#34;:5, \\\\\\\u0026#34;s3Prefix\\\\\\\u0026#34;:\\\\\\\u0026#34;example\\\\\\\u0026#34;}\\\\n\\\u0026#34;}\u0026#34; 會看到 S3 的路徑是 12/5/，而檔案名稱是 example- 開頭的。\nFirehose with Lambda 如果要透過 Lambda 做 Dynamic Partitioning，需要打開 transformation 的功能。\n這邊提供範例程式碼：\n1import json 2import logging 3import base64 4 5def lambda_handler(event, context): 6 output = [] 7 logger = logging.getLogger() 8 logger.setLevel(logging.INFO) 9 10 logger.info(\u0026#34;Lambda Start\u0026#34;) 11 logger.info(f\u0026#34;event: {json.dumps(event)}\u0026#34;) 12 13 for record in event[\u0026#39;records\u0026#39;]: 14 logger.info(f\u0026#34;record[\u0026#39;data\u0026#39;]: {record[\u0026#39;data\u0026#39;]}\u0026#34;) 15 decodeResult = base64.b64decode(record[\u0026#39;data\u0026#39;]).decode(\u0026#39;utf-8\u0026#39;) 16 17 logger.info(f\u0026#34;base64 decode : {decodeResult}\u0026#34;) 18 19 payload = json.loads(decodeResult) 20 payload[\u0026#39;firehose\u0026#39;] = \u0026#39;true\u0026#39; 21 partition_key = payload.get(\u0026#39;key\u0026#39;, \u0026#39;default\u0026#39;) 22 newData = json.dumps(payload) 23 logger.info(f\u0026#34;newData : {newData}\u0026#34;) 24 25 output_record = { 26 \u0026#39;recordId\u0026#39;: record[\u0026#39;recordId\u0026#39;], 27 \u0026#39;result\u0026#39;: \u0026#39;Ok\u0026#39;, 28 \u0026#39;data\u0026#39;: base64.b64encode(newData.encode()).decode(), 29 \u0026#39;metadata\u0026#39;: { 30 \u0026#39;partitionKeys\u0026#39;: { 31 \u0026#39;partitionKey\u0026#39;: partition_key, 32 \u0026#39;file_prefix\u0026#39;: payload.get(\u0026#39;file_prefix\u0026#39;, \u0026#39;2024\u0026#39;), 33 \u0026#39;year\u0026#39;: payload.get(\u0026#39;year\u0026#39;, \u0026#39;2024\u0026#39;), 34 \u0026#39;month\u0026#39;: payload.get(\u0026#39;month\u0026#39;, \u0026#39;09\u0026#39;), 35 \u0026#39;day\u0026#39;: payload.get(\u0026#39;day\u0026#39;, \u0026#39;01\u0026#39;), 36 \u0026#39;hour\u0026#39;: payload.get(\u0026#39;hour\u0026#39;, \u0026#39;01\u0026#39;) 37 } 38 } 39 } 40 output.append(output_record) 41 42 return {\u0026#39;records\u0026#39;: output} 解釋： Line 15：送到 Firehose 的 Data 必須經過 Base64 Encode，所以取出時需要 Decode。 Line 20：在 Transformation 過程中，對 Payload 新增 Key。 Line 26：須將原本的 Record 返回給 Firehose。 Line 27：result 參數可設為 \u0026ldquo;Ok\u0026rdquo;（保留）或 \u0026ldquo;Dropped\u0026rdquo;（丟棄）。 Line 28：data 參數是最後存入檔案的資料，需再次進行 Base64 Encode。 Line 29-36：metadata 底下的 partitionKeys 是用來設定 S3 Prefix。 建立好 Lambda 之後，就可以在 transformation 設定裡，填入 Lambda 的 ARN。\n啟用 Dynamic Partitioning，這次 Inline Parsing for JSON 不需要勾選。\n在 S3 Prefix 的 namespace 使用 partitionKeyFromLambda，這樣就能取出 Lambda 返回的結果。\n注意： partitionKeyFromQuery 和 partitionKeyFromLambda 是不同的！\n這邊附上我的 S3 Prefix 設定：\n1!{partitionKeyFromLambda:year}/!{partitionKeyFromLambda:month}/!{partitionKeyFromLambda:day}/!{partitionKeyFromLambda:file_prefix}-!{partitionKeyFromLambda:partitionKey}-!{partitionKeyFromLambda:year}-!{partitionKeyFromLambda:month}-!{partitionKeyFromLambda:day}-!{partitionKeyFromLambda:hour} 測試 Firehose with Lambda 使用 AWS CLI 來放入測試資料：\n1aws firehose put-record \\ 2 --cli-binary-format raw-in-base64-out \\ 3 --delivery-stream-name Lambda-Example \\ 4 --record \u0026#34;{\\\u0026#34;Data\\\u0026#34;: \\\u0026#34;{\\\\\\\u0026#34;month\\\\\\\u0026#34;:12, \\\\\\\u0026#34;day\\\\\\\u0026#34;:5, \\\\\\\u0026#34;key\\\\\\\u0026#34;:\\\\\\\u0026#34;example1\\\\\\\u0026#34;}\\\\n\\\u0026#34;}\u0026#34; 檢查 S3 prefix 是否符合預期：\n檔案內容 1{\u0026#34;month\u0026#34;: 12, \u0026#34;day\u0026#34;: 5, \u0026#34;key\u0026#34;: \u0026#34;example1\u0026#34;, \u0026#34;firehose\u0026#34;: \u0026#34;true\u0026#34;} 這樣就能成功使用 Lambda + Firehose 進行 Dynamic Partitioning！ 🚀\n","date":"December 12, 2024","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/firehose-part3-dynamic-partitioning/","smallImg":"","tags":[{"title":"FIREHOSE","url":"/tags/firehose/"}],"timestamp":1733961600,"title":"Firehose Dynamic Partitioning"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"架構 今日架構，會建立一個 Firehose 和 S3，並透過 AWS CLI 傳送資料到 Firehose 裡面，最後 Output 到 S3 中。\nS3 建置 進入到 S3 畫面，並點下 \u0026ldquo;Create Bucket\u0026rdquo; 按鈕\n填寫 Bucket name（注意 S3 Bucket 是 Global Unique，所以跟別人重複了是不能建立的），並滑到頁面最下面按 \u0026ldquo;Create Bucket\u0026rdquo; 按鈕\n建立完成，會在頁面最下面看到 S3 Bucket\nFirehose 建置 進入到 Firehose 頁面，點擊 \u0026ldquo;Create Delivery Stream\u0026rdquo;\nSource 的部分選 \u0026ldquo;Direct Put\u0026rdquo;，然後 Destination 選 \u0026ldquo;S3\u0026rdquo;，接著會展開更多資訊要填寫\n滾動到頁面最下面，然後點選 \u0026ldquo;Create Delivery Stream\u0026rdquo;，就會開始建置\n選擇 Configuration，可以看到 Service access，AWS 已經預設建立好 Service Role\n在 IAM Role 裡面可以看到，已經有權限可以讓 Firehose output 資料到 S3\n透過 AWS CLI 上傳 1aws firehose put-record \\ 2 --delivery-stream-name Basic-Firehose \\ 3 --record \u0026#34;{\\\u0026#34;Data\\\u0026#34;:\\\u0026#34;SGVsbG8gd29ybGQh\\\u0026#34;}\u0026#34; Firehose 預設 Buffer Size 是300 秒，所以五分鐘後可以到 S3 裡面去看檔案。\n","date":"October 6, 2024","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/firehose-part2-stream-creation/","smallImg":"","tags":[{"title":"FIREHOSE","url":"/tags/firehose/"}],"timestamp":1728172800,"title":"Firehose 建置"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"什麼是 Firehose Amazon Kinesis Data Firehose（簡稱 Firehose）是 AWS 提供的一種實時數據流處理服務，主要用於收集、轉換和加載數據到各種儲存與分析平台，例如 Amazon S3、Redshift、Elasticsearch Service、Splunk 等。\nFirehose 能夠自動擴展、無需管理伺服器，並提供批次處理、數據轉換和加密功能，使其成為數據管道（Data Pipeline）中關鍵的組件之一。\nFirehose 的主要功能 數據流收集與傳輸 從各種來源（IoT 設備、應用程式日誌、監控數據）接收數據。 低延遲地傳輸到 Amazon S3、Amazon Redshift、Amazon OpenSearch、Splunk 等。 數據格式轉換與壓縮 Firehose 支援 JSON → Parquet / ORC 轉換，也支援 Lambda 的動態轉換。 支援 Gzip、Snappy、ZIP 壓縮數據，減少儲存成本。 數據加密與安全性 Firehose 內建 AWS KMS（Key Management Service）加密，確保數據安全。 可與 AWS Identity and Access Management（IAM）整合，控制存取權限。 無伺服器、自動擴展 Firehose 無需管理基礎架構，AWS 會根據流量自動擴展吞吐量。 與 AWS 服務整合 可以與 Amazon CloudWatch、AWS Lambda、Kinesis Data Streams 等無縫整合，進行即時監控與處理。 Firehose 定價模式 資料擷取：資料傳輸到 Firehose 時，會根據擷取的資料量收費。 每筆至少以 5KB 為一個單位，例如 13KB 會算 15KB，然後以每 GB 計價。 格式轉換 (Optional): 每筆至少以 5KB 為一個單位，以每 GB 計價。 Dynamic Partitioning JQ 或 Lambda 以計算時間計算。 壓縮 也是以每 GB 為單位。 可以使用 AWS 計算機 做基礎計算\n實際情境案例 範例 1： IoT 事件流：假設一個智慧城市的 IoT 設備收集來的數據，如何使用 Firehose 實時將數據傳輸到 Amazon S3 進行儲存和分析。 範例 2： 實時日志處理：使用 Firehose 傳輸應用程式日誌到 Amazon Elasticsearch Service，用於即時的搜尋和分析。 ","date":"July 13, 2024","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/firehose-part1-intro/","smallImg":"","tags":[{"title":"FIREHOSE","url":"/tags/firehose/"}],"timestamp":1720828800,"title":"Firehose 101"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"建立 DynamoDB SAM 有定義一個 AWS::Serverless::SimpleTable 的 Resource 給 DynamoDb。\n我在 template.yaml 的 Resources 下增加了以下的 code\n1 Table: 2 Type: AWS::Serverless::SimpleTable # More info about SimpleTable Resource: https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/sam-resource-simpletable.html 3 Properties: 4 PrimaryKey: 5 Name: id 6 Type: String 7 TableName: Users 接著在 SAM Deploy 時，會看到以下的 Change Set\n1CloudFormation stack changeset 2----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 3Operation LogicalResourceId ResourceType Replacement 4----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 5+ Add Table AWS::DynamoDB::Table N/A 6----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 7 8 9Changeset created successfully. arn:aws:cloudformation:ap-northeast-1:129824596365:changeSet/samcli-deploy1711462102/d5561ddb-0426-4de1-be4d-08b4a0ab02aa 10 11 12Previewing CloudFormation changeset before deployment 13====================================================== 14Deploy this changeset? [y/N]: y 15 162024-03-26 22:08:41 - Waiting for stack create/update to complete 17 18CloudFormation events from stack operations (refresh every 5.0 seconds) 19----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 20ResourceStatus ResourceType LogicalResourceId ResourceStatusReason 21----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 22UPDATE_IN_PROGRESS AWS::CloudFormation::Stack sam-app User Initiated 23CREATE_IN_PROGRESS AWS::DynamoDB::Table Table - 24CREATE_IN_PROGRESS AWS::DynamoDB::Table Table Resource creation Initiated 25CREATE_COMPLETE AWS::DynamoDB::Table Table - 26UPDATE_COMPLETE_CLEANUP_IN_PROGRESS AWS::CloudFormation::Stack sam-app - 27UPDATE_COMPLETE AWS::CloudFormation::Stack sam-app - 28----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 從 AWS Console 可以看到，我們建立的DynamoDB Table Users 建立 Items 點入 Table Users 以後，右上角的 Action 裡面，有一個 Create Item 接著艾倫會建立一個 item ，id 是 1，firstName 是 Allen ，lastName 是 Hsieh 點下 Create Item ，我們就可以在 Table 裡面看到有第一筆 Item\n建立 Get Users API 這邊都是基於 Part1 的 Hello World 去修改\npackage.json 第一件事情，先在 package.json 加入 aws-sdk lib (line11)\n1{ 2 \u0026#34;name\u0026#34;: \u0026#34;hello_world\u0026#34;, 3 \u0026#34;version\u0026#34;: \u0026#34;1.0.0\u0026#34;, 4 \u0026#34;description\u0026#34;: \u0026#34;hello world sample for NodeJS\u0026#34;, 5 \u0026#34;main\u0026#34;: \u0026#34;app.js\u0026#34;, 6 \u0026#34;repository\u0026#34;: \u0026#34;https://github.com/awslabs/aws-sam-cli/tree/develop/samcli/local/init/templates/cookiecutter-aws-sam-hello-nodejs\u0026#34;, 7 \u0026#34;author\u0026#34;: \u0026#34;SAM CLI\u0026#34;, 8 \u0026#34;license\u0026#34;: \u0026#34;MIT\u0026#34;, 9 \u0026#34;dependencies\u0026#34;: { 10 \u0026#34;axios\u0026#34;: \u0026#34;\u0026gt;=1.6.0\u0026#34;, 11 \u0026#34;aws-sdk\u0026#34;: \u0026#34;2.1419.0\u0026#34; 12 }, 13 \u0026#34;scripts\u0026#34;: { 14 \u0026#34;test\u0026#34;: \u0026#34;mocha tests/unit/\u0026#34; 15 }, 16 \u0026#34;devDependencies\u0026#34;: { 17 \u0026#34;chai\u0026#34;: \u0026#34;^4.3.6\u0026#34;, 18 \u0026#34;mocha\u0026#34;: \u0026#34;^10.2.0\u0026#34; 19 } 20} 修改 hello_world 資料夾名稱 接著修改 hello_world 改成 users\n1$ tree . 2. 3├── README.md 4├── events 5│ └── event.json 6├── samconfig.toml 7├── template.yaml 8└── users 9 ├── app.mjs 10 ├── package.json 11 └── tests 12 └── unit 13 └── test-handler.mjs 修改 Lambda Function Line1 : 將 DynamoDBClient 匯入 Line16: 根據 Http Method 來判斷執行什麼 Action ，由於現在只處理 Get Method\n1import { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; 2import { 3 DynamoDBDocumentClient, 4 ScanCommand 5} from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; 6 7const client = new DynamoDBClient({}); 8 9const dynamo = DynamoDBDocumentClient.from(client); 10 11const tableName = \u0026#34;Users\u0026#34;; 12 13export const lambdaHandler = async (event, context) =\u0026gt; { 14 console.log(\u0026#34;EVENT: \\n\u0026#34; + JSON.stringify(event, null, 2)); 15 console.log(\u0026#34;httpmethod\u0026#34; + event.httpMethod); 16 let body; 17 switch(event.httpMethod) { 18 case \u0026#34;GET\u0026#34;: 19 console.log(\u0026#34;Http Get\u0026#34;); 20 body = await dynamo.send( 21 new ScanCommand({ TableName: tableName }) 22 ); 23 body = body.Items; 24 break; 25 } 26 const response = { 27 statusCode: 200, 28 body: JSON.stringify(body) 29 }; 30 31 return response; 32}; template.yaml 新增 Get Uesr Function 在 Resource 下面。\n1 GetUsers: 2 Type: AWS::Serverless::Function 3 Properties: 4 CodeUri: users/ 5 Handler: app.lambdaHandler 6 Runtime: nodejs20.x 7 Architectures: 8 - x86_64 9 Events: 10 HelloWorld: 11 Type: Api 12 Properties: 13 Path: /users 14 Method: get 重新部署 這邊記得，要先 sam build 之後執行 sam deploy 才會生效，接著我們使用 Curl 去打 apigateway\n1$ curl https://kxkhl0spi1.execute-api.ap-northeast-1.amazonaws.com/Prod/users 2{\u0026#34;message\u0026#34;: \u0026#34;Internal server error\u0026#34;} 這邊會發現，得到的 message 是錯誤，接著去 CloudWatch 看 Log ，會發現 Lambda 沒有權限去 access DynamoDB.\n1{ 2 \u0026#34;timestamp\u0026#34;: \u0026#34;2024-02-10T14:23:01.191Z\u0026#34;, 3 \u0026#34;level\u0026#34;: \u0026#34;ERROR\u0026#34;, 4 \u0026#34;requestId\u0026#34;: \u0026#34;def17c42-6b0b-4c96-a081-948984ae0c8f\u0026#34;, 5 \u0026#34;message\u0026#34;: { 6 \u0026#34;errorType\u0026#34;: \u0026#34;DynamoDBServiceException\u0026#34;, 7 \u0026#34;errorMessage\u0026#34;: \u0026#34;User: arn:aws:sts::129824596365:assumed-role/sam-app-GetUsersRole-e2VmZDAl4NoY/sam-app-GetUsers-PGeiGDJRikRx is not authorized to perform: dynamodb:Scan on resource: arn:aws:dynamodb:ap-northeast-1:129824596365:table/users because no identity-based policy allows the dynamodb:Scan action\u0026#34;, 8 \u0026#34;stackTrace\u0026#34;: [ 9 \u0026#34;AccessDeniedException: User: arn:aws:sts::129824596365:assumed-role/sam-app-GetUsersRole-e2VmZDAl4NoY/sam-app-GetUsers-PGeiGDJRikRx is not authorized to perform: dynamodb:Scan on resource: arn:aws:dynamodb:ap-northeast-1:129824596365:table/users because no identity-based policy allows the dynamodb:Scan action\u0026#34;, 10 \u0026#34; at throwDefaultError (/var/runtime/node_modules/@aws-sdk/node_modules/@smithy/smithy-client/dist-cjs/index.js:838:20)\u0026#34;, 11 \u0026#34; at /var/runtime/node_modules/@aws-sdk/node_modules/@smithy/smithy-client/dist-cjs/index.js:847:5\u0026#34;, 12 \u0026#34; at de_CommandError (/var/runtime/node_modules/@aws-sdk/client-dynamodb/dist-cjs/index.js:2150:14)\u0026#34;, 13 \u0026#34; at process.processTicksAndRejections (node:internal/process/task_queues:95:5)\u0026#34;, 14 \u0026#34; at async /var/runtime/node_modules/@aws-sdk/node_modules/@smithy/middleware-serde/dist-cjs/index.js:35:20\u0026#34;, 15 \u0026#34; at async /var/runtime/node_modules/@aws-sdk/lib-dynamodb/dist-cjs/index.js:174:30\u0026#34;, 16 \u0026#34; at async /var/runtime/node_modules/@aws-sdk/node_modules/@smithy/core/dist-cjs/index.js:165:18\u0026#34;, 17 \u0026#34; at async /var/runtime/node_modules/@aws-sdk/node_modules/@smithy/middleware-retry/dist-cjs/index.js:320:38\u0026#34;, 18 \u0026#34; at async /var/runtime/node_modules/@aws-sdk/middleware-logger/dist-cjs/index.js:33:22\u0026#34;, 19 \u0026#34; at async Runtime.lambdaHandler [as handler] (file:///var/task/app.mjs:34:16)\u0026#34; 20 ], 21 \u0026#34;name\u0026#34;: \u0026#34;AccessDeniedException\u0026#34;, 22 \u0026#34;$fault\u0026#34;: \u0026#34;client\u0026#34;, 23 \u0026#34;$metadata\u0026#34;: { 24 \u0026#34;httpStatusCode\u0026#34;: 400, 25 \u0026#34;requestId\u0026#34;: \u0026#34;ULUQ6S15FJ9GN2KDDMG9EF7NT3VV4KQNSO5AEMVJF66Q9ASUAAJG\u0026#34;, 26 \u0026#34;attempts\u0026#34;: 1, 27 \u0026#34;totalRetryDelay\u0026#34;: 0 28 }, 29 \u0026#34;__type\u0026#34;: \u0026#34;com.amazon.coral.service#AccessDeniedException\u0026#34;, 30 \u0026#34;message\u0026#34;: \u0026#34;User: arn:aws:sts::129824596365:assumed-role/sam-app-GetUsersRole-e2VmZDAl4NoY/sam-app-GetUsers-PGeiGDJRikRx is not authorized to perform: dynamodb:Scan on resource: arn:aws:dynamodb:ap-northeast-1:129824596365:table/users because no identity-based policy allows the dynamodb:Scan action\u0026#34; 31 } 32} 修復權限問題 SAM 有定義許多 policy template ，而 Get 只需要 Read DyanmoDB ，所以我們可以選擇 DynamoDBReadPolicy 就可以\n最終 template.yaml 的 Resources 會長這樣\n1Resources: 2 Table: 3 Type: AWS::Serverless::SimpleTable 4 Properties: 5 PrimaryKey: 6 Name: id 7 Type: String 8 TableName: Users 9 GetUsers: 10 Type: AWS::Serverless::Function 11 Properties: 12 CodeUri: users/ 13 Handler: app.lambdaHandler 14 Runtime: nodejs20.x 15 Architectures: 16 - x86_64 17 Events: 18 HelloWorld: 19 Type: Api 20 Properties: 21 Path: /users 22 Method: get 23 Policies: 24 - DynamoDBReadPolicy: 25 TableName: !Ref Table 部署時，從 ChangeSet 可以看到 IAM Role 有修改\n1CloudFormation stack changeset 2----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 3Operation LogicalResourceId ResourceType Replacement 4----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 5* Modify GetUsersRole AWS::IAM::Role False 6* Modify GetUsers AWS::Lambda::Function False 7* Modify ServerlessRestApi AWS::ApiGateway::RestApi False 8----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 部署完以後再用 Curl 打 ApiGateway 會拿到結果\n1$ curl https://kxkhl0spi1.execute-api.ap-northeast-1.amazonaws.com/Prod/users 2[{\u0026#34;id\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Hsieh\u0026#34;,\u0026#34;firstName\u0026#34;:\u0026#34;Allen\u0026#34;}] 建立 Create User API 修改 Lambda Fuction 艾倫在 swtich case 中，多加了 Post 的 case (line19-33)\n1import { DynamoDBClient } from \u0026#34;@aws-sdk/client-dynamodb\u0026#34;; 2import { 3 DynamoDBDocumentClient, 4 ScanCommand, 5 PutCommand 6} from \u0026#34;@aws-sdk/lib-dynamodb\u0026#34;; 7 8const client = new DynamoDBClient({}); 9 10const dynamo = DynamoDBDocumentClient.from(client); 11 12const tableName = \u0026#34;Users\u0026#34;; 13 14export const lambdaHandler = async (event, context) =\u0026gt; { 15 console.log(\u0026#34;EVENT: \\n\u0026#34; + JSON.stringify(event, null, 2)); 16 console.log(\u0026#34;httpmethod\u0026#34; + event.httpMethod); 17 let body; 18 switch(event.httpMethod) { 19 case \u0026#34;POST\u0026#34;: 20 console.log(\u0026#34;Http Post\u0026#34;); 21 let item = JSON.parse(event.body) 22 await dynamo.send( 23 new PutCommand({ 24 TableName: tableName, 25 Item: { 26 id: item.id, 27 lastName: item.lastName, 28 firstName: item.firstName 29 }, 30 }) 31 ); 32 body = \u0026#34;{}\u0026#34;; 33 break; 34 case \u0026#34;GET\u0026#34;: 35 console.log(\u0026#34;Http Get\u0026#34;); 36 body = await dynamo.send( 37 new ScanCommand({ TableName: tableName }) 38 ); 39 body = body.Items; 40 break; 41 } 42 const response = { 43 statusCode: 200, 44 body: JSON.stringify(body) 45 }; 46 47 return response; 48}; 修改 template.yaml 這邊要注意的是，因為我們是需要寫入 DynamoDB，所已這邊使用的 Policies 是 DynamoDBCrudPolicy\n1 CreateUsers: 2 Type: AWS::Serverless::Function 3 Properties: 4 CodeUri: users/ 5 Handler: app.lambdaHandler 6 Runtime: nodejs20.x 7 Architectures: 8 - x86_64 9 Events: 10 HelloWorld: 11 Type: Api 12 Properties: 13 Path: /users 14 Method: post 15 Policies: 16 - DynamoDBCrudPolicy: 17 TableName: !Ref Table 測試 在部署完後，使用 curl 測試 Post ，可以看到正常的回覆。\n1curl -X POST https://kxkhl0spi1.execute-api.ap-northeast-1.amazonaws.com/Prod/users -d \u0026#39;{\u0026#34;id\u0026#34;:\u0026#34;2\u0026#34;, \u0026#34;lastName\u0026#34; : \u0026#34;Chung\u0026#34;, \u0026#34;firstName\u0026#34;: \u0026#34;Leo\u0026#34;}\u0026#39; 2\u0026#34;{}\u0026#34; 再 call 一次，我們原先寫好的 get ，可以看到剛剛建立的 Item\n1$ curl https://kxkhl0spi1.execute-api.ap-northeast-1.amazonaws.com/Prod/users 2[{\u0026#34;id\u0026#34;:\u0026#34;2\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Chung\u0026#34;,\u0026#34;firstName\u0026#34;:\u0026#34;Leo\u0026#34;},{\u0026#34;id\u0026#34;:\u0026#34;1\u0026#34;,\u0026#34;lastName\u0026#34;:\u0026#34;Hsieh\u0026#34;,\u0026#34;firstName\u0026#34;:\u0026#34;Allen\u0026#34;}] ","date":"February 15, 2024","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/sam-part5-dynamodb/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"},{"title":"SAM","url":"/tags/sam/"}],"timestamp":1707955200,"title":"SAM Part5: 部署 Dynamodb"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"什麼是 AWS Community Builder Community Builder 是 AWS 社群中的一群志願者和熱心人士，他們致力於促進 AWS 技術和知識的分享與傳播。主要透過部落格、社交媒體、演講等多種方式與社群互動，分享他們的經驗。\n以前 AWS Community Builder 是一年有兩次審核，但隨著 Builder 人數變多，2024 改由一年審核一次。所以今年錯過了，就只能等 2025 嘍～\n這邊是官方的介紹和申請頁面\n另外可以參考，看看艾倫 2023 做了什麼相關事情，申請 Community Builder ，當然上面的事情不是全部，僅供參考而已\n福利 認識世界各地的 Builder \u0026 Heros AWS 有建立一個群組，將所有的 Builder 和 Heros 都拉入到群組中。大家可以在裡面詢問和互相討論問題～\n在這邊有許多強者，還可以學習到不同的文化和東西。\nBuilder\u0026rsquo;s 禮物 當然也不能少了 AWS Builder 禮物\nCredits AWS 會提供一些回饋讓 Builder 可以去實驗一些貴貴或是新的服務。\nAWS Sharing AWS 內部會定期派員工來分享一些新的功能和服務～\nAPJ Community 雖然台灣和中國一起被歸類在大中華地區，但我們還是可以被邀請一同參加 APJ 的活動 而且還有 APJ 限定的禮物 小總結 除了以上好處當然還有其他許多小福利，這邊就不一一分享。 因為當上 AWS Commuity Builder 我覺得最大的好處，就是可以認識一群熱愛 AWS 服務的人～ 福利真的只是次要，所以如果你也是熱愛 AWS ，不妨申請看看，一起加入 AWS Community Builder 大家庭！\n","date":"January 16, 2024","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/what-is-aws-community-builder/","smallImg":"","tags":[],"timestamp":1705363200,"title":"什麼是 AWS Community Builder"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"文章寫作 努力維持平均一個月寫一篇文章~\n今年一共貢獻了12篇文章，上半年，主要在準備 AWS 執照，所以就都專注於執照的筆記，而下半年由於想做一些 side project ，所以專注於使用 SAM 來開發 Lambda。\nCloudFormation Certification Note Config Certification Note S3 Certification Note DynamoDB Certification Note 使用 Lightsail 架設 WordPress 網站 使用 AWS Cognito CLI 建立 User Pool Build AWS Lambda Hello World Function by SAM 什麼是 AWS Lambda SAM Part1: Node 專案初始化 SAM Part2: 地端測試 SAM Part3: 雲端部署 SAM Part4: 雲端測試 AWS 執照 今天目標原本是考三四張的，但下半年因為公司變化，轉了部門，所以沒有太多時間準備考新的執照，最後在六月一次拼了兩張而已\nCertified Data Analytics AWS Certified Security 8 月 AWS Community Day 今年是台灣第二屆 AWS Community Day，由於公司分享需要申請，艾倫嫌麻煩，所以只好乖乖的當 Jam 的主持人～\n由於當天要看場，所以沒有帶電腦，看到下面每個人都認真在做 Jam ，也有股衝動，想下去玩玩 QAQ 當天熱情的志工和講師們～ 歡迎大家明年一起來加入我們 另外超開心的是獲得了 AWS 桌遊～ 打完一次以後就覺得超好玩，艾倫還有帶去公司和同事一起打 九月 AWS Community Builder 在十月的時候，很開心的申請上的 Community Buidler ，台灣剛好十位 Builders ，希望明年可以繼續續約～ 明年再來分享一篇什麼是 AWS Community Builder 好了。\n十月 AWS Traning 艾倫的公司有贊助員工上 AWS 原廠的課程，所以在十月時，上了 AWS EKS 的課程。\n總結 2023 過得很充實，雖然很多事情沒有達到原本的目標規劃，但至少還是有達成一半以上～\nAWS Summit 有點可惜，由於艾倫早就訂好機票去沖繩，沒下到跟 Summit 衝突到，希望 2024 不會再錯過了\n","date":"December 12, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/2023-aws-review/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"},{"title":"SAM","url":"/tags/sam/"}],"timestamp":1702339200,"title":"2023 回顧"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"直接打 API Gateway 在 Part3 中，Deployment 完時，CloudFomration 的 Output 可以看到 ApiGateway 的 URI。如果沒有記住，我們也可以在 AWS Console 中的 API Gateway Stage 找到 URI 找到 URI 以後，可以直接使用 CURL 做測試\n1$ curl https://t3faydf1rb.execute-api.ap-northeast-1.amazonaws.com/Prod/hello 2{\u0026#34;message\u0026#34;:\u0026#34;hello world\u0026#34;}% 取得執行 Log 透過 AWS Console AWS Lambda 預設會建立 CloudWatch Log Group，我們可以在 CloudWatch 中的 Log Group 找到 Lambda 執行的 Log。 預設的 Log Group 名字是 /aws/lambda/\u0026lt;function name\u0026gt; 在 Log Steam 裡面，可以找到艾倫在 Part3 中，修改 Lambda Function Code 時，所印出 Event 的 Log SAM Log 1$ sam logs -n HelloWorldFunction --stack-name sam-app --tail 2You can now use \u0026#39;sam logs\u0026#39; without --name parameter, which will pull the logs from all supported resources in your stack. 3 42024/03/26/[$LATEST]a0274c6a05404868b3fb3c15d3443312 2024-03-26T13:12:19.327000 { 5 \u0026#34;time\u0026#34;: \u0026#34;2024-03-26T13:12:19.327Z\u0026#34;, 6 \u0026#34;type\u0026#34;: \u0026#34;platform.initStart\u0026#34;, 7 \u0026#34;record\u0026#34;: { 8 \u0026#34;initializationType\u0026#34;: \u0026#34;on-demand\u0026#34;, 9 \u0026#34;phase\u0026#34;: \u0026#34;init\u0026#34;, 10 \u0026#34;runtimeVersion\u0026#34;: \u0026#34;nodejs:20.v19\u0026#34;, 11 \u0026#34;runtimeVersionArn\u0026#34;: \u0026#34;arn:aws:lambda:ap-northeast-1::runtime:ecf83feba464e64dae4dc1a80327f8f786abd91aed7e0d884474a062cd1a7d63\u0026#34;, 12 \u0026#34;functionName\u0026#34;: \u0026#34;sam-app-HelloWorldFunction-Qiut5gK4QT6I\u0026#34;, 13 \u0026#34;functionVersion\u0026#34;: \u0026#34;$LATEST\u0026#34; 14 } 15} 162024/03/26/[$LATEST]a0274c6a05404868b3fb3c15d3443312 2024-03-26T13:12:19.468000 { 17 \u0026#34;time\u0026#34;: \u0026#34;2024-03-26T13:12:19.468Z\u0026#34;, 18 \u0026#34;type\u0026#34;: \u0026#34;platform.start\u0026#34;, 19 \u0026#34;record\u0026#34;: { 20 \u0026#34;requestId\u0026#34;: \u0026#34;baf81fc5-767d-43e9-a780-6f96f0955a6c\u0026#34;, 21 \u0026#34;version\u0026#34;: \u0026#34;$LATEST\u0026#34;, 22 \u0026#34;tracing\u0026#34;: { 23 \u0026#34;spanId\u0026#34;: \u0026#34;6c72e2f7121224ce\u0026#34;, 24 \u0026#34;type\u0026#34;: \u0026#34;X-Amzn-Trace-Id\u0026#34;, 25 \u0026#34;value\u0026#34;: \u0026#34;Root=1-6602c9b3-1f608cce18790dbc0c64ca6e;Parent=7621c3d74d395e42;Sampled=1\u0026#34; 26 } 27 } 28} 292024/03/26/[$LATEST]a0274c6a05404868b3fb3c15d3443312 2024-03-26T13:12:19.469000 { 30 \u0026#34;timestamp\u0026#34;: \u0026#34;2024-03-26T13:12:19.469Z\u0026#34;, 31 \u0026#34;level\u0026#34;: \u0026#34;INFO\u0026#34;, 32 \u0026#34;requestId\u0026#34;: \u0026#34;baf81fc5-767d-43e9-a780-6f96f0955a6c\u0026#34;, 33 \u0026#34;message\u0026#34;: \u0026#34;EVENT: \\n{}\u0026#34; 34} 352024/03/26/[$LATEST]a0274c6a05404868b3fb3c15d3443312 2024-03-26T13:12:19.514000 { 36 \u0026#34;time\u0026#34;: \u0026#34;2024-03-26T13:12:19.514Z\u0026#34;, 37 \u0026#34;type\u0026#34;: \u0026#34;platform.report\u0026#34;, 38 \u0026#34;record\u0026#34;: { 39 \u0026#34;requestId\u0026#34;: \u0026#34;baf81fc5-767d-43e9-a780-6f96f0955a6c\u0026#34;, 40 \u0026#34;metrics\u0026#34;: { 41 \u0026#34;durationMs\u0026#34;: 44.002, 42 \u0026#34;billedDurationMs\u0026#34;: 45, 43 \u0026#34;memorySizeMB\u0026#34;: 128, 44 \u0026#34;maxMemoryUsedMB\u0026#34;: 66, 45 \u0026#34;initDurationMs\u0026#34;: 139.993 46 }, 47 \u0026#34;tracing\u0026#34;: { 48 \u0026#34;spanId\u0026#34;: \u0026#34;6c72e2f7121224ce\u0026#34;, 49 \u0026#34;type\u0026#34;: \u0026#34;X-Amzn-Trace-Id\u0026#34;, 50 \u0026#34;value\u0026#34;: \u0026#34;Root=1-6602c9b3-1f608cce18790dbc0c64ca6e;Parent=7621c3d74d395e42;Sampled=1\u0026#34; 51 }, 52 \u0026#34;status\u0026#34;: \u0026#34;success\u0026#34; 53 } 54} 使用 SAM 測試雲上 Lambda Function 除了使用基本的 Curl 以外， SAM remote 讓我們可以直接在地端觸發雲上的 Lambda Function ，並且提供一些額外的資訊，例如 billedDurationMs 等\n1$ sam remote invoke 2 3Invoking Lambda Function HelloWorldFunction 4{\u0026#34;time\u0026#34;:\u0026#34;2024-03-26T13:12:19.327Z\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;platform.initStart\u0026#34;,\u0026#34;record\u0026#34;:{\u0026#34;initializationType\u0026#34;:\u0026#34;on-demand\u0026#34;,\u0026#34;phase\u0026#34;:\u0026#34;init\u0026#34;,\u0026#34;runtimeVersion\u0026#34;:\u0026#34;nodejs:20.v19\u0026#34;,\u0026#34;runtimeVersionArn\u0026#34;:\u0026#34;arn:aws:lambda:ap-northeast-1::runtime:ecf83feba464e64dae4dc1a80327f8f786abd91aed7e0d884474a062cd1a7d63\u0026#34;,\u0026#34;functionName\u0026#34;:\u0026#34;sam-app-HelloWorldFunction-Qiut5gK4QT6I\u0026#34;,\u0026#34;functionVersion\u0026#34;:\u0026#34;$LATEST\u0026#34;}} 5{\u0026#34;time\u0026#34;:\u0026#34;2024-03-26T13:12:19.466Z\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;platform.initRuntimeDone\u0026#34;,\u0026#34;record\u0026#34;:{\u0026#34;initializationType\u0026#34;:\u0026#34;on-demand\u0026#34;,\u0026#34;phase\u0026#34;:\u0026#34;init\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;success\u0026#34;}} 6{\u0026#34;time\u0026#34;:\u0026#34;2024-03-26T13:12:19.466Z\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;platform.initReport\u0026#34;,\u0026#34;record\u0026#34;:{\u0026#34;initializationType\u0026#34;:\u0026#34;on-demand\u0026#34;,\u0026#34;phase\u0026#34;:\u0026#34;init\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;success\u0026#34;,\u0026#34;metrics\u0026#34;:{\u0026#34;durationMs\u0026#34;:139.899}}} 7{\u0026#34;time\u0026#34;:\u0026#34;2024-03-26T13:12:19.468Z\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;platform.start\u0026#34;,\u0026#34;record\u0026#34;:{\u0026#34;requestId\u0026#34;:\u0026#34;baf81fc5-767d-43e9-a780-6f96f0955a6c\u0026#34;,\u0026#34;version\u0026#34;:\u0026#34;$LATEST\u0026#34;,\u0026#34;tracing\u0026#34;:{\u0026#34;spanId\u0026#34;:\u0026#34;6c72e2f7121224ce\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;X-Amzn-Trace-Id\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Root=1-6602c9b3-1f608cce18790dbc0c64ca6e;Parent=7621c3d74d395e42;Sampled=1\u0026#34;}}} 8{\u0026#34;timestamp\u0026#34;:\u0026#34;2024-03-26T13:12:19.469Z\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;baf81fc5-767d-43e9-a780-6f96f0955a6c\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;EVENT: \\n{}\u0026#34;} 9{\u0026#34;time\u0026#34;:\u0026#34;2024-03-26T13:12:19.511Z\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;platform.runtimeDone\u0026#34;,\u0026#34;record\u0026#34;:{\u0026#34;requestId\u0026#34;:\u0026#34;baf81fc5-767d-43e9-a780-6f96f0955a6c\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;success\u0026#34;,\u0026#34;tracing\u0026#34;:{\u0026#34;spanId\u0026#34;:\u0026#34;3444a7bf6600aaff\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;X-Amzn-Trace-Id\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Root=1-6602c9b3-1f608cce18790dbc0c64ca6e;Parent=6c72e2f7121224ce;Sampled=1;Lineage=7e433ca5:0\u0026#34;},\u0026#34;spans\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;responseLatency\u0026#34;,\u0026#34;start\u0026#34;:\u0026#34;2024-03-26T13:12:19.468Z\u0026#34;,\u0026#34;durationMs\u0026#34;:6.097},{\u0026#34;name\u0026#34;:\u0026#34;responseDuration\u0026#34;,\u0026#34;start\u0026#34;:\u0026#34;2024-03-26T13:12:19.474Z\u0026#34;,\u0026#34;durationMs\u0026#34;:0.106},{\u0026#34;name\u0026#34;:\u0026#34;runtimeOverhead\u0026#34;,\u0026#34;start\u0026#34;:\u0026#34;2024-03-26T13:12:19.475Z\u0026#34;,\u0026#34;durationMs\u0026#34;:36.296}],\u0026#34;metrics\u0026#34;:{\u0026#34;durationMs\u0026#34;:43.028,\u0026#34;producedBytes\u0026#34;:57}}} 10{\u0026#34;time\u0026#34;:\u0026#34;2024-03-26T13:12:19.514Z\u0026#34;,\u0026#34;type\u0026#34;:\u0026#34;platform.report\u0026#34;,\u0026#34;record\u0026#34;:{\u0026#34;requestId\u0026#34;:\u0026#34;baf81fc5-767d-43e9-a780-6f96f0955a6c\u0026#34;,\u0026#34;status\u0026#34;:\u0026#34;success\u0026#34;,\u0026#34;metrics\u0026#34;:{\u0026#34;durationMs\u0026#34;:44.002,\u0026#34;billedDurationMs\u0026#34;:45,\u0026#34;memorySizeMB\u0026#34;:128,\u0026#34;maxMemoryUsedMB\u0026#34;:66,\u0026#34;initDurationMs\u0026#34;:139.993},\u0026#34;tracing\u0026#34;:{\u0026#34;type\u0026#34;:\u0026#34;X-Amzn-Trace-Id\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;Root=1-6602c9b3-1f608cce18790dbc0c64ca6e;Parent=7621c3d74d395e42;Sampled=1\u0026#34;,\u0026#34;spanId\u0026#34;:\u0026#34;6c72e2f7121224ce\u0026#34;}}}{\u0026#34;statusCode\u0026#34;:200,\u0026#34;body\u0026#34;:\u0026#34;{\\\u0026#34;message\\\u0026#34;:\\\u0026#34;hello world\\\u0026#34;}\u0026#34;} 11SAM CLI update available (1.113.0); (1.111.0 installed) 12To download: https://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-install.html ","date":"November 11, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/sam-part4-cloud-testing/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"},{"title":"SAM","url":"/tags/sam/"}],"timestamp":1699660800,"title":"SAM Part4: 雲端測試"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"SAM 部署 SAM 提供了 deployment 的指令，並且在 deployment 的 options 中有一個 guided，可以透過回答問題的方式，幫助另一次部署的人快速部署。記得在 deploy 之前，要先執行過 sam build。\n另外 SAM 使用的是 AWS CLI 的 Credentials，所以要先確認這些 Credential 是可以使用的。\n1$ sam deploy --guided 2 3Configuring SAM deploy 4====================== 5 6\tLooking for config file [samconfig.toml] : Found 7\tReading default arguments : Success 8 9\tSetting default arguments for \u0026#39;sam deploy\u0026#39; 10\t========================================= 11\tStack Name [sam-app]: 12\tAWS Region [ap-northeast-1]: 13\t#Shows you resources changes to be deployed and require a \u0026#39;Y\u0026#39; to initiate deploy 14\tConfirm changes before deploy [Y/n]: Y 15\t#SAM needs permission to be able to create roles to connect to the resources in your template 16\tAllow SAM CLI IAM role creation [Y/n]: Y 17\t#Preserves the state of previously provisioned resources when an operation fails 18\tDisable rollback [y/N]: y 19\tHelloWorldFunction has no authentication. Is this okay? [y/N]: y 20\tSave arguments to configuration file [Y/n]: Y 21\tSAM configuration file [samconfig.toml]: 22\tSAM configuration environment [default]: 23 24\tLooking for resources needed for deployment: 25 26\tManaged S3 bucket: aws-sam-cli-managed-default-samclisourcebucket-1syrjc2soglaa 27\tA different default S3 bucket can be set in samconfig.toml and auto resolution of buckets turned off by setting resolve_s3=False 28 29 Parameter \u0026#34;stack_name=sam-app\u0026#34; in [default.deploy.parameters] is defined as a global parameter [default.global.parameters]. 30 This parameter will be only saved under [default.global.parameters] in /Users/allen/sam-app/samconfig.toml. 31 32\tSaved arguments to config file 33\tRunning \u0026#39;sam deploy\u0026#39; for future deployments will use the parameters saved above. 34\tThe above parameters can be changed by modifying samconfig.toml 35\tLearn more about samconfig.toml syntax at 36\thttps://docs.aws.amazon.com/serverless-application-model/latest/developerguide/serverless-sam-cli-config.html 37 38\tUploading to sam-app/73ed78d2180973be557e5b20ff3918f7 598152 / 598152 (100.00%) 39 40\tDeploying with following values 41\t=============================== 42\tStack name : sam-app 43\tRegion : ap-northeast-1 44\tConfirm changeset : True 45\tDisable rollback : True 46\tDeployment s3 bucket : aws-sam-cli-managed-default-samclisourcebucket-1syrjc2soglaa 47\tCapabilities : [\u0026#34;CAPABILITY_IAM\u0026#34;] 48\tParameter overrides : {} 49\tSigning Profiles : {} 50 51Initiating deployment 52===================== 53 54\tUploading to sam-app/fced19bb73698b56db25505260c97e96.template 1273 / 1273 (100.00%) 55 56 57Waiting for changeset to be created.. 58 59CloudFormation stack changeset 60--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 61Operation LogicalResourceId ResourceType Replacement 62--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 63+ Add HelloWorldFunctionHelloWorldPermissionProd AWS::Lambda::Permission N/A 64+ Add HelloWorldFunctionRole AWS::IAM::Role N/A 65+ Add HelloWorldFunction AWS::Lambda::Function N/A 66+ Add ServerlessRestApiDeployment47fc2d5f9d AWS::ApiGateway::Deployment N/A 67+ Add ServerlessRestApiProdStage AWS::ApiGateway::Stage N/A 68+ Add ServerlessRestApi AWS::ApiGateway::RestApi N/A 69--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 70 71 72Changeset created successfully. arn:aws:cloudformation:ap-northeast-1:129824596365:changeSet/samcli-deploy1711380173/7c5b81e7-8642-4028-9362-80eb6fbe608d 73 74 75Previewing CloudFormation changeset before deployment 76====================================================== 77Deploy this changeset? [y/N]: 在 Line 14 時，我們有勾選需要先審核過 Changeset 才可以繼續部署，所以在初始化一個 Stack後，CloudFormation 會顯示這次的部署會修改什麼 (line 59-69)。前面有加號代表是這次部署新增的，而減號的話代表是刪除的。由於這次第一次部署，所以所有的資源肯定都是新增的。\n而在 AWS CloudFormation UI 上，也可以看到艾倫的 Stack 卡在 REVIEW_IN_PROGRESS\n當我們同意部署後，就可以看到 CloudFormation 正在部署，並且在最後會印出，我們在 template.yaml 所定義的 output (line 32 - 47)\n1Deploy this changeset? [y/N]: y 2 32023-09-15 23:33:09 - Waiting for stack create/update to complete 4 5CloudFormation events from stack operations (refresh every 5.0 seconds) 6--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 7ResourceStatus ResourceType LogicalResourceId ResourceStatusReason 8--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 9CREATE_IN_PROGRESS AWS::CloudFormation::Stack sam-app User Initiated 10CREATE_IN_PROGRESS AWS::IAM::Role HelloWorldFunctionRole - 11CREATE_IN_PROGRESS AWS::IAM::Role HelloWorldFunctionRole Resource creation Initiated 12CREATE_COMPLETE AWS::IAM::Role HelloWorldFunctionRole - 13CREATE_IN_PROGRESS AWS::Lambda::Function HelloWorldFunction - 14CREATE_IN_PROGRESS AWS::Lambda::Function HelloWorldFunction Resource creation Initiated 15CREATE_IN_PROGRESS AWS::Lambda::Function HelloWorldFunction Eventual consistency check initiated 16CREATE_IN_PROGRESS AWS::ApiGateway::RestApi ServerlessRestApi - 17CREATE_IN_PROGRESS AWS::ApiGateway::RestApi ServerlessRestApi Resource creation Initiated 18CREATE_COMPLETE AWS::ApiGateway::RestApi ServerlessRestApi - 19CREATE_IN_PROGRESS AWS::ApiGateway::Deployment ServerlessRestApiDeployment47fc2d5f9d - 20CREATE_IN_PROGRESS AWS::Lambda::Permission HelloWorldFunctionHelloWorldPermissionProd - 21CREATE_IN_PROGRESS AWS::Lambda::Permission HelloWorldFunctionHelloWorldPermissionProd Resource creation Initiated 22CREATE_IN_PROGRESS AWS::ApiGateway::Deployment ServerlessRestApiDeployment47fc2d5f9d Resource creation Initiated 23CREATE_COMPLETE AWS::Lambda::Function HelloWorldFunction - 24CREATE_COMPLETE AWS::Lambda::Permission HelloWorldFunctionHelloWorldPermissionProd - 25CREATE_COMPLETE AWS::ApiGateway::Deployment ServerlessRestApiDeployment47fc2d5f9d - 26CREATE_IN_PROGRESS AWS::ApiGateway::Stage ServerlessRestApiProdStage - 27CREATE_IN_PROGRESS AWS::ApiGateway::Stage ServerlessRestApiProdStage Resource creation Initiated 28CREATE_COMPLETE AWS::ApiGateway::Stage ServerlessRestApiProdStage - 29CREATE_COMPLETE AWS::CloudFormation::Stack sam-app - 30--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 31 32CloudFormation outputs from deployed stack 33--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 34Outputs 35--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 36Key HelloWorldFunctionIamRole 37Description Implicit IAM Role created for Hello World function 38Value arn:aws:iam::129824596365:role/sam-app-HelloWorldFunctionRole-WOf5YCP85EX0 39 40Key HelloWorldApi 41Description API Gateway endpoint URL for Prod stage for Hello World function 42Value https://t3faydf1rb.execute-api.ap-northeast-1.amazonaws.com/Prod/hello/ 43 44Key HelloWorldFunction 45Description Hello World Lambda Function ARN 46Value arn:aws:lambda:ap-northeast-1:129824596365:function:sam-app-HelloWorldFunction-Qiut5gK4QT6I 47--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 48 49 50Successfully created/updated stack - sam-app in ap-northeast-1 建立的 Resource API Gateway 在 API Gateway 的頁面，我們可以看到 sam-demo 已經被建立好了\n點入 sam-demo 以後，在 resource 可以看到我們定義好的 Http method Get 的 Hello，並且後面已經串接好 Lambda Function\nLambda Function 在 Lambda 頁面，也以樣可以看到我們剛剛部署好的 sam-app-HelloWorldFunction-Qiut5gK4QT6I 點入到 Lambda ，可以看到 Code Source Section，從左邊的 Folder 我們可以看到環境中有根據Package.json 所裝好的 Library node_modules。也可以同時看到我們的 Lambda Function Soruce code。\n","date":"October 18, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/sam-part3-deployment/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"},{"title":"SAM","url":"/tags/sam/"}],"timestamp":1697587200,"title":"SAM Part3: 雲端部署"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"SAM Local 這邊使用 sam local start-api 在地端起 Lambda Function 來測試，需要注意的是，這邊需要是會是在地端啟動 Docker ，所以需要將 Docker 預先安裝好。\n1$ sam local start-api 2 3Initializing the lambda functions containers. 4Local image is out of date and will be updated to the latest runtime. To skip this, pass in the parameter --skip-pull-image 5Building image..................................................................................................................................................................................................................................................................................................... 6Using local image: public.ecr.aws/lambda/nodejs:20-rapid-x86_64. 7 8Mounting /Users/allen/sam-app/.aws-sam/build/HelloWorldFunction as /var/task:ro,delegated, inside runtime container 9Containers Initialization is done. 10Mounting HelloWorldFunction at http://127.0.0.1:3000/hello [GET] 11You can now browse to the above endpoints to invoke your functions. You do not need to restart/reload SAM CLI while working on your functions, 12changes will be reflected instantly/automatically. If you used sam build before running local commands, you will need to re-run sam build for 13the changes to be picked up. You only need to restart SAM CLI if you update your AWS SAM template 142024-03-24 23:43:10 WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead. 15 * Running on http://127.0.0.1:3000 162024-03-24 23:43:10 Press CTRL+C to quit 使用 Curl 測試 我們可以看到，Sam 在 local 起的 Application 並聽 3000 port ，這使用可以使用 curl 來測試。\n1$ curl http://127.0.0.1:3000/hello 2{\u0026#34;message\u0026#34;:\u0026#34;hello world\u0026#34;} 而在原本執行 sam local start-api 的視窗，可以到以下的資訊\n1Invoking app.lambdaHandler (nodejs20.x) 2Reuse the created warm container for Lambda function \u0026#39;HelloWorldFunction\u0026#39; 3Lambda function \u0026#39;HelloWorldFunction\u0026#39; is already running 4START RequestId: 3475a269-43c0-468d-a6c9-f31fbf2c34fa Version: $LATEST 5END RequestId: 13944b37-b949-480d-865e-8e9ac1c4b0ea 6REPORT RequestId: 13944b37-b949-480d-865e-8e9ac1c4b0ea\tInit Duration: 0.06 ms\tDuration: 115.87 ms\tBilled Duration: 116 ms\tMemory Size: 128 MB\tMax Memory Used: 128 MB 7 8No Content-Type given. Defaulting to \u0026#39;application/json\u0026#39;. 92024-03-24 23:45:16 127.0.0.1 - - [24/Mar/2024 23:45:16] \u0026#34;GET /hello HTTP/1.1\u0026#34; 200 - 這邊可以還可以清楚看到，執行時間，和收費時間。雖然 Local 的硬體規格和 AWS 上的機器不同，但還可以作為簡單參考。\n插旗除錯 在發中過程中，插旗除錯是最常見的，我在 app.mjs 插入 Line2 將 Event 印出來，但修改後直接執行 sam local start-api ，在 Terminal 中的訊息，看不到剛剛的 Log。\n1export const lambdaHandler = async (event, context) =\u0026gt; { 2 console.log(\u0026#34;EVENT: \\n\u0026#34; + JSON.stringify(event, null, 2)); 3 const response = { 4 statusCode: 200, 5 body: JSON.stringify({ 6 message: \u0026#39;hello world\u0026#39;, 7 }) 8 }; 9 10 return response; 11 }; 之前在第一篇文章有提過 sam build ，sam local 是跑 build 完以後的結果，所以直接改 source code 沒有重新 build 是無法生效的。\n以下是重新 Build 完以後的結果。\n1Invoking app.lambdaHandler (nodejs20.x) 2Reuse the created warm container for Lambda function \u0026#39;HelloWorldFunction\u0026#39; 3Lambda function \u0026#39;HelloWorldFunction\u0026#39; is already running 4{\u0026#34;timestamp\u0026#34;:\u0026#34;2024-03-24T16:08:27.280Z\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;fa7a5020-efc9-4791-aaf3-1c9951aaa65a\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;EVENT: \\n{\\n \\\u0026#34;body\\\u0026#34;: null,\\n \\\u0026#34;headers\\\u0026#34;: {\\n \\\u0026#34;Accept\\\u0026#34;: \\\u0026#34;*/*\\\u0026#34;,\\n \\\u0026#34;Host\\\u0026#34;: \\\u0026#34;127.0.0.1:3000\\\u0026#34;,\\n \\\u0026#34;User-Agent\\\u0026#34;: \\\u0026#34;curl/7.79.1\\\u0026#34;,\\n \\\u0026#34;X-Forwarded-Port\\\u0026#34;: \\\u0026#34;3000\\\u0026#34;,\\n \\\u0026#34;X-Forwarded-Proto\\\u0026#34;: \\\u0026#34;http\\\u0026#34;\\n },\\n \\\u0026#34;httpMethod\\\u0026#34;: \\\u0026#34;GET\\\u0026#34;,\\n \\\u0026#34;isBase64Encoded\\\u0026#34;: false,\\n \\\u0026#34;multiValueHeaders\\\u0026#34;: {\\n \\\u0026#34;Accept\\\u0026#34;: [\\n \\\u0026#34;*/*\\\u0026#34;\\n ],\\n \\\u0026#34;Host\\\u0026#34;: [\\n \\\u0026#34;127.0.0.1:3000\\\u0026#34;\\n ],\\n \\\u0026#34;User-Agent\\\u0026#34;: [\\n \\\u0026#34;curl/7.79.1\\\u0026#34;\\n ],\\n \\\u0026#34;X-Forwarded-Port\\\u0026#34;: [\\n \\\u0026#34;3000\\\u0026#34;\\n ],\\n \\\u0026#34;X-Forwarded-Proto\\\u0026#34;: [\\n \\\u0026#34;http\\\u0026#34;\\n ]\\n },\\n \\\u0026#34;multiValueQueryStringParameters\\\u0026#34;: null,\\n \\\u0026#34;path\\\u0026#34;: \\\u0026#34;/hello\\\u0026#34;,\\n \\\u0026#34;pathParameters\\\u0026#34;: null,\\n \\\u0026#34;queryStringParameters\\\u0026#34;: null,\\n \\\u0026#34;requestContext\\\u0026#34;: {\\n \\\u0026#34;accountId\\\u0026#34;: \\\u0026#34;123456789012\\\u0026#34;,\\n \\\u0026#34;apiId\\\u0026#34;: \\\u0026#34;1234567890\\\u0026#34;,\\n \\\u0026#34;domainName\\\u0026#34;: \\\u0026#34;127.0.0.1:3000\\\u0026#34;,\\n \\\u0026#34;extendedRequestId\\\u0026#34;: null,\\n \\\u0026#34;httpMethod\\\u0026#34;: \\\u0026#34;GET\\\u0026#34;,\\n \\\u0026#34;identity\\\u0026#34;: {\\n \\\u0026#34;accountId\\\u0026#34;: null,\\n \\\u0026#34;apiKey\\\u0026#34;: null,\\n \\\u0026#34;caller\\\u0026#34;: null,\\n \\\u0026#34;cognitoAuthenticationProvider\\\u0026#34;: null,\\n \\\u0026#34;cognitoAuthenticationType\\\u0026#34;: null,\\n \\\u0026#34;cognitoIdentityPoolId\\\u0026#34;: null,\\n \\\u0026#34;sourceIp\\\u0026#34;: \\\u0026#34;127.0.0.1\\\u0026#34;,\\n \\\u0026#34;user\\\u0026#34;: null,\\n \\\u0026#34;userAgent\\\u0026#34;: \\\u0026#34;Custom User Agent String\\\u0026#34;,\\n \\\u0026#34;userArn\\\u0026#34;: null\\n },\\n \\\u0026#34;path\\\u0026#34;: \\\u0026#34;/hello\\\u0026#34;,\\n \\\u0026#34;protocol\\\u0026#34;: \\\u0026#34;HTTP/1.1\\\u0026#34;,\\n \\\u0026#34;requestId\\\u0026#34;: \\\u0026#34;ce8b7da4-94ef-42c9-a09a-d06a3d5d5fb2\\\u0026#34;,\\n \\\u0026#34;requestTime\\\u0026#34;: \\\u0026#34;24/Mar/2024:16:08:20 +0000\\\u0026#34;,\\n \\\u0026#34;requestTimeEpoch\\\u0026#34;: 1711296500,\\n \\\u0026#34;resourceId\\\u0026#34;: \\\u0026#34;123456\\\u0026#34;,\\n \\\u0026#34;resourcePath\\\u0026#34;: \\\u0026#34;/hello\\\u0026#34;,\\n \\\u0026#34;stage\\\u0026#34;: \\\u0026#34;Prod\\\u0026#34;\\n },\\n \\\u0026#34;resource\\\u0026#34;: \\\u0026#34;/hello\\\u0026#34;,\\n \\\u0026#34;stageVariables\\\u0026#34;: null\\n}\u0026#34;} 5END RequestId: fa7a5020-efc9-4791-aaf3-1c9951aaa65a 6REPORT RequestId: fa7a5020-efc9-4791-aaf3-1c9951aaa65a\tInit Duration: 0.46 ms\tDuration: 170.95 ms\tBilled Duration: 171 ms\tMemory Size: 128 MB\tMax Memory Used: 128 MB 7 8No Content-Type given. Defaulting to \u0026#39;application/json\u0026#39;. 92024-03-25 00:08:27 127.0.0.1 - - [25/Mar/2024 00:08:27] \u0026#34;GET /hello HTTP/1.1\u0026#34; 200 - 測試單個函式 在 Application 的開發中，程式會隨著時間越來越肥，直接跑起整個 Application 所花費的時間也會越來越多。Sam 提供了可以單純測試某個函式的功能，這樣就不用啟整個 Application\n1$ sam local invoke HelloWorldFunction --event events/event. 2Invoking app.lambdaHandler (nodejs20.x) 3Local image is up-to-date 4Using local image: public.ecr.aws/lambda/nodejs:20-rapid-x86_64. 5 6Mounting /Users/allen/sam-app/.aws-sam/build/HelloWorldFunction as /var/task:ro,delegated, inside runtime container 7{\u0026#34;timestamp\u0026#34;:\u0026#34;2024-03-24T16:10:18.482Z\u0026#34;,\u0026#34;level\u0026#34;:\u0026#34;INFO\u0026#34;,\u0026#34;requestId\u0026#34;:\u0026#34;61c9bf38-f46f-4906-9c25-0d5f77bac250\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;EVENT: \\n{\\n \\\u0026#34;body\\\u0026#34;: \\\u0026#34;{\\\\\\\u0026#34;message\\\\\\\u0026#34;: \\\\\\\u0026#34;hello world\\\\\\\u0026#34;}\\\u0026#34;,\\n \\\u0026#34;resource\\\u0026#34;: \\\u0026#34;/{proxy+}\\\u0026#34;,\\n \\\u0026#34;path\\\u0026#34;: \\\u0026#34;/path/to/resource\\\u0026#34;,\\n \\\u0026#34;httpMethod\\\u0026#34;: \\\u0026#34;POST\\\u0026#34;,\\n \\\u0026#34;isBase64Encoded\\\u0026#34;: false,\\n \\\u0026#34;queryStringParameters\\\u0026#34;: {\\n \\\u0026#34;foo\\\u0026#34;: \\\u0026#34;bar\\\u0026#34;\\n },\\n \\\u0026#34;pathParameters\\\u0026#34;: {\\n \\\u0026#34;proxy\\\u0026#34;: \\\u0026#34;/path/to/resource\\\u0026#34;\\n },\\n \\\u0026#34;stageVariables\\\u0026#34;: {\\n \\\u0026#34;baz\\\u0026#34;: \\\u0026#34;qux\\\u0026#34;\\n },\\n \\\u0026#34;headers\\\u0026#34;: {\\n \\\u0026#34;Accept\\\u0026#34;: \\\u0026#34;text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\\\u0026#34;,\\n \\\u0026#34;Accept-Encoding\\\u0026#34;: \\\u0026#34;gzip, deflate, sdch\\\u0026#34;,\\n \\\u0026#34;Accept-Language\\\u0026#34;: \\\u0026#34;en-US,en;q=0.8\\\u0026#34;,\\n \\\u0026#34;Cache-Control\\\u0026#34;: \\\u0026#34;max-age=0\\\u0026#34;,\\n \\\u0026#34;CloudFront-Forwarded-Proto\\\u0026#34;: \\\u0026#34;https\\\u0026#34;,\\n \\\u0026#34;CloudFront-Is-Desktop-Viewer\\\u0026#34;: \\\u0026#34;true\\\u0026#34;,\\n \\\u0026#34;CloudFront-Is-Mobile-Viewer\\\u0026#34;: \\\u0026#34;false\\\u0026#34;,\\n \\\u0026#34;CloudFront-Is-SmartTV-Viewer\\\u0026#34;: \\\u0026#34;false\\\u0026#34;,\\n \\\u0026#34;CloudFront-Is-Tablet-Viewer\\\u0026#34;: \\\u0026#34;false\\\u0026#34;,\\n \\\u0026#34;CloudFront-Viewer-Country\\\u0026#34;: \\\u0026#34;US\\\u0026#34;,\\n \\\u0026#34;Host\\\u0026#34;: \\\u0026#34;1234567890.execute-api.us-east-1.amazonaws.com\\\u0026#34;,\\n \\\u0026#34;Upgrade-Insecure-Requests\\\u0026#34;: \\\u0026#34;1\\\u0026#34;,\\n \\\u0026#34;User-Agent\\\u0026#34;: \\\u0026#34;Custom User Agent String\\\u0026#34;,\\n \\\u0026#34;Via\\\u0026#34;: \\\u0026#34;1.1 08f323deadbeefa7af34d5feb414ce27.cloudfront.net (CloudFront)\\\u0026#34;,\\n \\\u0026#34;X-Amz-Cf-Id\\\u0026#34;: \\\u0026#34;cDehVQoZnx43VYQb9j2-nvCh-9z396Uhbp027Y2JvkCPNLmGJHqlaA==\\\u0026#34;,\\n \\\u0026#34;X-Forwarded-For\\\u0026#34;: \\\u0026#34;127.0.0.1, 127.0.0.2\\\u0026#34;,\\n \\\u0026#34;X-Forwarded-Port\\\u0026#34;: \\\u0026#34;443\\\u0026#34;,\\n \\\u0026#34;X-Forwarded-Proto\\\u0026#34;: \\\u0026#34;https\\\u0026#34;\\n },\\n \\\u0026#34;requestContext\\\u0026#34;: {\\n \\\u0026#34;accountId\\\u0026#34;: \\\u0026#34;123456789012\\\u0026#34;,\\n \\\u0026#34;resourceId\\\u0026#34;: \\\u0026#34;123456\\\u0026#34;,\\n \\\u0026#34;stage\\\u0026#34;: \\\u0026#34;prod\\\u0026#34;,\\n \\\u0026#34;requestId\\\u0026#34;: \\\u0026#34;c6af9ac6-7b61-11e6-9a41-93e8deadbeef\\\u0026#34;,\\n \\\u0026#34;requestTime\\\u0026#34;: \\\u0026#34;09/Apr/2015:12:34:56 +0000\\\u0026#34;,\\n \\\u0026#34;requestTimeEpoch\\\u0026#34;: 1428582896000,\\n \\\u0026#34;identity\\\u0026#34;: {\\n \\\u0026#34;cognitoIdentityPoolId\\\u0026#34;: null,\\n \\\u0026#34;accountId\\\u0026#34;: null,\\n \\\u0026#34;cognitoIdentityId\\\u0026#34;: null,\\n \\\u0026#34;caller\\\u0026#34;: null,\\n \\\u0026#34;accessKey\\\u0026#34;: null,\\n \\\u0026#34;sourceIp\\\u0026#34;: \\\u0026#34;127.0.0.1\\\u0026#34;,\\n \\\u0026#34;cognitoAuthenticationType\\\u0026#34;: null,\\n \\\u0026#34;cognitoAuthenticationProvider\\\u0026#34;: null,\\n \\\u0026#34;userArn\\\u0026#34;: null,\\n \\\u0026#34;userAgent\\\u0026#34;: \\\u0026#34;Custom User Agent String\\\u0026#34;,\\n \\\u0026#34;user\\\u0026#34;: null\\n },\\n \\\u0026#34;path\\\u0026#34;: \\\u0026#34;/prod/path/to/resource\\\u0026#34;,\\n \\\u0026#34;resourcePath\\\u0026#34;: \\\u0026#34;/{proxy+}\\\u0026#34;,\\n \\\u0026#34;httpMethod\\\u0026#34;: \\\u0026#34;POST\\\u0026#34;,\\n \\\u0026#34;apiId\\\u0026#34;: \\\u0026#34;1234567890\\\u0026#34;,\\n \\\u0026#34;protocol\\\u0026#34;: \\\u0026#34;HTTP/1.1\\\u0026#34;\\n }\\n}\u0026#34;} 8END RequestId: 61c9bf38-f46f-4906-9c25-0d5f77bac250 9REPORT RequestId: 61c9bf38-f46f-4906-9c25-0d5f77bac250\tInit Duration: 0.07 ms\tDuration: 171.48 ms\tBilled Duration: 172 ms\tMemory Size: 128 MB\tMax Memory Used: 128 MB 10{\u0026#34;statusCode\u0026#34;: 200, \u0026#34;body\u0026#34;: \u0026#34;{\\\u0026#34;message\\\u0026#34;:\\\u0026#34;hello world\\\u0026#34;}\u0026#34;} ","date":"September 20, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/sam-part2-local-testing/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"},{"title":"SAM","url":"/tags/sam/"}],"timestamp":1695168000,"title":"SAM Part2: 地端測試"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"SAM Initialization 這邊使用 sam init 來初始化專案。\n1$ sam init 2 3You can preselect a particular runtime or package type when using the `sam init` experience. 4Call `sam init --help` to learn more. 5 6Which template source would you like to use? 7\t1 - AWS Quick Start Templates 8\t2 - Custom Template Location 9Choice: 1 10 11Choose an AWS Quick Start application template 12\t1 - Hello World Example 13\t2 - Data processing 14\t3 - Hello World Example with Powertools for AWS Lambda 15\t4 - Multi-step workflow 16\t5 - Scheduled task 17\t6 - Standalone function 18\t7 - Serverless API 19\t8 - Infrastructure event management 20\t9 - Lambda Response Streaming 21\t10 - Serverless Connector Hello World Example 22\t11 - Multi-step workflow with Connectors 23\t12 - GraphQLApi Hello World Example 24\t13 - Full Stack 25\t14 - Lambda EFS example 26\t15 - Hello World Example With Powertools for AWS Lambda 27\t16 - DynamoDB Example 28\t17 - Machine Learning 29Template: 1 30 31# 目前官方預設最常用的語言開發事 Python ，所以要選擇 N 以後，才可以選其他語言 32Use the most popular runtime and package type? (Python and zip) [y/N]: N 33 34Which runtime would you like to use? 35\t1 - aot.dotnet7 (provided.al2) 36\t2 - dotnet8 37\t3 - dotnet6 38\t4 - go1.x 39\t5 - go (provided.al2) 40\t6 - go (provided.al2023) 41\t7 - graalvm.java11 (provided.al2) 42\t8 - graalvm.java17 (provided.al2) 43\t9 - java21 44\t10 - java17 45\t11 - java11 46\t12 - java8.al2 47\t13 - nodejs20.x 48\t14 - nodejs18.x 49\t15 - nodejs16.x 50\t16 - python3.9 51\t17 - python3.8 52\t18 - python3.12 53\t19 - python3.11 54\t20 - python3.10 55\t21 - ruby3.2 56\t22 - rust (provided.al2) 57\t23 - rust (provided.al2023) 58Runtime: 13 59 60What package type would you like to use? 61\t1 - Zip 62\t2 - Image 63Package type: 1 64 65Based on your selections, the only dependency manager available is npm. 66We will proceed copying the template using npm. 67 68Select your starter template 69\t1 - Hello World Example 70\t2 - Hello World Example TypeScript 71Template: 1 72 73Would you like to enable X-Ray tracing on the function(s) in your application? [y/N]: y 74X-Ray will incur an additional cost. View https://aws.amazon.com/xray/pricing/ for more details 75 76Would you like to enable monitoring using CloudWatch Application Insights? 77For more info, please view https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/cloudwatch-application-insights.html [y/N]: N 78 79Would you like to set Structured Logging in JSON format on your Lambda functions? [y/N]: y 80Structured Logging in JSON format might incur an additional cost. View https://docs.aws.amazon.com/lambda/latest/dg/monitoring-cloudwatchlogs.html#monitoring-cloudwatchlogs-pricing for more details 81 82Project name [sam-app]: 83 84 ----------------------- 85 Generating application: 86 ----------------------- 87 Name: sam-app 88 Runtime: nodejs20.x 89 Architectures: x86_64 90 Dependency Manager: npm 91 Application Template: hello-world 92 Output Directory: . 93 Configuration file: sam-app/samconfig.toml 94 95 Next steps can be found in the README file at sam-app/README.md 96 97 98Commands you can use next 99========================= 100[*] Create pipeline: cd sam-app \u0026amp;\u0026amp; sam pipeline init --bootstrap 101[*] Validate SAM template: cd sam-app \u0026amp;\u0026amp; sam validate 102[*] Test Function in the Cloud: cd sam-app \u0026amp;\u0026amp; sam sync --stack-name {stack-name} --watch 檔案結構 event.json: 用來測試 Labmda 的 app.mjs: Lambda Function 原始碼 package.json: NPM 用來管理 Package 的檔案 test-handler: Lambda Unit Test samconfig.toml: SAM CLI 的設定檔案 template.ymal: Infrastructure as code 架構的定義檔案 1. 2├── README.md 3├── __init__.py 4├── events 5│ └── event.json 6├── hello_world 7│ ├── __init__.py 8│ ├── app.py 9│ └── requirements.txt 10├── samconfig.toml 11├── template.yaml 12└── tests 13 ├── __init__.py 14 ├── integration 15 │ ├── __init__.py 16 │ └── test_api_gateway.py 17 ├── requirements.txt 18 └── unit 19 ├── __init__.py 20 └── test_handler.py Template YAML AWSTemplateFormatVersion: AWS CloudFormation 的 Version Transform: 告訴 CloudFormation 這是 SAM 的格式 YAML Global: 這邊是針對某些服務資源，共同設定，像 Function 的 Tracing: Active 就是對全部的 Lambda 開啟 X-Ray Reousrce: 這邊就是建立 AWS 上的資源， SAM 跟 CloudFormation 的定義有差別，下面會附上簡易差別圖，詳細資訊可參考官網 Type 是 Function 就是我們實際的 Lambda Function CodeUri: 是 resource code 存放位置的路徑 Handler: 這邊是 filename.functionName 的格式 1AWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; 2Transform: AWS::Serverless-2016-10-31 3Description: \u0026gt; 4 sam-app 5 Sample SAM Template for sam-app 6 7Globals: 8 Function: 9 Timeout: 3 10 MemorySize: 128 11 Tracing: Active 12 LoggingConfig: 13 LogFormat: JSON 14 Api: 15 TracingEnabled: true 16Resources: 17 HelloWorldFunction: 18 Type: AWS::Serverless::Function 19 Properties: 20 CodeUri: hello_world/ 21 Handler: app.lambda_handler 22 Runtime: python3.9 23 Architectures: 24 - x86_64 25 Events: 26 HelloWorld: 27 Type: Api 28 Properties: 29 Path: /hello 30 Method: get 31 32Outputs: 33 HelloWorldApi: 34 Description: API Gateway endpoint URL for Prod stage for Hello World function 35 Value: !Sub \u0026#34;https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\u0026#34; 36 HelloWorldFunction: 37 Description: Hello World Lambda Function ARN 38 Value: !GetAtt HelloWorldFunction.Arn 39 HelloWorldFunctionIamRole: 40 Description: Implicit IAM Role created for Hello World function 41 Value: !GetAtt HelloWorldFunctionRole.Arn CloudFormation vs SAM Resource 驗證 Template AWS Sam 提供了 sam validate 去驗證 template 是否有問題\n1$ sam validate 2 3/Users/allen/sam-app/template.yaml is a valid SAM Template 如果我故意在 template 裡面寫沒有存在的 Type，會出現以下錯誤\n1$ sam validate 2 3E0001 Error transforming template: Resource with id [HelloWorldFunction] is invalid. Event with id [HelloWorld] is invalid. Resource dict has missing or invalid value for key Type. Event Type is: Api1. 4/Users/allen/sam-app/template.yaml:1:1 5 6Error: Linting failed. At least one linting rule was matched to the provided template. Lambda Function 1export const lambdaHandler = async (event, context) =\u0026gt; { 2 const response = { 3 statusCode: 200, 4 body: JSON.stringify({ 5 message: \u0026#39;hello world\u0026#39;, 6 }) 7 }; 8 9 return response; 10 }; Build Package 這邊使用 sam build 來建立 package\n1$ sam build 2 3Starting Build use cache 4Manifest file is changed (new hash: c0e83ff3ce1bd02a0c2a7c02974c24ec) or dependency folder (.aws-sam/deps/1d492548-0d35-49f3-af42-0252668aa785) is missing for (HelloWorldFunction), downloading 5dependencies and copying/building source 6Building codeuri: /Users/allen/sam-app/hello-world runtime: nodejs20.x metadata: {} architecture: x86_64 functions: HelloWorldFunction 7 Running NodejsNpmBuilder:NpmPack 8 Running NodejsNpmBuilder:CopyNpmrcAndLockfile 9 Running NodejsNpmBuilder:CopySource 10 Running NodejsNpmBuilder:NpmInstall 11 Running NodejsNpmBuilder:CleanUp 12 Running NodejsNpmBuilder:CopyDependencies 13 Running NodejsNpmBuilder:CleanUpNpmrc 14 Running NodejsNpmBuilder:LockfileCleanUp 15 Running NodejsNpmBuilder:LockfileCleanUp 16 17Build Succeeded 18 19Built Artifacts : .aws-sam/build 20Built Template : .aws-sam/build/template.yaml 21 22Commands you can use next 23========================= 24[*] Validate SAM template: sam validate 25[*] Invoke Function: sam local invoke 26[*] Test Function in the Cloud: sam sync --stack-name {{stack-name}} --watch 27[*] Deploy: sam deploy --guided 接著會在 local 產生 .aws-sam/build 資料夾。 在資料夾中，可以看到 node_modules 的資料，我們定義在 Package.json 的 modules 都會下載到這\n1$ tree .aws-sam/build 2 3.aws-sam/build 4├── HelloWorldFunction 5│ ├── app.mjs 6│ ├── node_modules 7│ │ ├── asynckit 8│ │ │ ├── LICENSE 9│ │ │ ├── README.md 10│ │ │ ├── bench.js 11│ │ │ ├── index.js 12│ │ │ ├── lib 13│ │ │ │ ├── abort.js 14│ │ │ │ ├── async.js 15│ │ │ │ ├── defer.js 16│ │ │ │ ├── iterate.js 17│ │ │ │ ├── readable_asynckit.js 18│ │ │ │ ├── readable_parallel.js 19│ │ │ │ ├── readable_serial.js 20│ │ │ │ ├── readable_serial_ordered.js 21│ │ │ │ ├── state.js 22│ │ │ │ ├── streamify.js 23│ │ │ │ └── terminator.js 24│ │ │ ├── package.json 25│ │ │ ├── parallel.js 26│ │ │ ├── serial.js 27│ │ │ ├── serialOrdered.js 28│ │ │ └── stream.js 29│ │ ├── axios 30│ │ │ ├── CHANGELOG.md 31│ │ │ ├── LICENSE 32│ │ │ ├── MIGRATION_GUIDE.md 33│ │ │ ├── README.md 34│ │ │ ├── SECURITY.md 35│ │ │ ├── dist 36│ │ │ │ ├── axios.js 37│ │ │ │ ├── axios.js.map 38│ │ │ │ ├── axios.min.js 39│ │ │ │ ├── axios.min.js.map 40│ │ │ │ ├── browser 41│ │ │ │ │ ├── axios.cjs 42│ │ │ │ │ └── axios.cjs.map 43│ │ │ │ ├── esm 44│ │ │ │ │ ├── axios.js 45│ │ │ │ │ ├── axios.js.map 46│ │ │ │ │ ├── axios.min.js 47│ │ │ │ │ └── axios.min.js.map 48│ │ │ │ └── node 49│ │ │ │ ├── axios.cjs 50│ │ │ │ └── axios.cjs.map 51│ │ │ ├── index.d.cts 52│ │ │ ├── index.d.ts 53│ │ │ ├── index.js 54│ │ │ ├── lib 55│ │ │ │ ├── adapters 56│ │ │ │ │ ├── README.md 57│ │ │ │ │ ├── adapters.js 58│ │ │ │ │ ├── http.js 59│ │ │ │ │ └── xhr.js 60│ │ │ │ ├── axios.js 61│ │ │ │ ├── cancel 62│ │ │ │ │ ├── CancelToken.js 63│ │ │ │ │ ├── CanceledError.js 64│ │ │ │ │ └── isCancel.js 65│ │ │ │ ├── core 66│ │ │ │ │ ├── Axios.js 67│ │ │ │ │ ├── AxiosError.js 68│ │ │ │ │ ├── AxiosHeaders.js 69│ │ │ │ │ ├── InterceptorManager.js 70│ │ │ │ │ ├── README.md 71│ │ │ │ │ ├── buildFullPath.js 72│ │ │ │ │ ├── dispatchRequest.js 73│ │ │ │ │ ├── mergeConfig.js 74│ │ │ │ │ ├── settle.js 75│ │ │ │ │ └── transformData.js 76│ │ │ │ ├── defaults 77│ │ │ │ │ ├── index.js 78│ │ │ │ │ └── transitional.js 79│ │ │ │ ├── env 80│ │ │ │ │ ├── README.md 81│ │ │ │ │ ├── classes 82│ │ │ │ │ │ └── FormData.js 83│ │ │ │ │ └── data.js 84│ │ │ │ ├── helpers 85│ │ │ │ │ ├── AxiosTransformStream.js 86│ │ │ │ │ ├── AxiosURLSearchParams.js 87│ │ │ │ │ ├── HttpStatusCode.js 88│ │ │ │ │ ├── README.md 89│ │ │ │ │ ├── ZlibHeaderTransformStream.js 90│ │ │ │ │ ├── bind.js 91│ │ │ │ │ ├── buildURL.js 92│ │ │ │ │ ├── callbackify.js 93│ │ │ │ │ ├── combineURLs.js 94│ │ │ │ │ ├── cookies.js 95│ │ │ │ │ ├── deprecatedMethod.js 96│ │ │ │ │ ├── formDataToJSON.js 97│ │ │ │ │ ├── formDataToStream.js 98│ │ │ │ │ ├── fromDataURI.js 99│ │ │ │ │ ├── isAbsoluteURL.js 100│ │ │ │ │ ├── isAxiosError.js 101│ │ │ │ │ ├── isURLSameOrigin.js 102│ │ │ │ │ ├── null.js 103│ │ │ │ │ ├── parseHeaders.js 104│ │ │ │ │ ├── parseProtocol.js 105│ │ │ │ │ ├── readBlob.js 106│ │ │ │ │ ├── speedometer.js 107│ │ │ │ │ ├── spread.js 108│ │ │ │ │ ├── throttle.js 109│ │ │ │ │ ├── toFormData.js 110│ │ │ │ │ ├── toURLEncodedForm.js 111│ │ │ │ │ └── validator.js 112│ │ │ │ ├── platform 113│ │ │ │ │ ├── browser 114│ │ │ │ │ │ ├── classes 115│ │ │ │ │ │ │ ├── Blob.js 116│ │ │ │ │ │ │ ├── FormData.js 117│ │ │ │ │ │ │ └── URLSearchParams.js 118│ │ │ │ │ │ └── index.js 119│ │ │ │ │ ├── common 120│ │ │ │ │ │ └── utils.js 121│ │ │ │ │ ├── index.js 122│ │ │ │ │ └── node 123│ │ │ │ │ ├── classes 124│ │ │ │ │ │ ├── FormData.js 125│ │ │ │ │ │ └── URLSearchParams.js 126│ │ │ │ │ └── index.js 127│ │ │ │ └── utils.js 128│ │ │ └── package.json 129│ │ ├── combined-stream 130│ │ │ ├── License 131│ │ │ ├── Readme.md 132│ │ │ ├── lib 133│ │ │ │ └── combined_stream.js 134│ │ │ ├── package.json 135│ │ │ └── yarn.lock 136│ │ ├── delayed-stream 137│ │ │ ├── License 138│ │ │ ├── Makefile 139│ │ │ ├── Readme.md 140│ │ │ ├── lib 141│ │ │ │ └── delayed_stream.js 142│ │ │ └── package.json 143│ │ ├── follow-redirects 144│ │ │ ├── LICENSE 145│ │ │ ├── README.md 146│ │ │ ├── debug.js 147│ │ │ ├── http.js 148│ │ │ ├── https.js 149│ │ │ ├── index.js 150│ │ │ └── package.json 151│ │ ├── form-data 152│ │ │ ├── License 153│ │ │ ├── README.md.bak 154│ │ │ ├── Readme.md 155│ │ │ ├── index.d.ts 156│ │ │ ├── lib 157│ │ │ │ ├── browser.js 158│ │ │ │ ├── form_data.js 159│ │ │ │ └── populate.js 160│ │ │ └── package.json 161│ │ ├── mime-db 162│ │ │ ├── HISTORY.md 163│ │ │ ├── LICENSE 164│ │ │ ├── README.md 165│ │ │ ├── db.json 166│ │ │ ├── index.js 167│ │ │ └── package.json 168│ │ ├── mime-types 169│ │ │ ├── HISTORY.md 170│ │ │ ├── LICENSE 171│ │ │ ├── README.md 172│ │ │ ├── index.js 173│ │ │ └── package.json 174│ │ └── proxy-from-env 175│ │ ├── LICENSE 176│ │ ├── README.md 177│ │ ├── index.js 178│ │ ├── package.json 179│ │ └── test.js 180│ └── package.json 181└── template.yaml ","date":"August 9, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/sam-part1-init-node-project/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"},{"title":"SAM","url":"/tags/sam/"}],"timestamp":1691539200,"title":"SAM Part1: Node 專案初始化"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"什麼是無伺服器服務 無伺服器服務是一種雲的架構，將應用程式的部署和管理抽象化，讓開發者可以專心的開發應用程式。\n以下圖為例 On Premise（本地部署）： 在本地部署模式下，所有的硬體和軟體都由自己和管理。 需要負責硬體的購買、配置、維護和更新，以及軟體的安裝、配置和更新。 本地部署提供了最大的控制權，但也需要更多的資源和成本進行管理和維護。 Infrastructure as a service/IaaS（基礎設施即服務） 在IaaS模式下，雲供應商提供虛擬化的計算資源，包括虛擬機器、儲存空間和網路。 使用者可以通過雲端管理控制台或API來管理這些計算資源，包括啟動、停止、調整規模等操作。 使用者負責管理操作系統和應用程式層面的配置和維護，雲端服務提供商負責底層基礎設施的管理。 Exampple: AWS EC2 Platform as a Service/PaaS（平台即服務) 雲供商不僅提供基礎設施，還提供了開發工具、執行環境和相關服務，使開發者能夠更快地構建、部署和管理應用程式。 Example: Elastic Beanstalk Serverless（無伺服器） 在無伺服器模式下，開發者只需上傳程式碼到雲端服務平台，而不需要關心伺服器的配置、管理和維護。 雲端服務平台會根據實際需求來分配計算資源，並且按照使用量來計費，使開發者只需為實際使用的資源付費。 什麼是 AWS Lambda Lambda 是 AWS 的無服務器服務，基於 Event-driven Architectures，當有一個事件(Event) 進來時，AWS 才會動態的啟動所需的運算服務，並將事先準備好的程式部署到上面去運行。 一個是事件可以是一個來自 API Gateway 的請求，或者是 S3 流出的事件，再者也可以是 CloudWatch Scheduler 排程排好的。\nLambda 的好處 自動擴展 Scalability AWS 會根據當下並行的請求數量，來自己決定 Auto Scaling ，所以在沒有請求的情況下，甚至是可以不需要有任何運算服務 依用量計價 AWS 是根據運行的時間（毫秒）來計價，所以如上面的自動擴展來說，在沒有任何運算服務的時候，可以不用付任何錢給 AWS 無須管理伺服器 所有的硬體，操作系統等維護，都交由 AWS 管理。我們只需專注在開發上面就好。而且 AWS 確保 Lambda 的高可用性和容錯性。 快速進入市場 由於 Lambda 讓開發者只需專注於 軟體(Function) 的開發，而且也省掉了硬體的購買時間，所以讓一個服務在短短幾分鐘內，就上到互聯網上供人使用。 Lambda 計價 Lambda 只可以設定 RAM 的大小，而隨著 RAM 的大小，是會影響 CPU 的，而不同 RAM 的大小，收費價格也不同，已下圖東京為例，我們可以看到隨著 RAM 越多，每毫秒的價格也越貴。\n所以 Lambda 的 RAM 開得越高，執行的當然也越快，但這就必非代表越便宜喔！因為計算的價格是不一樣的，我們需要根據每個 Lambda 分析，取得最佳值，不然有可能會白白浪費錢！\n已下圖為例\nRAM 128 MB，雖然每秒比較便宜，但執行時間過久 RAM 1024 MB 以後，執行時間的並沒有在明顯的變快，反而讓帳單變更貴而已 RAM 512 幾乎是效能 Cost 最低，效能還不錯的 這邊可以用官方的計算器來初估花費\n網上也許有多大神開發的工具可以使用，例如由 Alex Casalboni 開發的 aws-lambda-power-tuning\n","date":"June 7, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/what-is-lambda/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"}],"timestamp":1686096000,"title":"什麼是 AWS Lambda"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"以前當我第一次接觸 AWS Lambda Function 時，是在上 AWS Training 課程，使用 AWS Console 建立了一隻 Hello World。而 SAM (Serverless Application Model) 是一個開源的程式，主要在 CloudFormation 的基礎上擴展，專門用來開發 Serverless Application。我們可以透過 YAML 去定義我們的系統架構 像是 Endpoint 由哪個handler 處理，額外的 database (DynamoDB) 等等。這次的文章，主要是介紹使用 SAM 建立一個 Java Hello World 的 Lambda Function。\n事前準備 一個 AWS 帳號 安裝 AWS CLI 並 設定好，SAM 的權限是根據 AWS CLI喔！所以 SAM 不用額外設定 Access Key ID \u0026amp; Secret Access Key Mac \u0026amp; Linux 可以透過 pip 安裝，其他可以參考這篇官網安裝教學 如果不知道如何獲取 Access Key ID \u0026amp; Secret Access Key 可以參考這篇官網設定 1# 安裝 AWS CLI 2$ pip install awscli 3 4# 確認 AWS CLI 安裝成功 5$ aws --version 6 aws-cli/1.19.105 Python/2.7.16 Darwin/20.4.0 botocore/1.20.105 7 8 # AWS CLI 設定 9 $ aws configure 10 AWS Access Key ID [****************ASFC]: 11 AWS Secret Access Key [****************fM7z]: 12 Default region name [ap-northeast-1]: 13 Default output format [json]: Java11 JDK \u0026amp; Maven，這邊可以透過 Brew 安裝，如何安裝 Brew 看官網教學 1# 安裝 open jdk11 2$ brew install openjdk@11 3# 確認 Java JDK 安裝成功 4$ java -version 5 openjdk version \u0026#34;11.0.10\u0026#34; 2021-01-19 6 OpenJDK Runtime Environment (build 11.0.10+9) 7 OpenJDK 64-Bit Server VM (build 11.0.10+9, mixed mode) 8 9# 安裝 maven 10$ brew install maven 11# 確認 Maven 安裝成功 12$ mvn -version 13 Apache Maven 3.8.1 (05c21c65bdfed0f71a2f2ada8b84da59348c4c5d) 14 Maven home: /usr/local/Cellar/maven/3.8.1/libexec 15 Java version: 11.0.10, vendor: Oracle Corporation, runtime: /usr/local/Cellar/openjdk@11/11.0.10/libexec/openjdk.jdk/Contents/Home 16 Default locale: zh_TW_#Hant, platform encoding: UTF-8 17 OS name: \u0026#34;mac os x\u0026#34;, version: \u0026#34;11.3.1\u0026#34;, arch: \u0026#34;x86_64\u0026#34;, family: \u0026#34;mac\u0026#34; Docker ，由於 Docker 安裝比較麻煩，這邊就不寫安裝方式，我個人 MAC 是安裝 Docker Desktop 1$ docker --version 2 Docker version 20.10.7, build f0df350 今日主角，SAM CLI，這邊也是透過 Brew 去安裝 1# 安裝 SAM CLI 2$ brew tap aws/tap 3$ brew install aws-sam-cli 4# 確認 SAM CLI 安裝成功 5$ sam --version 6 SAM CLI, version 1.25.0 SAM 初始化專案 1$ sam init -r java11 -d maven --app-template hello-world -n demo 2 3# -r : --runtime 的縮寫，執行環境的語言，這邊指定 java11 4# -d : --dependency-manager 的縮寫(軟體套件管理系統)，這邊指定 maven 5# --app-template : 官方已經有寫好一些 template 提供大家使用 6# -n : --name 的縮寫，這個專案的名稱 7 8# 如果想瞭解更多參數，和每個參數可以設定的選項，可以使用 9$ sam init help 透過 SAM 初始化，會建立以下的檔案\n1$ tree 2 . 3 ├── HelloWorldFunction 4 │ ├── pom.xml 5 │ └── src 6 │ ├── main 7 │ │ └── java 8 │ │ └── helloworld 9 │ │ └── App.java 10 │ └── test 11 │ └── java 12 │ └── helloworld 13 │ └── AppTest.java 14 ├── README.md 15 ├── events 16 │ └── event.json 17 └── template.yaml Template.yaml 是我們設定 Resource 相關的資訊，由於太多這篇就不一一介紹，這邊會在產生出來的 Code 加一些簡單註解\n1AWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; 2Transform: AWS::Serverless-2016-10-31 3Description: \u0026gt; 4 demo 5 6 Sample SAM Template for demo 7 8Globals: 9 Function: 10 Timeout: 20 11 12Resources: 13 HelloWorldFunction: 14 Type: AWS::Serverless::Function # 這邊是指 Lambda Function 15 Properties: 16 CodeUri: HelloWorldFunction 17 Handler: helloworld.App::handleRequest # 這邊指定 Handler 18 #helloworld : java package 19 #App : class name 20 #handleRequest : handle request method 21 Runtime: java11 22 MemorySize: 512 23 Environment: # 可以設定系統環境的地方 24 Variables: 25 PARAM1: VALUE 26 Events: # Trigger 這個 Lambda Function 的 Event 27 HelloWorld: 28 Type: Api # Event 是由 API Gateway 來的 29 Properties: 30 Path: /hello # Api Gateway Endpoint 31 Method: get # Http Method 32 33#Outputs 就請參考 CloudFormation 34Outputs: 35 HelloWorldApi: 36 Description: \u0026#34;API Gateway endpoint URL for Prod stage for Hello World function\u0026#34; 37 Value: !Sub \u0026#34;https://${ServerlessRestApi}.execute-api.${AWS::Region}.amazonaws.com/Prod/hello/\u0026#34; 38 HelloWorldFunction: 39 Description: \u0026#34;Hello World Lambda Function ARN\u0026#34; 40 Value: !GetAtt HelloWorldFunction.Arn 41 HelloWorldFunctionIamRole: 42 Description: \u0026#34;Implicit IAM Role created for Hello World function\u0026#34; 43 Value: !GetAtt HelloWorldFunctionRole.Arn 這邊順便介紹主要處理邏輯的 Handler\n1package helloworld; 2 3import java.io.BufferedReader; 4import java.io.IOException; 5import java.io.InputStreamReader; 6import java.net.URL; 7import java.util.HashMap; 8import java.util.Map; 9import java.util.stream.Collectors; 10 11import com.amazonaws.services.lambda.runtime.Context; 12import com.amazonaws.services.lambda.runtime.RequestHandler; 13import com.amazonaws.services.lambda.runtime.events.APIGatewayProxyRequestEvent; 14import com.amazonaws.services.lambda.runtime.events.APIGatewayProxyResponseEvent; 15 16/** 17 * Handler for requests to Lambda function. 18 */ 19public class App implements RequestHandler\u0026lt;APIGatewayProxyRequestEvent, APIGatewayProxyResponseEvent\u0026gt; { 20 21 public APIGatewayProxyResponseEvent handleRequest(final APIGatewayProxyRequestEvent input, final Context context) { 22 // response 的 header 23 Map\u0026lt;String, String\u0026gt; headers = new HashMap\u0026lt;\u0026gt;(); 24 headers.put(\u0026#34;Content-Type\u0026#34;, \u0026#34;application/json\u0026#34;); 25 headers.put(\u0026#34;X-Custom-Header\u0026#34;, \u0026#34;application/json\u0026#34;); 26 27 APIGatewayProxyResponseEvent response = new APIGatewayProxyResponseEvent() 28 .withHeaders(headers); 29 try { 30 // call amanzon api 取得系統 IP 31 final String pageContents = this.getPageContents(\u0026#34;https://checkip.amazonaws.com\u0026#34;); 32 33 // response body 34 String output = String.format(\u0026#34;{ \\\u0026#34;message\\\u0026#34;: \\\u0026#34;hello world\\\u0026#34;, \\\u0026#34;location\\\u0026#34;: \\\u0026#34;%s\\\u0026#34; }\u0026#34;, pageContents); 35 36 return response 37 .withStatusCode(200) 38 .withBody(output); 39 } catch (IOException e) { 40 return response 41 .withBody(\u0026#34;{}\u0026#34;) 42 .withStatusCode(500); 43 } 44 } 45 46 private String getPageContents(String address) throws IOException{ 47 URL url = new URL(address); 48 try(BufferedReader br = new BufferedReader(new InputStreamReader(url.openStream()))) { 49 return br.lines().collect(Collectors.joining(System.lineSeparator())); 50 } 51 } 52} 所以從以上來看，這邊就是透過 Template.yaml 去指定 環境執行語言， API Endpoint 和 Handler 等等重要資訊。而 App.java 就是我們 Lambda Function 主要計算邏輯。目前透過這兩個 File 就可以產生出基本的 get hello 函示。\n這邊要注意，hello-world Template 建立出的 pom 檔，裡面指定的 Compile Source 是 1.8 ，這邊建議改成 Java 11\n1\u0026lt;properties\u0026gt; 2 \u0026lt;maven.compiler.source\u0026gt;11\u0026lt;/maven.compiler.source\u0026gt; 3 \u0026lt;maven.compiler.target\u0026gt;11\u0026lt;/maven.compiler.target\u0026gt; 4\u0026lt;/properties\u0026gt; SAM 本地測試 SAM 我個人覺得最方便的就是，它使用了 Docker 的技術，讓我們可以在本地也可以建立起一個環境做測試 API\n1$ sam local start-api 2 3 Mounting HelloWorldFunction at http://127.0.0.1:3000/hello [GET] 4 You can now browse to the above endpoints to invoke your functions. You do not need to restart/reload SAM CLI while working on your functions, changes will be reflected instantly/automatically. You only need to restart SAM CLI if you update your AWS SAM template 5 2021-07-03 19:40:16 * Running on http://127.0.0.1:3000/ (Press CTRL+C to quit) 從上面的 Output 可以看到，起了一個環境，並聽本地的3000 port，這邊會在開另一個terminal 來測試 curl 來測試結果\n1$ curl -v http://127.0.0.1:3000/hello 2 * Trying 127.0.0.1... 3 * TCP_NODELAY set 4 * Connected to 127.0.0.1 (127.0.0.1) port 3000 (#0) 5 \u0026gt; GET /hello HTTP/1.1 6 \u0026gt; Host: 127.0.0.1:3000 7 \u0026gt; User-Agent: curl/7.64.1 8 \u0026gt; Accept: */* 9 \u0026gt; 10 * HTTP 1.0, assume close after body 11 \u0026lt; HTTP/1.0 200 OK 12 \u0026lt; X-Custom-Header: application/json 13 \u0026lt; Content-Type: application/json 14 \u0026lt; Content-Length: 57 15 \u0026lt; Server: Werkzeug/1.0.1 Python/3.8.11 16 \u0026lt; Date: Sat, 03 Jul 2021 11:47:10 GMT 17 \u0026lt; 18 * Closing connection 0 19 { \u0026#34;message\u0026#34;: \u0026#34;hello world\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;114.44.114.30\u0026#34; } 在原本的 Terminal 可以看到以下資訊\n1Mounting /Users/allen/demo/.aws-sam/build/HelloWorldFunction as /var/task:ro,delegated inside runtime container 2 END RequestId: 74bd804b-096b-473b-9c3f-2ba1cd847431 3 REPORT RequestId: 74bd804b-096b-473b-9c3f-2ba1cd847431 Init Duration: 0.37 ms Duration: 2255.80 ms Billed Duration: 2300 ms Memory Size: 512 MB Max Memory Used: 512 MB 4 2021-07-03 19:44:13 127.0.0.1 - - [03/Jul/2021 19:44:13] \u0026#34;GET /hello HTTP/1.1\u0026#34; 200 - Sam 也可以直接一次性的執行某個 Function\n1$ sam local invoke \u0026#34;HelloWorldFunction\u0026#34; 2 Invoking helloworld.App::handleRequest (java11) 3 Skip pulling image and use local one: amazon/aws-sam-cli-emulation-image-java11:rapid-1.25.0. 4 5 6 Mounting /Users/allen/demo/.aws-sam/build/HelloWorldFunction as /var/task:ro,delegated inside runtime container 7 END RequestId: 70223332-2a37-4094-bdf2-aa924df0d416 8 REPORT RequestId: 70223332-2a37-4094-bdf2-aa924df0d416 Init Duration: 0.29 ms Duration: 2153.55 ms Billed Duration: 2200 ms Memory Size: 512 MB Max Memory Used: 512 MB 9 {\u0026#34;statusCode\u0026#34;:200,\u0026#34;headers\u0026#34;:{\u0026#34;X-Custom-Header\u0026#34;:\u0026#34;application/json\u0026#34;,\u0026#34;Content-Type\u0026#34;:\u0026#34;application/json\u0026#34;},\u0026#34;body\u0026#34;:\u0026#34;{ \\\u0026#34;message\\\u0026#34;: \\\u0026#34;hello world\\\u0026#34;, \\\u0026#34;location\\\u0026#34;: \\\u0026#34;114.44.114.30\\\u0026#34; }\u0026#34;} SAM 部署到 AWS 這邊可以透過 sam deploy –guided Deploy 到 AWS 上面，由於內容資訊比較多，所以這邊用圖片的方式，在第一次執行時這邊會需要填寫一些預設資料。\n在填完預設資料後，SAM會一直執行，直到要你確認這次 Deploy 的改動 CloudFormation 的 changeset\nCloudFormation 這時候會卡在 REVIEW_IN_PROGRESS\n這時Change Set 同意以後，這時看 CloudFormation 會正在建立 Resource， Status 是 CREATE_IN_PROGRESS\nSAM CLI 在 Deploy 完以後，會看到類似以下資訊\n可以在 API Gateway 看到新的 Endpoint\n也可以在 Lambda 看到 HelloWorld Lambda Function 建立好了\n1$ curl -v https://rla530b9o1.execute-api.ap-northeast-1.amazonaws.com/Prod/hello/ 2 * Trying 13.35.7.43... 3 * TCP_NODELAY set 4 * Connected to rla530b9o1.execute-api.ap-northeast-1.amazonaws.com (13.35.7.43) port 443 (#0) 5 * ALPN, offering h2 6 * ALPN, offering http/1.1 7 * successfully set certificate verify locations: 8 * CAfile: /etc/ssl/cert.pem 9 CApath: none 10 * TLSv1.2 (OUT), TLS handshake, Client hello (1): 11 * TLSv1.2 (IN), TLS handshake, Server hello (2): 12 * TLSv1.2 (IN), TLS handshake, Certificate (11): 13 * TLSv1.2 (IN), TLS handshake, Server key exchange (12): 14 * TLSv1.2 (IN), TLS handshake, Server finished (14): 15 * TLSv1.2 (OUT), TLS handshake, Client key exchange (16): 16 * TLSv1.2 (OUT), TLS change cipher, Change cipher spec (1): 17 * TLSv1.2 (OUT), TLS handshake, Finished (20): 18 * TLSv1.2 (IN), TLS change cipher, Change cipher spec (1): 19 * TLSv1.2 (IN), TLS handshake, Finished (20): 20 * SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256 21 * ALPN, server accepted to use h2 22 * Server certificate: 23 * subject: CN=*.execute-api.ap-northeast-1.amazonaws.com 24 * start date: May 17 00:00:00 2021 GMT 25 * expire date: Jun 15 23:59:59 2022 GMT 26 * subjectAltName: host \u0026#34;rla530b9o1.execute-api.ap-northeast-1.amazonaws.com\u0026#34; matched cert\u0026#39;s \u0026#34;*.execute-api.ap-northeast-1.amazonaws.com\u0026#34; 27 * issuer: C=US; O=Amazon; OU=Server CA 1B; CN=Amazon 28 * SSL certificate verify ok. 29 * Using HTTP2, server supports multi-use 30 * Connection state changed (HTTP/2 confirmed) 31 * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 32 * Using Stream ID: 1 (easy handle 0x7f9298809200) 33 \u0026gt; GET /Prod/hello/ HTTP/2 34 \u0026gt; Host: rla530b9o1.execute-api.ap-northeast-1.amazonaws.com 35 \u0026gt; User-Agent: curl/7.64.1 36 \u0026gt; Accept: */* 37 \u0026gt; 38 * Connection state changed (MAX_CONCURRENT_STREAMS == 128)! 39 40 41 \u0026lt; HTTP/2 200 42 \u0026lt; content-type: application/json 43 \u0026lt; content-length: 58 44 \u0026lt; date: Sat, 03 Jul 2021 14:28:53 GMT 45 \u0026lt; x-amzn-requestid: fa2fb89a-5379-4167-b13c-0a59269f71e0 46 \u0026lt; x-amz-apigw-id: B5cU7GWTNjMFc6A= 47 \u0026lt; x-custom-header: application/json 48 \u0026lt; x-amzn-trace-id: Root=1-60e0741f-7e93aac373f51300700bbc59;Sampled=0 49 \u0026lt; x-cache: Miss from cloudfront 50 \u0026lt; via: 1.1 260a465bf4779e35dde8adbb89981df1.cloudfront.net (CloudFront) 51 \u0026lt; x-amz-cf-pop: TPE52-C1 52 \u0026lt; x-amz-cf-id: aGy5WF0naNegGjNJM1kaZpBnl5SDcg23eZMy8wYUrd0sxyQnHLnhgg== 53 \u0026lt; 54 * Connection #0 to host rla530b9o1.execute-api.ap-northeast-1.amazonaws.com left intact 55 { \u0026#34;message\u0026#34;: \u0026#34;hello world\u0026#34;, \u0026#34;location\u0026#34;: \u0026#34;13.231.109.123\u0026#34; }* Closing connection 0 清理 Sam 建立好的 AWS 環境 如果大家有 Deploy 到 AWS 上，最後記得要把 CloudFormation 建立出來的環境給刪除，以免產生額外的費用。這邊可以直接到 AWS CloudFormation 把 Stack 給刪除，或者使用 AWS CLI\n1$ aws cloudformation delete-stack --stack-name demo 這邊要注意一下， SAM 會建立一個 S3 當作 Artifact ，所以需要先把 S3 裡面的資料手動清掉才可以 delete stack，否則 stack 會刪除失敗。以下是S3 沒有清空時的範例圖\n","date":"June 3, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/build-aws-lambda-hello-world-function-by-sam/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"},{"title":"CloudFormation","url":"/tags/cloudformation/"},{"title":"SAM","url":"/tags/sam/"}],"timestamp":1685750400,"title":"Build AWS Lambda Hello World Function by SAM"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"個人用戶管理對於許多網站 或 App 都是不可缺少的，大家有可能會經常煩惱要怎麼樣讓自己的服務，可以透過 Google 、Facebook 等第三方認證，或者擁有自己的使用者群。這時可以選擇考慮 AWS Cognito，它可以讓你快速的為你的服務建立使用者群，並且可以整合讓使用者擁有權限操作其他 AWS 服務 。由於使用 UI 建立 Cognito User Pool 的文章已經不少，所以這邊文章會介紹使用 AWS CLI cognito-idp 建立一個用戶可以註冊，並且自己透過 Mail 認證通過的 User Pool。\n前置作業 AWS CLI AWS SES 驗證過的 Email 透過 AWS Console 設定 SES Step1 註冊 SES Mail 這邊要注意，Cognito 目前允許的 SES Region 只有三個，分別是 us-east-1、us-east-2、eu-west-1。所以在建立 Email 時，請確認要別確認 Region 喔，不然之後有可能會無法設定喔\n請到 SES 下面，點選 Email Address，然後點下 Verify a New Email Address，並填寫你的 Mail\n當你填完以後，這時可以你的 Email 在 list 中，而 Verification Status 還會在 Pending 喔～ AWS 會寄 Mail 到你的郵箱，請去填寫的 Email 認證。\nStep2 驗證 Mail 這時候當入剛剛輸入的 Mail 中，應該會有一封 Email Address Verification Request 的 Mail ，這時候請點選裡面的 Link 完成驗證\nStep3 確認信箱已驗證 這時候重新進入 SES 頁面，會發現 Verification Status 是 verified\n如果你也在嘗試練習，請點選 UI 的 Email ，這時候可以看到 Identity ARN。請將 Identity ARN 記錄下來，後面建立 User Pool 會使用到。\n使用 AWS CLI cognito-idp 建立 User Pool \u0026 Client aws cognito-idp command 主要是讓我們來管理 User Pool 的，裡面有分兩種不同的 level 的 command ，分別是 ADMIN 和 一般 User 的， 所有 admin 的 command 都會是 admin- 開頭的。以下是附上 AWS 官方的圖片，一開始 User 在 Cognito 註冊是在 已註冊狀態(Registered) 是不能 Login 的，必須要是認證狀態(Confirmed) ，才能 Login。而目前只有兩種方式才能讓 User 變成認證的，第一種就是由 ADMIN 這邊認證，而第二種就是 User 可以自己認證透過電話或 Mail。這邊要示範透過 Mail 認證\nStep1 使用 AWS cognito-idp 列出目前所擁有的 User Pool 使用 list-user-pools command 列出目前擁有的全部 User Pool，目前艾倫的 User Pool 都已經清空，所以沒有。\n1$ aws cognito-idp list-user-pools --max-results 10 2 3#Result 4{ 5 \u0026#34;UserPools\u0026#34;: [] 6} Step2 使用 cognito-idp 建立 User Pool 如果正在使用這邊文章做範例請紀錄 ID，後面建立 Client 需要使用\n這邊使用 create-user-pool command\n\u0026ndash;pool-name User Pool 的名字 \u0026ndash;auto-verified-attributes 想要驗證的欄位，這邊是 Mail \u0026ndash;username-attributes 這邊特別指定 User Name 可以透過 Email 替代 ，這邊可以不強制 User Name 使用 Email，也可以讓 User 自定義自己的 Uesr Id \u0026ndash;email-configuration 這邊要定義 Cognito 寄出的 Mail Server，艾倫這邊使用 SES 寄出，SourceArn 記得改成你的 SES ARN 這邊的 Result 由於太長，所以艾倫有做一些刪減。Result 中的 VerificationMessageTemplate ，裡面寫 CONFIRM_WITH_CODE， 當 User Sign up 時， Cognito 會產生一組驗證碼寄送到 Mail 中，這樣 User 就可以使用驗證碼來自己驗證。另外可以看到下面 PasswordPolicy，至少要一個大小寫英文字母，並且要有符號和數字，最後長度必須要八以上，這些條件都是可以客製化的，不過可以看到，艾倫在建立 User Pool 時，沒有帶入特定參數，所以這些目前是使用預設的。\n1$ aws cognito-idp create-user-pool \\ 2 --pool-name helloWorld \\ 3 --auto-verified-attributes email \\ 4 --username-attributes \u0026#34;email\u0026#34; \\ 5 --email-configuration=SourceArn=\u0026#34;arn:aws:ses:us-east-1:129824596365:identity/allen.hsieh.aws@gmail.com\u0026#34;,ReplyToEmailAddress=\u0026#34;allen.hsieh.aws@gmail.com\u0026#34; 6 7# Result 8{ 9 \u0026#34;UserPool\u0026#34;: { 10 \u0026#34;Name\u0026#34;: \u0026#34;helloWorld\u0026#34;, 11 \u0026#34;VerificationMessageTemplate\u0026#34;: { 12 \u0026#34;DefaultEmailOption\u0026#34;: \u0026#34;CONFIRM_WITH_CODE\u0026#34; 13 }, 14 \u0026#34;EmailConfiguration\u0026#34;: { 15 \u0026#34;EmailSendingAccount\u0026#34;: \u0026#34;COGNITO_DEFAULT\u0026#34;, 16 \u0026#34;ReplyToEmailAddress\u0026#34;: \u0026#34;allen.hsieh.aws@gmail.com\u0026#34;, 17 \u0026#34;SourceArn\u0026#34;: \u0026#34;arn:aws:ses:us-east-1:129824596365:identity/allen.hsieh.aws@gmail.com\u0026#34; 18 }, 19 \u0026#34;Policies\u0026#34;: { 20 \u0026#34;PasswordPolicy\u0026#34;: { 21 \u0026#34;RequireNumbers\u0026#34;: true, 22 \u0026#34;RequireLowercase\u0026#34;: true, 23 \u0026#34;RequireSymbols\u0026#34;: true, 24 \u0026#34;RequireUppercase\u0026#34;: true, 25 \u0026#34;TemporaryPasswordValidityDays\u0026#34;: 7, 26 \u0026#34;MinimumLength\u0026#34;: 8 27 } 28 }, 29 \u0026#34;Id\u0026#34;: \u0026#34;ap-northeast-1_DpExb5BW8\u0026#34;, \u0026#34;Arn: \u0026#34;arn:aws:cognito-idp:ap-northeast-1:129824596365:userpool/ap-northeast-1_DpExb5BW8\u0026#34; 30} Step3 確認 User Pool 再次使用 Step1 的 list-user-pools Command，這時後會看到 User Pool。\n1$ aws cognito-idp list-user-pools --max-results 10 2 3# Result 4 { 5 \u0026#34;UserPools\u0026#34;: [ 6 { 7 \u0026#34;CreationDate\u0026#34;: 1625996882.861, 8 \u0026#34;LastModifiedDate\u0026#34;: 1625996882.861, 9 \u0026#34;LambdaConfig\u0026#34;: {}, 10 \u0026#34;Id\u0026#34;: \u0026#34;ap-northeast-1_DpExb5BW8\u0026#34;, 11 \u0026#34;Name\u0026#34;: \u0026#34;helloWorld\u0026#34; 12 } 13 ] 14 } Step4 建立 User Pool 的 Client 一個 User Pool 可以有多個 Client ，例如想要區分 App, Web 等等\n如果正在使用這邊文章做範例請紀錄 ClientId，後面建立 User 需要使用\n\u0026ndash;user-pool-id 這邊需要 Step3 or Step2 的 ID (User Pool 的 ID) \u0026ndash;explicit-auth-flows 特別指定驗證方式， USER_PASSWORD_AUTH 是同意使用 User \u0026amp; Password 去做驗證，這邊是因為後面方便要 Demo 使用 Cli 去做 Login 的關係，否則正式環境 App 建議使用 (SRP)[https://docs.aws.amazon.com/cognito/latest/developerguide/amazon-cognito-user-pools-authentication-flow.html] 驗證。 \u0026ndash;client-name: Client 的名字 1$ aws cognito-idp create-user-pool-client \\ 2 --user-pool-id ap-northeast-1_DpExb5BW8 \\ 3 --explicit-auth-flows USER_PASSWORD_AUTH \\ 4 --client-name cli 5 6# Result 7{ 8 \u0026#34;UserPoolClient\u0026#34;: { 9 \u0026#34;UserPoolId\u0026#34;: \u0026#34;ap-northeast-1_DpExb5BW8\u0026#34;, 10 \u0026#34;LastModifiedDate\u0026#34;: 1625999636.182, 11 \u0026#34;ClientId\u0026#34;: \u0026#34;400d11al9p25pmjg3igflo5h4i\u0026#34;, 12 \u0026#34;AllowedOAuthFlowsUserPoolClient\u0026#34;: false, 13 \u0026#34;TokenValidityUnits\u0026#34;: {}, 14 \u0026#34;ExplicitAuthFlows\u0026#34;: [ 15 \u0026#34;USER_PASSWORD_AUTH\u0026#34; 16 ], 17 \u0026#34;RefreshTokenValidity\u0026#34;: 30, 18 \u0026#34;CreationDate\u0026#34;: 1625999636.182, 19 \u0026#34;EnableTokenRevocation\u0026#34;: true, 20 \u0026#34;ClientName\u0026#34;: \u0026#34;cli\u0026#34; 21 } 建立 \u0026 驗證新 User 這邊需要使用建立 Client 時的 Client Id ，如果忘了拷貝下來，可以使用 list-user-pool-clients 取得。\n1$ aws cognito-idp list-user-pool-clients --user-pool-id ap-northeast-1_DpExb5BW8 2 3# Result 4 { 5 \u0026#34;UserPoolClients\u0026#34;: [ 6 { 7 \u0026#34;ClientName\u0026#34;: \u0026#34;cli\u0026#34;, 8 \u0026#34;UserPoolId\u0026#34;: \u0026#34;ap-northeast-1_DpExb5BW8\u0026#34;, 9 \u0026#34;ClientId\u0026#34;: \u0026#34;400d11al9p25pmjg3igflo5h4i\u0026#34; 10 } 11 ] 12 } Step1 建立新 User \u0026ndash;client-id 從 Create Client 時拿掉 \u0026ndash;username 這邊要填寫 User Name ，由於艾倫建立的 User Pool 強制要求需要使用 Email 當 User Name，所以要使用 Email 喔 \u0026ndash;password 密碼，記得要 Follow 之前的 PasswordPolicy 1$ aws cognito-idp sign-up \\ 2 --client-id 400d11al9p25pmjg3igflo5h4i \\ 3 --username allen.hsieh.aws@gmail.com \\ 4 --password Aa123456! 5 6# Result 7{ 8 \u0026#34;UserConfirmed\u0026#34;: false, 9 \u0026#34;UserSub\u0026#34;: \u0026#34;c57c5fb9-7fbd-406d-9bb3-19f88cfc9ac0\u0026#34;, 10 \u0026#34;CodeDeliveryDetails\u0026#34;: { 11 \u0026#34;AttributeName\u0026#34;: \u0026#34;email\u0026#34;, 12 \u0026#34;Destination\u0026#34;: \u0026#34;a***@g***.com\u0026#34;, 13 \u0026#34;DeliveryMedium\u0026#34;: \u0026#34;EMAIL\u0026#34; 14 } 15 } 這時後透過 AWS Console 進入 User Pool 裡面的 Users \u0026amp; Groups 裡面，可以看到剛剛註冊的用戶，這邊可以看到 Account Status 是 UNCONFIRMED\nStep2 嘗試 Login Step1 註冊 Command 是 Sign-up，這邊是驗證，而並非登入，所以 Command 不是 Login ，而是 initiate-auth\n\u0026ndash;auth-flow 驗證方式，這邊使用 USER_PASSWORD_AUTH 單純使用 UserName \u0026amp; Password 。 這邊要特別注意， Client 必須要 Allow 可以使用 USER_PASSWORD_AUTH，艾倫在 Create Client 時有特別特定\n\u0026ndash;auth-parameters 這邊是 USERNAME \u0026amp; PASSWORD 結果會是噴 Exception ，原因是 Account Status 還是 UNCONFIRMED\n1aws cognito-idp initiate-auth \\ 2 --auth-flow USER_PASSWORD_AUTH \\ 3 --client-id 400d11al9p25pmjg3igflo5h4i \\ 4 --auth-parameters USERNAME=allen.hsieh.aws@gmail.com,PASSWORD=Aa123456! 5 6# Result 7An error occurred (UserNotConfirmedException) when calling the InitiateAuth operation: User is not confirmed. Step3 驗證 User Cognito 會寄送 verification code 到你的 mail ，信箱內應該要有一封 email title 叫做 Your verification code，如果沒有看到，建議先到垃圾郵箱裡面查看。\n這邊使用 confirm-sign-up 去認證 ，注意正常認證成功是不會有任何 result\n1aws cognito-idp confirm-sign-up \\ 2 --client-id 400d11al9p25pmjg3igflo5h4i \\ 3 --username allen.hsieh.aws@gmail.com \\ 4 --confirmation-code 328625 如果沒有收到 Email 或覺得麻煩 ，想要直接認證的話，可以先使用 ADMIN 的權限認證\n1aws cognito-idp admin-confirm-sign-up \\ 2 --user-pool-id ap-northeast-1_DpExb5BW8 \\ 3 --username allen.hsieh.aws@gmail.com Step4 確認驗證 這時後透過 UI，可以看到 Account Status 已經是 CONFIRMED\nStep5 再次 Login 這時候，再次 call initiate-auth 就會成功，而且這時候 Result 會有三個 Token，分別是 IdToken, AccessToken 和 RefreshToken，這三個 Token 都是使用 JWT Token。RefreshToken 就如字面的意思，主要用來更新 Token。Response 中有 ExpiresIn 這個是告知 Token 過期時間，這邊單位是秒。IdToken 主要有包含客戶的一些資訊（例如 email, phone)，可以知道這個人是誰。而 AccessToken 主要是給你 call 一些不需要知道個人資訊的 API，API 只是單純要知道這個 User 擁有權限就可以使用 AccessToken。這邊也可以使用 JWT.io 將 Token decode 回來，看看裡面有什麼資訊。\n1aws cognito-idp initiate-auth \\ 2 --auth-flow USER_PASSWORD_AUTH \\ 3 --client-id 400d11al9p25pmjg3igflo5h4i \\ 4 --auth-parameters USERNAME=allen.hsieh.aws@gmail.com,PASSWORD=Aa123456! 5 6# Result 7{ 8 \u0026#34;AuthenticationResult\u0026#34;: { 9 \u0026#34;ExpiresIn\u0026#34;: 3600, 10 \u0026#34;IdToken\u0026#34;: \u0026#34;eyJraWQiOiJhTmJjOWZpbUw5TjUxWWk2VkV6VlUwZ1EyZUdkRFVPNElQVURYYmN4MVhFPSIsImFsZyI6IlJTMjU2In0.eyJzdWIiOiJjNTdjNWZiOS03ZmJkLTQwNmQtOWJiMy0xOWY4OGNmYzlhYzAiLCJlbWFpbF92ZXJpZmllZCI6dHJ1ZSwiaXNzIjoiaHR0cHM6XC9cL2NvZ25pdG8taWRwLmFwLW5vcnRoZWFzdC0xLmFtYXpvbmF3cy5jb21cL2FwLW5vcnRoZWFzdC0xX0RwRXhiNUJXOCIsImNvZ25pdG86dXNlcm5hbWUiOiJjNTdjNWZiOS03ZmJkLTQwNmQtOWJiMy0xOWY4OGNmYzlhYzAiLCJvcmlnaW5fanRpIjoiNGVlYmIyMTQtMzBlOC00N2Q3LWJjOGMtODA3NjM5ZTljMzU2IiwiYXVkIjoiNDAwZDExYWw5cDI1cG1qZzNpZ2ZsbzVoNGkiLCJldmVudF9pZCI6IjM3Nzk5N2RlLTFhMWYtNDA5ZS1iNjM1LWVjNzk2ZTBjZTEwYiIsInRva2VuX3VzZSI6ImlkIiwiYXV0aF90aW1lIjoxNjI2MDAzNjU5LCJleHAiOjE2MjYwMDcyNTksImlhdCI6MTYyNjAwMzY1OSwianRpIjoiOWZkN2M1MjYtNTBkMy00NWFmLTg5YmUtOWMxNWMzMjMzMjUxIiwiZW1haWwiOiJhbGxlbi5oc2llaC5hd3NAZ21haWwuY29tIn0.Asp7HF1mpPzWUE3l_7S8EH1nY8x9y3o2NK_8fBb_-Hz0PPXTkPGTvjqooEbHRLGGWAf8d7jwoBbsqV3jhFN-UHvrfcAYNRX_DAOeyxi4tCDTQXDk_Ozu8bCU9Clmb5zyg8Jo_SBAZdnKJewbWLEuhqi9_g7AHQrI_sufec3G6L8Ufr3mdfm-eTGtMcICmgkCxImd_zVgWSGkT5gUgcN0DvFzu6cqWC6kjaM3UoUx1uJ-iLpgA2rXzoBEKI2MqGWlIFSJcxL-IFtZyBvU2k4WNDrT5wN1s30UBa6_zeP_-8ZOp-BdU5D4omWltJfns16fqsPBmhbVoyuycamhxv_htQ\u0026#34;, 11 \u0026#34;RefreshToken\u0026#34;: \u0026#34;eyJjdHkiOiJKV1QiLCJlbmMiOiJBMjU2R0NNIiwiYWxnIjoiUlNBLU9BRVAifQ.BJz_JPV5gRBtqiMLhiQroXg0GsTg33jpT9JOlpT1COkmYCTQBfYblnkoGb4tNCL7y7JWreHJDAFXRafaq4fYkOU9gob0FSxUv3MhVs8V1AKiWunM-iytuKFjNALe2Xlmsa70hBcjiEda5agWMdoYG8Q4eL59-ogmJUgsn46h69-B2cxnWx7RQQ9RwJpauLV8zEEKCUYkVE7C5umlceJjQI0OWN76fcoWoCdx-IUgAJEBf72PJ0KBWeZ1p4ElSMWFtg3Egso-OcES1rzW1gE1qG7N_Hcn_58td8fnQAZEONMxPbHzH2C6AaUPF1NaLcQl9mRSs7KgODZkGFQ6FmAc8Q.jitGP9kMECesDsZj.QODsHRk2PYwx9LktJrkbGz__7i2eh7Fz7ueI5qrgrR3uK0nC5jU06RVuMQqn9m_EnlWh0dj9HEU_e9j5XMrbeRA4ZCJkL3wlsZmfRFfF04pAhjO7H7_pxsq_-gGw-5ZNGyh0osd3MICYIYBoJ90RrRHetKKfna9X_hktv8f9A63lqjZLSWDFhAWmXYD_UiLsi7Pf9JAw5g9w3MGYxQ2RN_KRmoaxQg213_6r4fZjqpH0QDpo7Y7bsMu82kGusv8HXwP-O4l7pE6IMTH8k2oX2q2Yg85o-fwEjFZmIiCwnkQfOK607I9qUIN1w8ACtfW6KbN8AXch3CXsnyYeZbprAtgzwYJCERIImfv6UakKwvqlzBCIr3o_idkHnBJrn4HnVhlNTzttl6cyySvO3ombFdHWfn8KbztaAVAZwazQC5WNTm6sCwvz5oR30A-i2taDeT7gwXe_CSg-YiSG8ODKCcTBOeCmCKOpx2Z7maMBP1dAsKqHQ_0-Ozfp_VPJ57TsjTVyLiUCwOCKlZPcMJbKz_svgkc7yTHv9EAYklOLDC3eEEvIIuhXqkmdW0CEvlwvfQLXiRvMbrVPxxGvOrHyIN7f7MSEY8NjZZ-LaXxCg7ilCHEk_pNGn8tru6r_FjTs657tVnxRg0CL5yOu-heKwcYXrK1syS5YRWYi4DYwkBI2_2ymPOlWxZY94cM6LfJpW7EVFxvF7ZUu3aMm4F2s5lQsFuWo6LNIm7umdpm6hJyP6lsgzn3VHsHXBN1WQZDqqUWmVSOcAVQjzvYVaisin90r5LSwMqGE2cxgSzlykE7tSwzZbK8I3sO-iUwdZoaVQYHqSKEa9dwRUc_y3yJxfo81vaLvy73FFg2QnTUA8l6mjziRk0-pG3aM6ODneCGewXm0lyZ6sTbzk2euT6ohrj0CgdJ3kDe1IS0IyV8G5wd_bxE0a5U5IVMnPMexZo-HeJxMbiRKh7dFZ3lCoLvJ3r9vfOGIJCMCo5u-nCC9KkQDJQY5P8mWbKRh4pO6XmPMIj4c96reguvnXmm-eA09y89hQm9AkOafnjMDhYRNEISr0WO1zP5GQRpY98BRdz5T-e8xzQKufoerg3Ogalciw_r6FJgjUJeyfG9PEQlEQXz4nvfLFI5DwHXs768g-_02i0tRZ-mVl8cXRMQ2Sa8L-w2ptvznmayCLEL8rMdggGEHQZSuQKP5pmQu9Mq-nP4mWjR2GWey-UAMLHTZ1l-VsoextWfwdsZaTRJQNXUmOpHgZHHYb8yAOae6nQP60CNGA9DnvAkalrhaNZlOdXG5paDG8hUz1wNFsOLunEe3fhon573QivWx0dUOmxf2DGCqlDC1GrB2UvY6lw.1uaq1g1lQ9BBIMa3X5VG1Q\u0026#34;, 12 \u0026#34;TokenType\u0026#34;: \u0026#34;Bearer\u0026#34;, 13 \u0026#34;AccessToken\u0026#34;: \u0026#34;eyJraWQiOiJKcXVVM0N3dk1YNW1oMTNhb0ZrRnp6VTJ5VytIdXcwUnR4cGdRSXZEVFIwPSIsImFsZyI6IlJTMjU2In0.eyJvcmlnaW5fanRpIjoiNGVlYmIyMTQtMzBlOC00N2Q3LWJjOGMtODA3NjM5ZTljMzU2Iiwic3ViIjoiYzU3YzVmYjktN2ZiZC00MDZkLTliYjMtMTlmODhjZmM5YWMwIiwiZXZlbnRfaWQiOiIzNzc5OTdkZS0xYTFmLTQwOWUtYjYzNS1lYzc5NmUwY2UxMGIiLCJ0b2tlbl91c2UiOiJhY2Nlc3MiLCJzY29wZSI6ImF3cy5jb2duaXRvLnNpZ25pbi51c2VyLmFkbWluIiwiYXV0aF90aW1lIjoxNjI2MDAzNjU5LCJpc3MiOiJodHRwczpcL1wvY29nbml0by1pZHAuYXAtbm9ydGhlYXN0LTEuYW1hem9uYXdzLmNvbVwvYXAtbm9ydGhlYXN0LTFfRHBFeGI1Qlc4IiwiZXhwIjoxNjI2MDA3MjU5LCJpYXQiOjE2MjYwMDM2NTksImp0aSI6ImMyMDlhYWQyLTYxZDEtNDgwNy1hMmFlLWJjODNhNmJiY2I2NyIsImNsaWVudF9pZCI6IjQwMGQxMWFsOXAyNXBtamczaWdmbG81aDRpIiwidXNlcm5hbWUiOiJjNTdjNWZiOS03ZmJkLTQwNmQtOWJiMy0xOWY4OGNmYzlhYzAifQ.IuD31XgD2C93v0H9PUCCIWCBYUVX7QdSq3S3MQlR0LhWI7Ai-w5yEI7KVT0Zy6U943sqsvoagU3ykNS756ivfJbPzI1un4L6d8Y4bZBR9ZY4QRylLx7s3sDY4gnNd02KFGcwYQxj_MGm3SDXQF9xFyDJ6_gP7j1XXgIWknhvrN1-QzEaNqGDiY5v97jT1pLLGvlAe5VuUkcbptMdhStM10fAWww-xMVO_2W3mZcCJwUQ5NR6CaGo2HP_EwkkZ5_Qy7w8q3yTzdrNlX67e6TCHdU5Yu2p-bceSU3_2X3IeHfUhAOobhR_BuntsoSdXLJgnJcCYYg2BiHcUY2jIf8h6A\u0026#34; 14 }, 15 \u0026#34;ChallengeParameters\u0026#34;: {} 16 } ![jwt_decode_example]jwt_decode_example.webp?width=1024px#center)\n總結 AWS Cognito 真的很方便，對於還沒有自己的用戶管理App，可以快速的部署。內部還有許多功能例如 Host Login UI 、客製化 Lambda trigger 或者使用第三方認證。艾倫之後有空的話，也會寫使用第三方認證如 Facebook 或 Gmail，或者建立 Serverless Application (API Gateway 驗證）相關文章～\n","date":"May 11, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/create-cognito-user-pool-by-aws-cli/","smallImg":"","tags":[{"title":"Cognito","url":"/tags/cognito/"}],"timestamp":1683763200,"title":"使用 AWS Cognito CLI 建立 User Pool"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"MAGNATE 今日第一站，陪女朋友去她夢寐以求的 MAGNATE 咖啡廳 ，據了解這間咖啡廳是 BTS 其中一名成員 Jimin的爸爸開的咖啡廳～走出地鐵在前往咖啡廳的路上，還遇到一位正在遛狗的韓國爺爺，他聽到我們講的不是韓文後，就問我們是不是要去 \u0026ldquo;Jimin Father Coffee?\u0026rdquo; ，因為這附近一帶都是住宅區，感覺當地人應該都知道咖啡廳在哪，外國人來這裡大部分都是 BTS 的 Army(BTS粉絲的代稱) 而且都是要去 Jimin 爸爸開的咖啡廳～我們回答 \u0026ldquo;yes\u0026rdquo; 後，韓國爺爺很熱心的幫我們指路，還陪我們走了一小段，並用手指指向咖啡廳告訴我們位置～\n從遠遠就可以看到 Magnate 的招牌\n店門口\n一進門口右邊就是BAR台，這間咖啡廳比我想像中的大很多，我原本還擔心 BTS 這麼有名，會不會連來咖啡廳都需要特別先訂位，看來是我想多了，但也是有可能我們選擇在平日早上來，所以人才沒這麼多～\n還有賣許多看起來都邪惡很好吃的蛋糕！\n內部裝潢得很漂亮\n還有一櫃的帽子，聽女友說都是 Jimin 帶過的帽子～而且看標示只能拍照不能觸碰～\n連廁所門口都砸下重金\n門口的正前方，有一桌是 Jimin 或 BTS 的商品，聽說還有粉絲送的東西～\n女友自己還帶了 Jimin 的小卡，和現場有 Jimin 相關的雜誌，來和今日的餐點飲料拍照~\n接著在這悠閒的度過一個上午，看著女友開心的表情，這次是來對了～\n金剛部隊鍋 因為在 Magnate Coffee 有買了一袋商品，不想要下午帶著到處走，所以又跑回飯店放東西。由於時間已經中午了，怕太晚吃晚餐又不知道要到什麼時候吃，所以在 Google Map 上找飯店附近的餐廳，剛好看到其他部落客有推薦的金剛部隊鍋，艾倫決定去嚐鮮看看，畢竟部隊鍋也算是韓國有名的料理之一。\n金剛部隊鍋果然招牌就是一個金剛\n就連泡麵也有特別找廠商合作，印了金剛的 Logo～而且這邊白飯和泡麵是可以免費續的\n今日點了牛五花部隊鍋，照片是兩人份量的，老闆會根據人數來放不同份量\n老闆還很大方的招待一份炸鍋貼，這個鍋貼真的很大～\n最後整體吃起來艾倫個人覺得味道普通，但有可能這家本身價位不高，加上份量給的算不錯，所以應該是算是CP值不錯的餐廳，如果是食量比較大的人比較適合～\n甘川洞文化村 接著我們坐地鐵再轉乘小巴士到甘川洞文化村，由於甘川洞文化村算是在山上，所以小巴士上去的時候超晃～看來不管到哪個國家的小巴士都一樣，有好幾個轉彎幅度超彎的路段，司機還是能邊控制好油門衝上坡ＸＤ真的覺得司機很厲害!\n一下車就看到一堆人正在拍照，我們也跟著拍了幾張，拍完以後就走到一個服務站，想說去要一個地圖。 結果服務站的老奶奶跟我們說地圖要去另一個服務站買，當下服務站門上有一張地圖，老奶奶很熱心的指給我們看並建議怎麼走比較好。因為甘川洞文化村很大，所以有很多路線可以走，我們就用手機把地圖拍下來，省下一筆地圖費！ 老奶奶也告訴我們，有魚的地方就代表可以走，最後還問我們從哪裡來的，我們回答說台灣以後，老奶奶還很開心的說一些中文單詞，但不知道是不是因為剛剛的對話都是英文，老奶奶突然切換成中文一時之間反而沒聽懂XD。\n服務站外面還有小王子～\n接著我們走了老奶奶推薦的路線，這路口就很明顯～\n而且入口進入沒多久就有看到歡迎的小人～公車站下來也有一個，還在那邊努力拍了許久，因為人行道太窄，如果要拍照需要站到馬路上，但一直陸陸續續會有車子挺危險的，早知道入口這也有一個，就不在公車站那邊拍了 \u0026gt;_\u0026lt;\n接著就看到老奶奶說的魚～也太大一條了吧\n文化村內的路都是平路也很好走，一旁還有許多文創小店，都會賣一些紀念品或明信片，還有手作小物的小店和吃的～\n艾倫在中間一處拍貓的地方拍照時，女友跑來跟我說旁邊有貓貓耶～\n接著走去看女友說的地方，原來是一間麵包店\n結果女友說的貓貓是這隻，我以為是真貓\n接著看到一間外面放滿包包的店～這放在外面都不怕髒嗎，每天都要收的話不會累嗎?!\n接著看到一面牆，上面是各國語言的我愛你\n再走一小段，就看到女友的 BTS 壁畫，聽女友說因為有兩個 BTS 的成員是來自釜山， 所以壁畫有畫那兩個成員的畫像～\n接著看到了最熱門的拍照點，就是「小王子」啦！超多人都在排隊等著和小王子合影，我們大約也排了十幾分鐘才拍到\n接著來到 148 階梯\n從上面往下看，真的很深\n這邊許多房屋都是住家，沿路真的就要靠老奶奶說的魚魚在哪就能知道往哪邊走，魚魚都做得很明顯\n中間還看到路牌上面有中文\n這邊還放了 1970 年代甘川洞文化村的樣子\n不過艾倫最後沒有走完 148 階梯，因為越走越下面，離我們進來的地方會越離越遠～ 加上艾倫有點累了，所以走一半就回頭了。\n最後附上沿路邊走邊拍不同角度的甘川洞文化村～\n南浦洞 接著到 Day2 沒有什麼時間逛的南浦洞～\n看到一家賣飾品的店，外面的裝潢全部是一個一個的耳環組成的\n接著還看到了 Kakao Friend Store，雖然艾倫對 Line Friend Store 比較有興趣，可惜釜山的 Line Store 已經關閉了～\n看到超大的 Ryan\n還有看到一隻跟艾倫在家時經常會有的姿勢的 Ryan\nBiff 廣場 接著到 Biff 廣場，路邊有超多的路邊攤，很像台灣的小夜市，我們先來吃元祖的糖餅～這裡的糖餅會放滿滿的堅果，和昨天 Day4 宵夜 吃的糖餅不太一樣，昨天吃的裡面沒有包堅果，雖然有人說包堅果的比較好吃，但艾倫覺得沒有堅果的也挺好吃的\n接著再買旁邊攤位的雞肉串來吃～\n我覺得韓國這點做得不錯，就是攤位旁有地方可以直接丟吃完的竹籤\n最後拍了一下 Biff 廣場\n奶奶伽倻小麥冷麵 接著來體驗韓國的冷麵，來到了女友同事推薦的奶奶伽倻小麥冷麵，也在南浦洞，從 Biff 廣場走五到十分鐘就到了，不過這家店在巷內，要稍微比對一下Google map上的店家照片才找的到。\n奶奶伽倻小麥冷麵有中文的菜單\n女友還想說中文菜單會不會和店裡給當地人的菜單不一樣，後來用翻譯軟體翻譯，結果是一模一樣的 xD\n最後艾倫想品嚐看看，所以面食和拌麵都各點了一碗，原本看到面食是湯的，還以為是熱的，結果沒想到也是冷的。由於拌麵沒有湯是直接配醬，所以味道會比較重也比較辣。因為麵都特別長～所以店家也會附剪刀讓客人在食用時可以自己剪斷，而且當下桌上會附上一壺茶(艾倫在還沒喝之前是這麼以為)，結果倒在杯子裡喝後才發現原來這壺茶其實是熱湯呀。最後由於艾倫比較不能吃辣，所以拌麵沒有吃完。\n樂天超市 最後又來到了樂天超市，原本是想逛樂天百貨的，但艾倫沒有事先做好功課，沒想到韓國的百貨只開到八點半，最後晃了一下地下室的美食街，想說最後一天看能不能再嚐看看什麼小東西。意外看到這裡也有摩斯漢堡進駐，但韓國的 Logo 竟然是綠色的。\n最後在樂天超市又買了一些伴手禮，還有晴王麝香葡萄～外包裝盒上還寫有16度的甜度！ 提醒大家～在樂天超市買水果即使金額有超過三萬韓元也是不能退稅的，還好艾倫有準備其他備案的商品，預防不能退稅時買 xD\n之前艾倫去日本時也有吃過十幾度的葡萄，艾倫覺得雖然日本的葡萄比較甜，不過還是覺得韓國的比較好吃，因為日本的真的甜過頭，是那種吃多了會喉嚨痛的甜。\n韓國之旅就在這邊劃上句點～因為隔天是早上的飛機，早上五點多就出發去機場準備回國了！感謝大家的閱讀～\n","date":"April 4, 2023","img":"/posts/travel/2023_busan_day5/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/travel/2023_busan_day5/feature_hufd89d48379a3affc1274354adc56097c_221644_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/travel/2023_busan_day5/","smallImg":"/posts/travel/2023_busan_day5/feature_hufd89d48379a3affc1274354adc56097c_221644_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"TRAVEL","url":"/tags/travel/"}],"timestamp":1680566400,"title":"2023 釜山六天五夜 Day5"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"在大學時間，我曾經使用過 WordPress.com 只是最後覺得 WordPress.com 限制太多，想要達到我想要的效果，又需要額外花錢，所以最後就放棄了。這邊不會花太多時間解釋 WordPress com \u0026amp; org 的差別，如果有興趣的人，可以參考這邊文章 WordPress.org 和 WordPress.com 有什麼不一樣？。 2016年，AWS 宣布新的 Lightsail 服務上市。Lightsail 這邊使用 Bitnami 一鍵部署很快， 不用自己啟一個 EC2 \u0026amp; MySql Server 然後還要設定網路， WordPress 也會安裝好。這邊介紹直接用 Lightsail Console 頁面直接部署。\nLightsail 架設 WordPress Server Step1 進入 Lightstail 服務，點下 Create instance Step 2 選擇 地區、服務和方案。 由於我是新網站，所以這邊選用有一個月免費試用的 3.5 美金一個月的方案。\n使用 bncert 建立 HTTPS 透過UI，可以直接連線到 Instance 上\n使用 bncert 安裝憑證，我的機器一開始上面安裝有安裝 bncert。\n1# 安裝憑證 2sudo /opt/bitnami/bncert-tool 3# 如果沒有 bncert-tool 可以執行以下 command 4wget -O bncert-linux-x64.run https://downloads.bitnami.com/files/bncert/latest/bncert-linux-x64.run 5sudo mkdir /opt/bitnami/bncert 6sudo mv bncert-linux-x64.run /opt/bitnami/bncert/ 7sudo chmod +x /opt/bitnami/bncert/bncert-linux-x64.run 8sudo ln -s /opt/bitnami/bncert/bncert-linux-x64.run /opt/bitnami/bncert-tool 執行bncert-tool，一開始會詢問 Domain List 和 是否將 Http 近來的頁面全部轉到 Https\n之後會確認改動和填寫憑證上面的 mail\n執行結果\nRouter 53 購買域名 進入Router53 購買域名頁面，點選 Register Domain\n這邊可以搜尋你要的 domain，同時 Router 53 也會提供其他建議。\n確認要購買域名時，需要填寫個人資訊\n購買完以後就可以在 Rounter 53 上確認自己的 Domain 狀態\n申請完 Domain 需要一點時間喔～艾倫這邊等了大約兩天才下來。\n建立新的 index 到 Google Search 這邊順便介紹一下，我目前在 Worldpress 使用的 SEO Plugin Yoast SEO ，安裝完以後每一個 Post \u0026amp; Page 下面可以設定一些 keyphrase、Meta description 等等資訊，也會提供每一個 Status 作為參考。\n這邊簡單一個方法可以確認 Google 是否有 index 你的網站，新的網站通常都沒有資訊，在 Google 打上 “site:domainName”\n以艾倫的 allenhsieh1992.com ，由於我已經有設定幾天了，所以 Google 有 index 了，反則就會只有一個請使用 Google Search Console 的頁面 Google Search Console 驗證網域 Google Search Console 是一個 Google 讓我們告訴他現在新的網域方法。目前有兩種驗證方法，這邊建議使用網域的新功能，因為使用網域前置字元，會把 HTTPS 和 HTTP 當作不同的網域處理。\n我一開始使用右邊的方式 \u0026ldquo;網址前置字元\u0026rdquo;，但因為我一開始架設網站時，不是先設定HTTPS，所以先驗證了HTTP。由於之後犯蠢登入不同的Gmail，所以以為HTTP 沒驗證成功，又驗證了一次HTTPS。事後發現 HTTP \u0026amp; HTTPS 是可以分開建立成功的，所以這邊會教學並建議使用\u0026quot;網域\u0026quot;的方式，並免大家跟我犯一樣的錯誤\nStep1 輸入要驗證的網域 Step2 複製 Google 提供的 TXT Record 設定資訊 Step3 在 Router 53 建立 Txt Record Record Type 記得選 Txt 和 Value 貼上 Type2 的資訊 Step4 回到 Step2 頁面點選驗證 ～ 驗證成功就會在 Google Search Console 看到你的 Domain\n上交 Sitemap 到 Google Search Console Sitemap 主要包含了網站結構資訊，上交 Sitemap 可以讓 Google 更好地瞭解你的網站。這邊的 Sitemap 是由之前所提的 Yoast SEO Plugin 所產生的\nStep1 取得 Sitemap endpoint 在 Yoast 介面的 Features 下面有一個 XML Sitemaps 的設定，點選右邊的問號，在點下 See the xml sitemap，這時候就會直接打開 Sitemap 的頁面\nSitemap 實際內容就這個網域下所有的網頁，並且最後修改時間\nStep2 上交 Sitemap 到 Google Search Console 接著等待幾天後，就可以在 Google 透過 site 找到自己的網站\n總結 這次架完以後，挺佩服那些沒有資訊背景又自己一手包辦，從零開始架設WorldPress 網站的人。這次的網站，雖然不如我內心所想要的外觀，無奈前端不熟，如果想要用出自己的外觀，又要花不少時間。所以艾倫我決定先增加這個網站的內容，將來這個網站如果我有動力繼續做下去，再花時間修改外觀。\n","date":"April 4, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/use-lightsail-to-create-wordpress-website/","smallImg":"","tags":[{"title":"Lightstail","url":"/tags/lightstail/"},{"title":"Route53","url":"/tags/route53/"},{"title":"WORDPRESS","url":"/tags/wordpress/"}],"timestamp":1680566400,"title":"使用 Lightsail 架設 WordPress 網站"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"奇瓦家鱈魚湯 由於前三天都比較早出門～大家都玩太累了，加上今天要去海雲臺搭乘的天空膠囊列車預約的時段在下午1點，所以今天的行程就可以睡得比較晚再慢慢出發～\n第一站行程是海雲臺的奇瓦家鱈魚湯，這是前一天大家在 Google Map 上找到的。一早從西面站出發，坐到中洞站從七號出口出來一路直走。在前往餐廳的路上也會經過迎月路，路上也有許多櫻花，雖然沒有鎮海栽種的密集，但有櫻花花瓣伴隨著海風吹拂飄動～整條路走起來也額外賞心悅目。\n抵達時才十一點左右，但奇瓦家鱈魚湯的門口已經停滿了車子，艾倫看到大部分來用餐的人都是當地的韓國人！而在菜單方面沒有選擇，就只有賣鱈魚湯套餐，一份就是一萬四韓元。\n用餐的空間牆上掛滿了滿滿的簽名，不過艾倫完全看不懂是誰就是了 xD\n鱈魚湯的份量很大一碗，艾倫覺得兩人吃一碗應該都不是問題，但基於韓國的文化，好像沒有辦法兩個人點一個餐點共食，所以應該還是只能一人點一碗。\nBUSAN X THE SKY 由於吃完鱈魚湯之後，離搭乘天空膠囊列車預定的時間還有一個小時多，所以就跑到BUSAN X THE SKY前走走。不得不說，當天的風真的很大，我們當中有很多人的帽子都被吹飛了！在馬路上還有看到被風吹飛的漢堡躺在地上，看起來幾乎還沒吃幾口就意外掉落～\n在BUSAN X THE SKY前的海灘有許多海鷗！現場還有許多人在現場將食物拿在手上餵食海鷗，海鷗會一直在沙灘上走，等風一來就嘗試飛起來吃食物～由於風很大，所以海鷗經常快吃到時，又被風吹回去，真的能感受到海鷗很努力的想飛過來吃食物。艾倫的同伴們也在一旁的超商買了吃的，餵食成功～\n接著走到海灘上，沒想到這邊的海灘踩下去的沙超硬很紮實，靠海的地方還能看到很多貝殼。\n從海灘用 iPhone 廣角和全景來照BUSAN X THE SKY真的很漂亮！\n因為時間的關係，我們沒有上去BUSAN X THE SKY，只好拍一張門口來假裝自己上去過BUSAN X THE SKY了～\n膠囊列車 我們在台灣時，就事先預約好了尾浦到青沙浦的車票～網上預約的時候只能選一個時間的區間，因此到了現場還是要排隊的喔，只是減少了買票的時間。\n艾倫拍了幾張尾浦站的入口\n膠囊列車有許多不同的外觀，有最基本的單色，另外也有海鷗系列的！當天還有小夥伴們在打賭，等一下坐到的列車會是什麼顏色，雖然賭輸賭贏沒有獎勵或懲罰，就單純好玩～不過艾倫覺得海鷗系列的都好好看！\n接著就從尾浦站出發! 艾倫是坐到單色的膠囊，不過其實車廂內部都一樣，所以坐什麼顏色的膠囊列車，實際上是無感的～\n從膠囊列車內往回拍尾浦站\n從膠囊列車內拍大海，大海的水好乾淨還能很清晰地看到下面的石頭\n最後抵達青沙浦站\n青沙浦站 到了青沙浦站，艾倫就直往天空步道的方向移動，結果到了天空步道後，發現步道是關閉的，步道的柵欄上面張貼了公告，後來用翻譯才知道，原來風太大就會不開放！艾倫就只能在旁邊拍照，天空步道一旁還掛著許多許願的魚魚。\n因為風太大，加上今日是走休閒路線，所以我們打算休閒的喝杯咖啡再走。青沙浦站附近有許多咖啡廳，而我們選了一家 Alice Donut，原因只是因為遠方就看到一個大大的甜甜圈招牌。\nAlice Donut 店裡也裝潢得蠻漂亮的\n最後來一張美美的甜點網紅照，艾倫喝的是草莓優格，剛好是草莓季節，只能說韓國草莓系列的飲料實在是太好喝太邪惡了！\n海岸列車 接著來體驗海岸列車，列車也是事先在網路上就預約好的，從青沙浦站搭乘到松亭站～由於天空步道這個景點沒有走到，所以我們就想提早離開，就嘗試跑到車站去詢問是否能提早搭車～\n在去車站的路上就剛好遇到一班海岸列車出發\n拍完照之後到車站現場詢問，還好因為週一的關係所以前一班列車沒滿，現場的工作人員就幫我們安排提早一班車搭乘。不然我們看現場的時刻表，不少之後的班次都已經是滿的，所以也挺看運氣的。\n最後拍一張從列車內往外拍的照片\n機張市場 接著我們從松亭站走路到地鐵站改搭地鐵到機張站～ 機張站從玻璃往外看真的很漂亮，下面都是鐵軌\n到了機張市場入口，就可以看到賣很多海鮮～還有海藻海帶\n還看到傳說中的盲鰻，現場還有看到有人在處理剝盲鰻的皮，而且還是在盲鰻活著的情況下處理\u0026hellip;\n接著再往前走就可以看到各式各樣的螃蟹店～現場的韓國人一直瘋狂拉客，有個還是一直用拜託的手勢要你去他們的店家品嚐看看，實在太恐怖了\n韓國人果然很會醃製各種食材，除了常見的泡菜還有醃製的螃蟹\n我們來機張市場前，事先已經選好了餐廳\u0026quot;小夥子巨蟹\u0026quot;，所以晃了差不多我們就拿著手機開著 Google Map 找，經過了一家店時，有一個店員看到我們手機上的照片，就跟我們說是他們這家～我們當下拿手機對了一下名字，是一樣的，但外觀跟 Google Map 上顯示的對不起來。後來有一個隊伍中的夥伴跟我們說他在另一條街找到店家，圖片跟 Google Map 一樣，所以我們就跑過去另一家店。路途中我們還在聊會不會是店名故意取一樣的店家XD～因為像台灣的夜市，有很多店賣的東西都一樣，然後都寫自己是創始店。到了現場我們還特別問店員說剛剛有另一家店名字一樣，結果店員跟我們說，都是同一家店，他們的店在地下一樓，空間很大，所以有兩個入口，我們剛剛看到的其實就是是另一個入口。\n我們這次點了店員推薦現在比較好吃的松葉蟹和紅蟹～我們一開始選了四隻算起來 7萬韓幣，結果店員又送了我們兩隻，還被我們砍到了25萬韓幣。而且還一人送一個扇貝，都讓我懷疑是不是我們殺的不夠多 xD\n進去餐廳前還發現有一隻螃蟹一直在那吃東西，他運氣很好今天沒有被小哥選到\n到了裡面，才知道原來韓國海鮮料理是要收料理費，一個人 5000 韓元～\n不過最重要的是上菜！！！\n小夥子巨蟹的小菜還不錯，有一個煎餅是現做的，我們跟一位會說中文的中國店員說我們想加點煎餅，她還跟我們說阿姨不一定會做。然後我們等了老半天看煎餅沒有來，結果又問了一次中國店員，她卻告訴我們說材料沒有了，也不知道是不是真的沒有還是不想做，不過竟然對方都說沒有了當然也只能這樣囉。\n最後料理費十人5萬，加上螃蟹本身 25萬，然後加了一點炒飯就吃了三十多萬。 (但跟前幾日吃鮑魚粥跟白帶魚的費用比起來便宜很多～)\n宵夜 由於吃螃蟹比較不容易飽，加上隔天是自由行動，所以女友的老闆打算今天晚上跟大家一起喝酒。回到西面站的時候已經是九點四十五分，然後大家都想吃糖餅，Google Map 上有看到店家十點關門，所以大家都是用衝的跑去買糖餅。我在台灣的夜市有嚐過一口糖餅，但覺得不好吃，所以一開始我試嚐了一口女友買的糖餅，結果意外的超好吃，艾倫還自己買一個來吃～\n回飯店的路上剛好看到有人推薦的麵包店還開著，我們就進去買了一個紅豆鮮奶油麵包，想說來當隔天的早餐。\n沿路就買了酒回飯店，接著他們想請飯店幫忙叫外送。一開始飯店是拒絕的，因為飯店本身有餐廳然後沒有送外送到房間的服務。後來跟櫃檯小哥說，我們想自己叫外送，但怕對方聽不懂韓文，想請櫃檯小哥幫我們下單，然後我們自己在飯店門口等取餐就好～後來櫃檯小哥被我們說服了，算是他自己幫我們，他用他手機的 App 幫我們點了貨到付款的餐點。\n我們後來點了橋村炸雞配酒～～～\n因為早上風實在太大，加上最近玩的比較累，有可能免疫力比較差，晚上竟然微燒起來，後來只吃了一兩口炸雞後，就吞了個成藥去休息了。說實話炸雞好好吃，艾倫還想多吃一點，可惜身體撐不住了，先陣亡了ＱＡＱ\n","date":"April 3, 2023","img":"/posts/travel/2023_busan_day4/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/travel/2023_busan_day4/feature_hua33b7391889bce092ba07d6deb177769_192034_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/travel/2023_busan_day4/","smallImg":"/posts/travel/2023_busan_day4/feature_hua33b7391889bce092ba07d6deb177769_192034_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"TRAVEL","url":"/tags/travel/"}],"timestamp":1680480000,"title":"2023 釜山六天五夜 Day4"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"集合 我們在台灣時就事先在 Klook 上買了鎮海賞櫻一日遊行程，早上在西面站的12號出口等載我們的巴士，結果到了現場超多遊覽車和一堆導遊拿著旗子正在找他們的團員。我們問了一圈都找不到我們的導遊，還在擔心說是不是跑錯集合地點！最後原先等待的車子都集合完畢出發了，到了約定集合的時間但我們還沒看到任何巴士，但還好我們不是唯一一組在現場等的，所以至少確定不是我們走錯。最後有一台司機開著巴士過來，然後說了往鎮海的韓文，就叫我們先都上車，而且司機也不會講英文或中文，最後在其他人的詢問下才知道導遊遲到晚點會到，我們也只好先邊吃了在 7-11 買的泡菜飯糰當邊等導遊來。\n等了大概有五到十分鐘後，導遊終於出現了，是一位稍微會講中文的韓國人。導遊和我們整團的人都確認身份讓我們上車出發，在車上導遊還發給我們這次鎮海的地圖並簡單的介紹鎮海。\n導遊說鎮海大約有四十萬顆櫻花樹，而櫻花樹不是韓國的國花為什麼要種植這麼多櫻花樹呢？因為韓國跟台灣一樣以前有被日本殖民過，所以當時住在韓國的日本人想看櫻花，就在韓國也種下許多櫻花樹～而鎮海也是韓國海軍主要的駐點。\n慶和火車站 第一站是慶和火車站，現場滿滿的都是人，但重點是櫻花實在太漂亮了~真希望台灣也能種這樣的白櫻花，而且這次我們運氣很好趕上這次的櫻花，因為導遊有提到大概下禮拜開始櫻花就要準備掉了，加上天氣非常的晴朗～現場也有放一台火車可以拍照，但因為還要排隊拍照，艾倫就直接跳過了 xD\n余佐川櫻花道 第二站:余佐川櫻花道，余佐川櫻花道一共有十幾座小橋，而且有的小橋還有中文名字。\n穿過一個地下道就開始是余佐川櫻花道\n花道的其中一側都是店家在賣東西，烤魷魚不管在哪裡似乎都是最邪惡的食物，嗅覺滿分！還好艾倫克制住了，沒有買烤魷魚就趕快離開了。\n接著來到姻緣橋拍照，後面也有在不同橋拍照，但艾倫忘了去記橋名了 xD\n接著我們被一家賣烤乳豬的店吸引，就在這邊簡單吃了一點東西，不過這邊畢竟是觀光景點，艾倫覺得味道就一般，能先墊墊肚子就行 xD\n吃飽後就是繼續拍拍拍\n剛好還遇到一陣風，櫻花這樣落下來真的好漂亮\n離開前遇到一個攤販，有賣像優酪乳的飲料！一開始艾倫是沒有打算要買的，其他人是買了美顏的優酪乳，飲料的設計是蓋子轉開後會有膠囊可以吃～而且聽同團旅伴都說很好喝，所以艾倫就被洗到也跟著買了一罐～但艾倫是男生當然沒有買補充膠原蛋白的，反而是買了一個保健腸胃的！優酪乳到哪裡都好喝，就是不知道吃的膠囊是什麼，如果有人知道可以留言給艾倫～\n離開余佐川櫻花道前再拍一張停放在這的火車\n鎮海市晃晃 接著艾倫和其他人都走累了，就在余佐川櫻花道附近找了一家咖啡廳上個廁所順便休息一下～\n快三點的時候，一堆人就離開咖啡廳，因為附近接著會有表演，所以很多人都去看表演。接著我們也開始到附近走走，還剛好遇到有 B-Box 表演，現場也有很多人觀看～\n一旁還有韓國坦克車展示\n之後我們到運動場看軍樂儀隊，不過現場實在太熱了，座位也沒有遮陽的地方，艾倫覺得坐太久會中暑所以待一下簡單拍個照就離開現場了。\n接著去附近的小市集晃晃，現場還看到韓國炸醬麵的吉祥物浣熊~\n然後吃了一小雞肉串和炸熱狗～韓國的炸熱狗好好吃喔，果然跟台灣夜市吃的完全不一樣，咬開可以看到外面那層炸皮是有層次的～\n接著到了鎮海的中央市場，還在這邊吃辣炒年糕，對艾倫來說超級辣，而且不幸的是剛好艾倫身上的水和飲料都喝完了，所以艾倫最後只好忍著辣吃完它。吃完辣炒年糕後，就到了回程的時間了。\n味贊王塩烤肉 回到西面車站，晚餐就是吃～ Day2 因為昨天客滿而錯過的味贊王塩烤肉。在過去餐廳的路上一堆人聚集在一起，認真一看好像是街舞比賽～\n到了味贊王塩烤肉，外面依舊已經排滿了人，還好我們有預約所以有座位可以馬上入座用餐～\n一開始小菜上來就看到有新鮮的芝麻葉！這是艾倫第一次吃芝麻葉，真的很適合配肉一起吃～\n味贊王塩烤肉只有五花肉和梅花肉兩種選擇，而且低消至少要點三份。另外在味贊王塩烤肉有店員會幫忙烤，是不用自己烤的～\n當店員把肉翻過來時，這顏色實在太漂亮了，店員真的好會烤～\n在其他人的教學下，只是用手指先比2再比1，店員就會知道 2 + 1 兩瓶啤酒和一瓶燒酒！\n由於今天在外走了一整天，吃完晚餐後就結束今天這回合。\n","date":"April 2, 2023","img":"/posts/travel/2023_busan_day3/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/travel/2023_busan_day3/feature_hu7379166eb2ca908851cd242159810684_422850_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/travel/2023_busan_day3/","smallImg":"/posts/travel/2023_busan_day3/feature_hu7379166eb2ca908851cd242159810684_422850_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"TRAVEL","url":"/tags/travel/"}],"timestamp":1680393600,"title":"2023 釜山六天五夜 Day3"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"Egg Drop 今日的早餐是在網路上找到評價還不錯的連鎖店 Egg Drop，早上九點多一到現場遠遠就看到已經一堆人在店門口排隊！我們在一旁研究了菜單老半天，後來進餐廳點餐，發現店裡是用點餐機，而且沒想到點餐機還可選中文，只是我們都已經看好要點什麼了，一時之間用中文點餐機反而還對不上，只好又改回英文。點完後我們就開始到餐廳外等候叫號，中間還有服務人員出來找某一個號碼餐點的人，結果是一個老外。我在旁邊聽到店員在跟他確認是不是點 20 份餐點，老外還說對，他是幫他和他朋友點的\u0026hellip;.店員還問對方說要等 20 分鐘可不可以，老外說可以\u0026hellip;我看了一下我的號碼，結果在是在老外後面，我們最後等了一個多小時。雖然味道還行，但沒看到什麼當地人來吃，而且等的時間太久，CP 值艾倫覺得不高，所以如果是第一次嚐鮮還行。\n釜山塔 接著我們從西面坐地鐵到南浦站，由於早上 Egg Drop 等太久時間有 Delay 太久，加上我們要去看兩點整的影島大橋，所以這邊自由行動到一個半小時～有的人不想逛釜山塔就在商圈逛街，而對艾倫這種購物慾比較低的人當然是選擇釜山塔。釜山塔進入的位子在一個很奇妙的地點，是在商圈裡面，而且很不起眼。\n還好上去有電扶梯，不然艾倫走上去有可能半條命都沒了！電扶梯旁都掛著不同國家語言的歡迎光臨字樣。\n到了最上面就能看到龍頭山公園的石牌\n石牌的右旁還有一個鐘\n而石牌的左邊看到一個很像陽明山上的花鐘，一度還以為來到陽明山了呢（被打\n往裡面走一點，有一個釜山正修寺，上面還有一個觀音。旁邊的歷史介紹著，1954發生過大火，而在 1956 年有重建過，目前裡面主要供奉著 89 位在二戰為國捐軀的英靈。\n再往裡面走一點，就能看到韓國英雄李舜臣將軍的銅像\n在釜山塔一旁，還有紀念品商店，賣一些紀念品\n在紀念品商店前面還可以看到在機場也有出現過的吉祥物海鷗～\n一旁還能看到許多觀光景點的文字配上愛心提供拍照\n因為時間有限，艾倫就沒有上到釜山塔上面，不過釜山塔一樓也是能看到不錯的風景了，艾倫覺得不一定真的要上到塔上。要離開時，才發現有一個時鐘，上面還刻著台灣國際獅子會，艾倫的女友還說幹嘛拍這種東西 xD\nArtbox 下來後剩不到半個小時，就逛了賣許多小物的 Artbox\n艾倫覺得 Artbox 的角色做得好可愛\n推門就是戳臉\n拉門就是拉臉\n最後在 Artbox 買了一支皮卡丘的護唇膏！而且剛好還特價便宜了2000韓元。 離開 Artbox 沒多久路程，又看到招牌海鷗推廣韓國 2030 世博會~\n影島大橋 時間差不多，艾倫就開始慢慢往影島大橋的路上移動，中間還看到一個路牌上面有著不同國家的大城市\n剛有人說為什麼沒看到台灣的時候，我們就在側面看到台北，而且剛好是往影島大橋的方向，所以我們正在往回台北的路上（被打\n因為提早到，距離兩點開橋還有一點時間，艾倫就開始隨便拍，後來還被女友打電話說來說人怎麼不見了\n時間快到時，還會廣播並放音樂然後橋就會開始慢慢升起。開橋畫面跟艾倫想像中的有點不太一樣，電影看太多了，以為會從橋的中心為基礎，往兩邊升起來，結果只有左側的橋升起而已。\n橋升起最高的樣子\n而且還真的有船從這裡經過\n白淺灣 看完影島大橋後，我們就移動到樂天百貨對面的公車站，坐公車到白淺灣。韓國公車坐起來的感覺跟台灣很像，扣除韓文，還以為在台灣坐公車呢～ 到了白淺灣先晃晃白淺灣文化村，沒想到韓國人也看手相，一進去沒多久就看到有個攤位在看手相~ 白淺灣的海上都是船，可惜艾倫拍不出一片都是船的感覺，如果是軍艦，感覺就像戰爭一樣很壯觀，不過也不知道為什麼能停這麼多船在海上。\n在看手相旁邊的攤位有個 Artshop，裡面幾乎都是賣貓的周邊商品，最重要的是，竟然還有一隻貓星人在現場睡覺，很多客人看到就會摸摸他～但貓也沒反應就繼續睡自己的。\n接著沿著海岸步道走，走到底有一個海岸隧道，裡面有一個 Touch Love 的牆壁，如果隔一段時間沒有碰牆壁，手掌的燈就會按掉，左右兩邊同時亮時會有個動畫，很適合情侶在這拍照～\n出了海岸隧道有一個小海邊，那邊有許多人嘗試用石頭堆石堆，而現場有一個前人留下的石堆，超厲害，也不知道怎麼堆的能堆這麼高\n接著我們開始移動往天空步道移動，結果在這邊又看到海鷗！感覺在哪個觀光景點都能看到海鷗的出現，真的是韓國釜山觀光大使～\n天空步道這邊有看到一輛攤車，上面竟然還有賣不知道什麼蟲～韓國大媽還跟我們比讚說這個很好吃，讓我們試試看！不過當然我們當中沒有人敢嘗試。不過因為沒吃午餐所以艾倫肚子有點餓了，就在這邊買了魚板來吃，1000韓元一支，雖然艾倫換成台幣覺得不貴，但後來回到市區有發現市區才賣500韓元一支，果然都是坑觀光客的價格ＸＤ！\n結果艾倫顧著吃忘了拍天空步道，不過在橋上有看到有情人放愛心鎖在上面\n樂天超市 白淺灣走差不多了，我們就坐公車回到樂天超市～這邊順便提醒大家，我們也是當中有人之前在韓國旅遊過提醒才知道。原來樂天超市週日不開門，所以我們選擇今天就先買點東西回去。樂天超市感覺專門設計給觀光客的，因為裡面好多個櫃位都會寫旅遊客熱銷產品來吸引觀光客去買！而且也有不少買一送一活動，最後腦熱就買了兩大包海苔！重量不重但超占行李空間。不過 total 不到一千台幣，而且滿三萬元韓元，結帳時可以直接提供護照辦理退稅。\n濟州家 買完商品後就先回西面的樂天飯店放東西，原來想在飯店附近吃韓式燒烤，但因為我們沒有事先預訂加上週六人潮眾多，而且我們有十個人，店家說要等一個多小時\u0026hellip;我們覺得要等太久就預訂了明天再來用餐，然後找改其他店家用餐。後來在飯店對面看到還有位子的濟州家。\n韓式料理一如往常，老闆一上來就是先上小菜，這家一共有七個小菜。\n我們十個人一共分兩桌四人和六人，艾倫這桌兩男兩女一共點了一碗大的鮑魚粥、海膽粥、烤黃油鮑魚和海鮮蔥煎餅 粥的部分都比較淡，需要自己額外加鹽\n海鮮蔥煎餅的部分，他的蔥都是完整的一大條，艾倫本身沒有特別喜歡吃蔥所以就覺得一般般～\n烤黃油鮑魚是當中我覺得味道算還不錯的，不過料有點少就是了，畢竟鮑魚很貴 xD\n後來隔壁六人桌點了兩份白帶魚，吃不完送了一份過來給我們吃，正常一份是三片，所以圖片並非正常一份的份量。不過白帶魚意外的很貴，一份竟然要 5 萬韓元！在台灣白帶魚應該是很便宜的食材才是，不知道為什麼韓國能賣這麼貴～\nhome plus 吃飽後飯，因為有看到 BT21 和 home plus 有聯名出一些商品，所以艾倫就跑到 home plus 去。原本以為 home plus 是賣家具類的地方像是 ikea，結果沒想到實際是大型超市～\n在走過去的路上韓國很特別，有些比較大的馬路會是畫雙向的斑馬綫分別給過來和過去\n然候 home plus 的電扶梯超擠窄，不知道是韓國人都特別瘦嗎\u0026hellip;不然像北美那些比較胖的人根本沒有辦法坐這電扶梯吧\n最後就是看到台灣現在整天超缺的蛋！在韓國可以當雞蛋富翁～\n結果 BT21 的商品熱賣了，熱門的角色都賣完了，只能說 BTS 影響力太強大了 \u0026gt;_\u0026lt;\n","date":"April 1, 2023","img":"/posts/travel/2023_busan_day2/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/travel/2023_busan_day2/feature_hu2398e6c3403cb4f786b4d95258155cdb_317038_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/travel/2023_busan_day2/","smallImg":"/posts/travel/2023_busan_day2/feature_hu2398e6c3403cb4f786b4d95258155cdb_317038_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"TRAVEL","url":"/tags/travel/"}],"timestamp":1680307200,"title":"2023 釜山六天五夜 Day2"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"金海國際機場 艾倫今年很幸運的能參加女友的員工旅遊，她的公司是去釜山六天五夜，不過實際上算是玩五天，因為最後一天是一大早的飛機。她的公司這次選在清明連假出國，因為四月一號訂不到票了，所以提早一天三月三十一日出發～\n一大清早就坐著計程車到桃園國際機場，在國際機場的免稅店內還看到傳說中很難買到的 PS5，而且還不用綁遊戲真的是很佛，但可惜艾倫現在都沒什麼時間打遊戲了，買了很大的機率放著長灰塵，所以只好打消念頭～ 不然 $16715 的價格確實算挺便宜的，前一陣子過年的時候，還聽同事說他用原價賣了他已經買了1～2年的 PS5，主要聽他說過年很多人有時間玩遊戲，所以遊戲機的價格被炒得很高～\n在登機室等待上飛機的時候，剛好看到前一陣子航空股很火熱的星宇航空飛機準備起飛，就拍了一張起來\n這是艾倫第一次搭乘大韓航空，居然國際線的航空竟然沒有螢幕可以觀看電影之類的，反而只有一個 USB 孔可以充電～艾倫的認知通常都是廉價航空才會沒有螢幕，所以感到有點意外。\n而讓我更意外的是，大韓航空的餐點只有一種～是沒有辦法做選擇的，通常像長榮都會有兩個餐點讓客戶選擇～這次是韓式雞肉飯，對於不吃辣的艾倫來說有點小辣，不過那個醬艾倫覺得挺配飯的，所以艾倫覺得整體還不錯吃，不過也有其他人覺得不好吃，就真的是看人口味喜好。\n從桃園到釜山只要兩個多小時，所以在吃完飯後沒多久就聽到機長通知飛機準備要開始降落了，艾倫就趕快拿起相機往外拍照。\n到了釜山的金海國際機場，就看到吉祥物海鷗的迎接～\n樂天飯店 入境韓國釜山以後，我們先走去了機場的輕軌車站，由於我們事先在 KKDAY 上已經買好了 Tmoney 的卡，加上團隊中有人以前來過韓國，身上還有些韓幣，就先跟旅伴借了一萬韓元來加值。\n接著我們先搭乘機場的輕軌到轉乘站「沙上站」，然後再轉搭捷運到我們住宿的「西面站」\n在行駛的過程中還可以看到外面道路及河堤都是滿滿的櫻花，非常漂亮，都想跳下車去看櫻花了～還好我們之後行程也有安排去鎮海看櫻花所以就忍住了ＸＤ\n接著到了我們住宿的樂天飯店，從遠方就看到一個大大的招牌上面寫著 Casino，沒想到韓國的賭場是合法的，而且還在樂天飯店裡面～ 這次住在 23 樓，電梯超快一下子就從一樓飆到二十三樓～最重要的是窗外的 View 超好的！\n娜英老奶奶換錢所 短暫休息了一下後大家就一起出發去換錢所換錢～娜英老奶奶換錢所在一個巷子內，第一次走的時候有經過但以為不是就這樣走過去了，來回走了第二次才找到。許多人身上都沒有韓幣，都是帶著美金或台幣來換的，而艾倫自己和女友一共換了10000元台幣，想說釜山大城市，大部分都可以刷卡，而且換錢所離飯店很近不夠可以再來換就沒有換很多。當天的匯率是41.3，如果換個25000元台幣瞬間就變成百萬富翁了！\n路上看到了 Mega Coffee，大家就開始先買起咖啡了，估計早上太早起來大家都累了～需要先來點咖啡因補一下\n松亭3代豬肉湯飯 接著我們到附近的松亭3代豬肉湯飯吃晚餐，艾倫點了血腸豬肉湯～一開始聽來過的旅伴說血腸不好吃，但艾倫覺得很特別就吃看看。後來覺得味道還行，而說之前來吃過覺得不好吃的旅伴這次吃也覺得還可以接受～他說可能是上次搭紅眼班機然後當成是早餐在吃，不知道是不是剛睡醒吃不習慣血腸 xD。 這邊有個挺特別的就是桌上會放一小罐鹽，店員阿姨用手比劃意思大概是跟我們講可以自己加。豬肉湯喝起來感覺只放了一點點或者沒放鹽，所以艾倫自己加了一點後才覺得味道不錯～\nDaiso 吃飽飯後，我們就在 Google Map 上找了 Dasio（其實就是大創）~ 主要發現飯店因應環保政策所以沒有提供牙刷和牙膏，雖然當初負責訂房的旅伴有提醒我們，但女友太忙了，所以沒注意到，以為有提供牙刷牙膏所以就沒從台灣帶過來。韓國的 Dasio 真的很便宜，有的東西換算下來還不到30塊台幣。最後還在 Dasio 買了小火龍的牙膏～\n阿拉丁二手書店 因為女友很喜歡 BTS ，所以我們就到阿拉丁二手書店晃晃～裡面有兩層樓，而且有一小區專門賣 BTS 的東西。我自己在旁邊隨便逛，還看到程式相關的書籍，雖然完全看不懂 xD\n西面車站 晃完書店以後，就在附近開始亂逛，還遇到有賣魚板的店，有客人就在站店前面直接拿起來吃～西面車站整個給艾倫的感覺像是台北的西門町或東區，好多年輕人在這一區逛，而且有很多開放式酒吧，可以看到有人在裡面喝酒！路上也看到最近流行的四格自拍機器。最後走到 NC 百貨，不過 NC 百貨不能拍照就沒拍了，最後在地下室的超市買了草莓和一點零食就回飯店了～\nCasino 艾倫已經很久沒有去賭場了，上次去已經是大學的時後，在加拿大的尼加拉瀑布那邊的賭場。樂天飯店的賭場最主要的限制就是當地人不能進去，這是專門給觀光客的賭場，整體不大，人數我覺得也不多，應該主要是當地人不能進來的關係。艾倫小玩了一下，沒有輸贏就離開了\n樂天飯店夜景 最後送上釜山飯店的夜景\n","date":"March 31, 2023","img":"/posts/travel/2023_busan_day1/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/travel/2023_busan_day1/feature_hu2404bca6c561b5e648a94dcd15f1606d_190922_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/travel/2023_busan_day1/","smallImg":"/posts/travel/2023_busan_day1/feature_hu2404bca6c561b5e648a94dcd15f1606d_190922_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"TRAVEL","url":"/tags/travel/"}],"timestamp":1680220800,"title":"2023 釜山六天五夜 Day1"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"Basic of DynamoDB DynamoDB 是 AWS NOSQL Database. performance 的部分，DynamoDB 的資料存在 SSD Data 會自動備份到不同的 AZ ，預防 single point failure DynamoDB 以 table 為單位，裡面每筆的 Row 為 Item ，而每個 Item 的 Column 為 Attribute DynamoDB 有兩種 Type 的 Primary Key ，在 DB 需要是唯一值 Partition Key Composite Key ( Partition Key + Sort Key) 同一個 Partition Key 會存在一起，根據 Sort Key 去排序 可以設定 TTL (Time to Live ) to Item，所以當時間到 Item 會自動刪除。TTL 需要存要刪除的時間 Timestamp Secondary Index Projection 代表一組 Attribute 複製到 secondary Index Types Global Secondly Index Partition Key 和 Sort Key 可以都不一樣 queries or scans 只能拉有 projected 到 secondary Index 的 attribute Local Secondary Index 一樣的 Partition Key 但是不一樣的 Sort Key =\u0026gt; 所以 Primary Key 一定要是 Composite Key 只能在建立 Table 時建立 query or scan 如果沒有 projected 到 secondary Index 的 attribute， DynamoDB 會自動從 table 拉出來 Read Consistency Eventually Consistent Reads: 最終會一制性，因為 Data Source 存在不只一個地方，有可能讀到舊的 Data Source Strongly Consistent Reads: 讀到的資料一定是最新的，有更高的延遲，不支援 global secondary index Transition: 支援 ACID (atomicity, consistency, isolation, \u0026amp; durability) Transition ，上限一次 25 個 write Query v.s Scan Query 是透過 primary key 去找搜尋 撈出來的資料是根據 Sort Key 去排序 ， 可以透過設定 ScanIndexForward = false 得到相反的順序的結果 預設是 Eventually Consistent ，可以設定是 Strongly Consistent Scan 是拉出所有的 Items (full table scan)，然後可以透過 Filter 一一過濾 performance 比 Query 差 可以用小的 page size 改進 performance 可以設定 Parallel 去加強 performance，但要注意 DynamoDB loading 是否很重 DynamoDB Capacity Provisioned Capacity 吞吐量 (Throughput) DynamoDB 吞吐量設定單位為 Capacity Unit ，區分為 Read, Write 兩個 一個 Write Capacity Unit 等於 1 KB/1 Second 一個 Read Capacity Unit 等於 1 個 Strongly Consistent Reads 4 KB / 1 Second 2 個 Eventually Consistent Reads 4 KB / 1 Second 如果超出設定的 Capacity Unit ，DynamoDB 會噴 ProvisionedThroughputExceededException 。 建議時做 exponential backoff retry，意思就是隨著 retry 次數的增長，每個request 中間的時間區隔也會增長 On-Demand Capacity AWS 會根據流量自動 Scaling 很難預測花費 DynamoDB Accelerator (DAX) DAX 是 AWS 管理的 in memory cache cluster ，可以加快 Read 的 Perofrmance 在寫入資料時，會同時寫入 DAX 和 DynamoDB Table，所以寫入後直接 Read 會 Hit 到 cache 不支援 Strongly consistent reads DynamoDB Stream 會抓到所有修改 Item 的 Event ，可以 Trigger Lambda 資料會加密和保存 24 小時 有獨立的 Endpoint AWS CLI create table example 1aws dynamodb create-table \\ 2 --table-name Music \\ 3 --attribute-definitions \\ 4 AttributeName=Artist,AttributeType=S \\ 5 AttributeName=SongTitle,AttributeType=S \\ 6 --key-schema \\ 7 AttributeName=Artist,KeyType=HASH \\ 8 AttributeName=SongTitle,KeyType=RANGE \\ 9 --provisioned-throughput \\ 10 ReadCapacityUnits=10,WriteCapacityUnits=5 KeyType : Hash: Partition Key RANGE: Sort Key IAM Policy Conditions 限制 IAM User 只能操作特定的 Item ，以下面為例 dynamodb:LeadingKeys 是指 partition key，當 IAM UserID 等於 partition key 時才可以執行 Policy 裡面的 Action。 1{ 2 \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, 3 \u0026#34;Statement\u0026#34;: [ 4 { 5 \u0026#34;Sid\u0026#34;: \u0026#34;AllowAccessToOnlyItemsMatchingUserID\u0026#34;, 6 \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, 7 \u0026#34;Action\u0026#34;: [ 8 \u0026#34;dynamodb:GetItem\u0026#34;, 9 \u0026#34;dynamodb:BatchGetItem\u0026#34;, 10 \u0026#34;dynamodb:Query\u0026#34;, 11 \u0026#34;dynamodb:PutItem\u0026#34;, 12 \u0026#34;dynamodb:UpdateItem\u0026#34;, 13 \u0026#34;dynamodb:DeleteItem\u0026#34;, 14 \u0026#34;dynamodb:BatchWriteItem\u0026#34; 15 ], 16 \u0026#34;Resource\u0026#34;: [ 17 \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/GameScores\u0026#34; 18 ], 19 \u0026#34;Condition\u0026#34;: { 20 \u0026#34;ForAllValues:StringEquals\u0026#34;: { 21 \u0026#34;dynamodb:LeadingKeys\u0026#34;: [ 22 \u0026#34;${www.amazon.com:user_id}\u0026#34; 23 ], 24 \u0026#34;dynamodb:Attributes\u0026#34;: [ 25 \u0026#34;UserId\u0026#34;, 26 \u0026#34;GameTitle\u0026#34;, 27 \u0026#34;Wins\u0026#34;, 28 \u0026#34;Losses\u0026#34;, 29 \u0026#34;TopScore\u0026#34;, 30 \u0026#34;TopScoreDateTime\u0026#34; 31 ] 32 }, 33 \u0026#34;StringEqualsIfExists\u0026#34;: { 34 \u0026#34;dynamodb:Select\u0026#34;: \u0026#34;SPECIFIC_ATTRIBUTES\u0026#34; 35 } 36 } 37 } 38 ] 39} ","date":"March 21, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/dynamodb-certification-note/","smallImg":"","tags":[{"title":"DynamoDB","url":"/tags/dynamodb/"}],"timestamp":1679356800,"title":"DynamoDB Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"Basic of S3 已 Object 為單位的儲存空間 ，而每個 Object 儲存在 Bucket 每 Object 的大小可以從 0 byptes to 5 TB，但 Bucket 沒有儲存中間上限 每個 S3 都會有獨立的 URL，這個是全球唯一的，所以 S3 建立後就無法修改 Region ，也不可以修改名字。 可以 Host 靜態頁面 如果要把 Object 變成公開的，需要先把 Bucket 設定為公開的，預設是私有的。 AWS CloudTrail 有存 API LOG 取得 S3 資訊的方法 API Amazon Direct Connect Storage Gateway Kinesis Firehouse Transfer Acceleration Snow Family (SnowBall, SnowBall Edge, Snow Mobile) 每個 Objects 包含基本資訊 Key (name of the object) Value Version ID Metadata Sub-resources Access Control Lists and Bucket Policies Torrent Data Consistency Read after Write consistency for PUTS of new Objects 每當建立新的物件後，直接去讀取物件會存在，並不會讀取不完整的物件 Eventual Consistency for overwrite PUTS and DELETES 因為 S3 一個物件存在多個地方，所以對舊有的物件做更新或刪除後立馬讀取的資訊有可能並非最新的。 Strong Consistency for overwrite PUTS and DELETES 保證在更新物件以後，拉到的資料是最新的 Tiered S3 Standard : 基本 S3 Infrequently Access : 比 Standard 便宜，但需要額外收 retrieval fee ，適合存放比較不常使用的物件 S3 One Zone Infrequently Access : 比 S3 IA 便宜，但只存在一個 AZ ，單點壞掉的風險比較大 S3 Intelligent : 透過物件 access 頻繁度，自動區分 Standard or IA Glacier : 每個物件在 Glacier 叫 Archive ，一個 Archive 空間上限是 40TB Archive 存在 Vaults 裡面 不能 real time 取得物件 ，都需要先做初始化 Retrieval 的動作 初始化到完成可以下載需要時間，等完成以後可以透過 SNS 通知 下載的 URL 是有時效性的，如果過期就需要再重新申請restore 預設所有的物件都會被 AWS AES-256 加密 也有 vault access policy 和 lock policy type S3 Glacier Retrieval Options Expedited : 最快但最貴，可以是 On-Demand 的也可以是 Provisioned (1-5 mins) Standard : 基本的 (3-5 hours) Bulk : 最慢，但最便宜 (5 to 12 hours) S3 Glacier Deep Archive Retrieval Options Standard : 基本的 (12 hours) Bulk : 最慢，但最便宜 (48 hours) S3 Standard S3 Intelligent S3 Standard IA S3 one zone IA S3 Glacier S3 Glacier Deep Archive Durability 99.99999999999 (11\u0026rsquo;s 9) 99. (11\u0026rsquo;s 9) 99. (11\u0026rsquo;s 9) 99. (11\u0026rsquo;s 9) 99. (11\u0026rsquo;s 9) 99. (11\u0026rsquo;s 9) Availability 99.99% 99.9% 99.9% 99.5% 99.99% 99.99% SLA 99.9% 99% 99% 99% 99.9% 99.9% AZ \u0026gt;= 3 \u0026gt;= 3 \u0026gt;= 3 =1 \u0026gt;= 3 \u0026gt;= 3 最小 Object Size收費單位 (小於這單位以這單位收錢） N/A N/A 128KB 128KB 40KB 40KB 最小收費存取時間 (存取時間小於這單位以這單位收錢) N/A 30 days 30 days 30 days 90 days 180 days Retrieval fee N/A N/A per GB per GB per GB per GB 功能 Lifecycle Management 可以設定現在版本或過去版本的Object N 天以後移動到不同的 Tiered 可以設定最新的版本只保留多久或多久後永久刪除 刪除超時未完成的 Multi-part 上傳 可以根據不同的 prefix or tag 設定 Versioning Bucket Level 功能 當物件被刪除時，會有 delete marker ，如果我們將 delete marker 刪除，物件又會回來 不可以關閉(disable) 只能暫停 (suspend) 物件大小計算是 全部 Versioning 的總和 新物件都會有 Version Id ，但如果是在開啟 Versioning 功能之前就上傳的物件會是 null Encryption Server Side Encryption 3 type SSE-AES : AWS 管理的 Key - header \u0026ldquo;x-amz-server-side-encrpytion\u0026rdquo; : \u0026ldquo;AES256\u0026rdquo; SSE-KMS : 透過 KMS Key - header \u0026ldquo;x-amz-server-side-encrpytion\u0026rdquo; : \u0026ldquo;aws:kms\u0026rdquo; SSE-C : 自己提供的 Key，S3 不會存取這個 Key ，透過 request Header 將 Key 提供給 S3 加解密 可以在 Bucket Level 開啟 Default Encryption 有 SSE-AES \u0026amp; SSE-KMS 可以選擇 可以透過 Bucket Policy 根據 header 強制要 Encryption Client Side Encryption Transfer Acceleration 透過 CloudFront Edge 加速上傳速度，會有不同的 endpoint Ex xxx.s3-accerate.amazonaws.com Cross Region Replication (CRR) or Same Region Replication (SRR) 自動備份到不同的 Region (不需要同 Account) ，但開啟功能前已存在的物件是不會備份的。 需要開啟 Versioning 的功能 如果是加密物件，備份到的 Bucket 也需要有加密 Key 的權限。 如果要備份 delete mark，需要額外設定 刪除 Version ID 不會備份去避免遭到惡意病毒攻擊 如果 Bucket1 備份到 Bucket2, 而 Bucket2 備份到 Bucket3, Bucket1 的備份不會到 Bcuket3 Pre-Signed URL 只能透過 CLI 或 SDK 產生，提供短暫有效的 URL URL 擁有的權限繼承產生 URL 的人 預設Timeout 一小時 1aws s3 presign s3:://mybucket/myobject --expires-in 300 (sec) MFA for Delete 刪除物件需要 MFA 驗證 需要打開 Versioning 的功能 只有 Root Account 可以打開或關閉這功能 ，只能透過 CLI or SDK 設定，沒辦法透過 Console Object Lock 主要達到 WORM (write object once, read many) 有兩種模式 Government model : 只有特殊權限的人，才可以修改物件 Compliance model : 在特定的時間內，任何人都無法修改物件 Glacier 也有 Glacier Vault Lock Bucket Policies 可以給予其他 AWS Account 權限 1{ 2 \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, 3 \u0026#34;Statement\u0026#34;: [ 4 { 5 \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, 6 \u0026#34;Principal\u0026#34;: { 7 \u0026#34;AWS\u0026#34;: [\u0026#34;arn:aws:iam::111122223333:user/Alice\u0026#34;, 8 \u0026#34;arn:aws:iam::111122223333:root\u0026#34;] 9 }, 10 \u0026#34;Action\u0026#34;: \u0026#34;s3:*\u0026#34;, 11 \u0026#34;Resource\u0026#34;: [\u0026#34;arn:aws:s3:::my_bucket\u0026#34;, 12 \u0026#34;arn:aws:s3:::my_bucket/*\u0026#34;] 13 } 14 ] 15} ACL 1\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; 2\u0026lt;AccessControlPolicy xmlns=\u0026#34;http://s3.amazonaws.com/doc/2006-03-01/\u0026#34;\u0026gt; 3 \u0026lt;Owner\u0026gt; 4 \u0026lt;ID\u0026gt;Owner-canonical-user-ID\u0026lt;/ID\u0026gt; 5 \u0026lt;DisplayName\u0026gt;display-name\u0026lt;/DisplayName\u0026gt; 6 \u0026lt;/Owner\u0026gt; 7 \u0026lt;AccessControlList\u0026gt; 8 \u0026lt;Grant\u0026gt; 9 \u0026lt;Grantee xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;CanonicalUser\u0026#34;\u0026gt; 10 \u0026lt;ID\u0026gt;Owner-canonical-user-ID\u0026lt;/ID\u0026gt; 11 \u0026lt;DisplayName\u0026gt;display-name\u0026lt;/DisplayName\u0026gt; 12 \u0026lt;/Grantee\u0026gt; 13 \u0026lt;Permission\u0026gt;FULL_CONTROL\u0026lt;/Permission\u0026gt; 14 \u0026lt;/Grant\u0026gt; 15 16 \u0026lt;Grant\u0026gt; 17 \u0026lt;Grantee xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;CanonicalUser\u0026#34;\u0026gt; 18 \u0026lt;ID\u0026gt;user1-canonical-user-ID\u0026lt;/ID\u0026gt; 19 \u0026lt;DisplayName\u0026gt;display-name\u0026lt;/DisplayName\u0026gt; 20 \u0026lt;/Grantee\u0026gt; 21 \u0026lt;Permission\u0026gt;WRITE\u0026lt;/Permission\u0026gt; 22 \u0026lt;/Grant\u0026gt; 23 24 \u0026lt;Grant\u0026gt; 25 \u0026lt;Grantee xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;CanonicalUser\u0026#34;\u0026gt; 26 \u0026lt;ID\u0026gt;user2-canonical-user-ID\u0026lt;/ID\u0026gt; 27 \u0026lt;DisplayName\u0026gt;display-name\u0026lt;/DisplayName\u0026gt; 28 \u0026lt;/Grantee\u0026gt; 29 \u0026lt;Permission\u0026gt;READ\u0026lt;/Permission\u0026gt; 30 \u0026lt;/Grant\u0026gt; 31 32 \u0026lt;Grant\u0026gt; 33 \u0026lt;Grantee xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;Group\u0026#34;\u0026gt; 34 \u0026lt;URI\u0026gt;http://acs.amazonaws.com/groups/global/AllUsers\u0026lt;/URI\u0026gt; 35 \u0026lt;/Grantee\u0026gt; 36 \u0026lt;Permission\u0026gt;READ\u0026lt;/Permission\u0026gt; 37 \u0026lt;/Grant\u0026gt; 38 \u0026lt;Grant\u0026gt; 39 \u0026lt;Grantee xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; xsi:type=\u0026#34;Group\u0026#34;\u0026gt; 40 \u0026lt;URI\u0026gt;http://acs.amazonaws.com/groups/s3/LogDelivery\u0026lt;/URI\u0026gt; 41 \u0026lt;/Grantee\u0026gt; 42 \u0026lt;Permission\u0026gt;WRITE\u0026lt;/Permission\u0026gt; 43 \u0026lt;/Grant\u0026gt; 44 45 \u0026lt;/AccessControlList\u0026gt; 46\u0026lt;/AccessControlPolicy\u0026gt; Access log 可以存放 Access Log 到另一個 S3 Bucket 如果要監控 BucketA ，不要將 BucketA 的 access log 寫到 BucketA 自己，會造成無限循環 S3 CORS (CROS Origin Resource Sharing) Origin 包含 protocol , domain, port EX: https://www.google.com =\u0026gt; protocol: https, domain: www.google.com, port 443 如果沒有 CORS Header ， Browser 會阻擋其他網站來 request 我們網站 Origin Header : Access-Control-Allow-Origin : origin Method Header : Access-Control-Allow-Methods : http_method (GET, PUT) 範例 如果 S3 BucketA 裡面的頁面要拉 S3 BucketB 的圖案，那 BucketB 需要打開 CORS Allow BucketA 來讀取。 1[ 2 { 3 \u0026#34;AllowedOrigins\u0026#34;: [\u0026#34; https://www.example.com \u0026#34;], 4 \u0026#34;AllowedMethods\u0026#34;: [\u0026#34;GET\u0026#34;], 5 \u0026#34;MaxAgeSeconds\u0026#34;: 3000, 6 \u0026#34;ExposeHeaders\u0026#34;: [] 7 \u0026#34;AllowedHeaders\u0026#34;: [Authorization\u0026#34;] 8 } 9] Inventory 可以產特定的 Bucket 每日或每週的 Metadata 報表存放到另一個同 Region 的 Bucket 報表格式可以是 CVS, ORC 或 Apache Parquet 可以用來 Auditing 加密狀態、統計 Object 數量等等 S3 \u0026 Glacier Select 如果 Object 是 Json 或 CVS 的格式，可以透過 SQL 的指令方式取出資料 可以減少流量的傳輸，因為已經在server side 過濾，並減少 Client Side 的 CPU (如果Client 要自己過濾） S3 Analytics 分析多少物件從 Standard 轉到 Standard_IA Report 每天更新，第一開始需要 24 - 48 小時初始化 Event Notification 當S3 更新物件或者是新增物件等等事件，可以發出 Event 給 Lambda, SNS, or SQS. S3 Access Endpoint 每個 Access Endpoint 都有獨立的 DNS 和 Policy 去限制誰可以access point policy 這個 S3 access point 流量可以從網路 或從 VPC S3 Batch Operation 一個 request 可以做多個指令 建立一個 Job ，裡邊包含要變動的物件從 (Inventory Report) 或特定格式的 CSV，然後指定特定的 Operation 複製到其他定方 Trigger Lambda Function 換 Tag 或 刪除 Tag 換 ACL 對 Glacier 物件申請恢復 加 或修改 Lock Performance S3 每多一個 prefix 3500 PUT/COPY/POST/DELETE qps 5,500 GET/HEAD qps Ex: https://s3.amazonaws.com/mybucket/prefix1/prefix2/myObject1 https://s3.amazonaws.com/mybucket/prefix1/prefix3/myObject2 https://s3.amazonaws.com/mybucket/prefix3/myObject3 https://s3.amazonaws.com/mybucket/prefix4/myObject4 如果 request 平均留到不同 prefix =\u0026gt; 那會有 3500 * 4 的PUT/COPY/POST/DELETE qps 如果 S3 的物件有透過 KMS 加密，qps 上限有可能受到 KMS 影響。 KMS 有每個region 有 quota qps，可以申請提高 Multipart Upload 建議超過 100 MB 就要使用 Multipart Upload ，如果物件 Size 超過 5GB 一定要使用 Byte Range Fetch 可以同時拉不同 Range 的 Object 下來，最後組成一個完成的 Object 整合其他 AWS 服務 DataSync : 將機器上大量物件上傳到 S3 ，並且可以週期性的上傳，需安裝 data sync agent Athena : 跟 S3 Select 一樣也是使用 SQL 的方式去拉取 S3 物件但是可以同時對大量的物件 ，S3 Select 一次只對單個物件。 Athena 是 Serveless，先將資料讀進 DB，然後再從 DB Query 資料出來 Macie: 使用 Machine Learning 去監測，是否有存取敏感性資料 如 個資 PII, 信用卡等 ","date":"February 2, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/s3-certification-note/","smallImg":"","tags":[{"title":"S3","url":"/tags/s3/"}],"timestamp":1675296000,"title":"S3 Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"Basic Resource Type : Config 是 Region Level 服務，預設存取當下 Region 下 Config 支援服務的全部設定，可以指定特定服務 可以存取 Global 服務的設定 所有 Config 紀錄存取到 S3 單一 Resource 可以看 Configuration Timeline detailed 包含 和其他服務的關係 改動的地方 CloudTail 整合 Event Rules 每一個 Rule 每個月有固定費用 ex 1 USD/Month AWS 已經有提供許多常見的 Rule ， 也可以客製化自己的 Rule - rule 是透過 Lambda 執行去檢查 Trigger Type Configuration Change : 每次更動都檢查 Periodic: 週期性檢查 檢查 Scope Resource Scope : 特定 Resource 例如 EC2 Tags: 特定 Tag All Changes Compliance Status: Noncompliant or compliant 單一 Resource 可以看 Compliance Timeline - 可以從 Timeline 看到 Rule 的 Status 改變 - 和其他服務的關係 - 改動的地方 SNS AWS Config 有 Streaming 的功能，可以將 Event 通知到 SNS 會通知的事件包含 Resource 的 Config 變動 歷史紀錄 或 Snapshot 上傳到 S3 Compliance 的結果 Compliance Rule 開始審核 AWS Config 跟 S3 互動失敗，例如上傳 Snapshot CloudWatch Event 可以偵測到 Event AWS API call via CloudTail Config Configuration Item Change Config Rules Compliance Change Config Rules Re-evaluation Status Config Configuration Snapshot Delivery Status Config Configuration History Delivery Status SSM Config 整合 System Manager Automation 可以嘗試自動修復 Noncompliant 資源 Advance Query Example 可以使用 SQL Query 1SELECT 2 resourceId, 3 resourceType, 4 configuration.instanceType, 5 configuration.placement.tenancy, 6 configuration.imageId, 7 availabilityZone 8WHERE 9 resourceType = \u0026#39;AWS::EC2::Instance\u0026#39; 10 AND configuration.imageId = \u0026#39;ami-12345\u0026#39; Aggregator View 可以整合多個 AWS Account 或多個 Region 下的 AWS Config 資訊 需要由一個 Main Config 建立 View，其他 Config 授權給 Main Config 就算是同一個 Account 但不同 Region。 例如要多個Region ，Main Config 在 JP 建立 Aggregator 並整合 US Config，在 US Config 下需要授權給 JP Config S3 允許 Config 權限的 Bucket Policy 1{ 2 \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, 3 \u0026#34;Statement\u0026#34;: [ 4 { 5 \u0026#34;Sid\u0026#34;: \u0026#34;AWSConfigBucketPermissionsCheck\u0026#34;, 6 \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, 7 \u0026#34;Principal\u0026#34;: { 8 \u0026#34;Service\u0026#34;: [ 9 \u0026#34;config.amazonaws.com\u0026#34; 10 ] 11 }, 12 \u0026#34;Action\u0026#34;: \u0026#34;s3:GetBucketAcl\u0026#34;, 13 \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::targetBucketName\u0026#34; 14 }, 15 { 16 \u0026#34;Sid\u0026#34;: \u0026#34;AWSConfigBucketExistenceCheck\u0026#34;, 17 \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, 18 \u0026#34;Principal\u0026#34;: { 19 \u0026#34;Service\u0026#34;: [ 20 \u0026#34;config.amazonaws.com\u0026#34; 21 ] 22 }, 23 \u0026#34;Action\u0026#34;: \u0026#34;s3:ListBucket\u0026#34;, 24 \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::targetBucketName\u0026#34; 25 }, 26 { 27 \u0026#34;Sid\u0026#34;: \u0026#34;AWSConfigBucketDelivery\u0026#34;, 28 \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, 29 \u0026#34;Principal\u0026#34;: { 30 \u0026#34;Service\u0026#34;: [ 31 \u0026#34;config.amazonaws.com\u0026#34; 32 ] 33 }, 34 \u0026#34;Action\u0026#34;: \u0026#34;s3:PutObject\u0026#34;, 35 \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::targetBucketName/[optional] prefix/AWSLogs/sourceAccountID-WithoutHyphens/Config/*\u0026#34;, 36 \u0026#34;Condition\u0026#34;: { 37 \u0026#34;StringEquals\u0026#34;: { 38 \u0026#34;s3:x-amz-acl\u0026#34;: \u0026#34;bucket-owner-full-control\u0026#34; 39 } 40 } 41 } 42 ] 43} ","date":"January 20, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/config-certification-note/","smallImg":"","tags":[{"title":"Config","url":"/tags/config/"}],"timestamp":1674172800,"title":"Config Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":" 實踐 Infrastructure as Code，不需要手動建立資源，而且可以對 Source Code 做 Version Control。 CloudFormation 本身是免費的，只需要付建立的資源費用即可。 可以透過 CloudFormation Designer 產生基本的架構圖 Template 必須要上傳到 S3 ，Template 格式可以是 Yaml or Json Stack 是由一個 Template 產生的包含多個資源，Stack 名字當作識別。 CloudFormation Template Section Parameters : 當要建立 Stack ，可以由外面設定動態參數 可設定資訊 Type: String, Number, CommaDelimitedList, List, AWS Parameter Description Constraints ConstraintDescription Min/MaxLength Defaults AllowedValues (array) AllowedPattern (regular expression) NoEcho(Boolean) 可以從 SSM 取得資料 1VpcId: !Ref MyVPC 2 3Parameters: 4 InstanceType: 5 Type: \u0026#39;AWS::SSM::Paramter::Value\u0026lt;String\u0026gt;\u0026#39; 6 Default: /EC2/InstanceType 7#there is public SSM parameters by AWS Conditions : 建立資源的條件 intrinsic function : Fn::And, Fn::Equals, Fn::If, Fn::Not, Fn::Or 1Conditions: 2\tCreateProdResources: !Equals [!Ref EnvType, prod] 3 4Resource: 5 MountPoint: 6 Type: \u0026#34;AWS::EC2::VolumeAttachment\u0026#34; 7 Condition: CreateProdResources Resource: 要建立的 AWS 資源，此為必要欄位 格式 : AWS::aws-product-name::data-type-name Mapping: 建立 Key Value Mapping 1Mapping: 2 RegionMap: 3 user-east-1: 4 \u0026#34;32\u0026#34; : \u0026#34;ami-aaa\u0026#34; 5 \u0026#34;64\u0026#34; : \u0026#34;ami-bbb\u0026#34; 6 user-east-2: 7 \u0026#34;32\u0026#34; : \u0026#34;ami-ccc\u0026#34; 8 \u0026#34;64\u0026#34; : \u0026#34;ami-ddd\u0026#34; 9 10ImagesId: !FindInMap [RegionMap, !Ref \u0026#34;AWS:Region\u0026#34;, 32] Transforms: 主要用於 Serve-less Application Model (SAM) ，宣告這是 SAM 的格式 Output: 可以將 Stack 建立的 Resource Output 出來，所以其他 Stack 可以建立 reference 如果被其他 Stack reference ，那就不能 delete 1Outputs: 2 StackSSHSecurityGroup: 3 Description: The SSH Security Group for our Company 4 Vaule: !Ref MyCompanyWideSSHSecurityGroup 5 Export: 6 Name: SSHSecurityGroup 7 8Resource: 9 MySecureInstance: 10 Type: AWS::EC2::Instance 11 Properties: 12 AvailabilityZone: us-east-1a 13 ImageId: ami-a5c7edb2 14 InstanceType: t2.micro 15 SecurityGroup: 16 - !ImportValue SSHSecurityGroup Metadata: 提供額外有關 Template 資訊 Intrinsic Functions Fn::Ref Parameters ⇒ 返回 parameter 對應的值 Resources ⇒ 返回資源的 physical ID Fn:GetAtt 1Resource: 2 EC2Instance: 3 Type: \u0026#34;AWS::EC2::Instance\u0026#34; 4 Properties: 5 ImageId: ami-1234567 6 InstanceType: t2.micro 7 8NewVolume: 9 Type: \u0026#34;AWS::EC2::Volume\u0026#34; 10 Confition: CreateProdResources 11 Properties: 12 Size: 100 13 AvailabilityZone: 14 !GetAtt EC2Instance.AvailabilityZone Fn::Join 1\u0026#34;Fn::Join\u0026#34; : [ \u0026#34;,\u0026#34;, [ \u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34; ] ] =\u0026gt; \u0026#34;a,b,c\u0026#34; Fn::Sub 1Fn::Sub: 2 - String 3 - Var1Name: Var1Value 4 Var2Name: Var2Value 5 6Name: !Sub 7 - www.${Domain} 8 - { Domain: !Ref RootDomainName }\tFn::Split 1!Split [ \u0026#34;|\u0026#34; , \u0026#34;a|b|c\u0026#34; ] =\u0026gt; [\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;] Fn::Select 1!Select [ \u0026#34;1\u0026#34;, [ \u0026#34;apples\u0026#34;, \u0026#34;grapes\u0026#34;, \u0026#34;oranges\u0026#34;, \u0026#34;mangoes\u0026#34; ] ] Fn::Base64 可以用在 EC2 pass 整個 script 在 user data user data script log ⇒ /var/log/cloud-init-output.log 1Resource: 2 EC2Instance: 3 Type: \u0026#34;AWS::EC2::Instance\u0026#34; 4 Properties: 5 ImageId: ami-1234567 6 InstanceType: t2.micro 7 UserData: 8 Fn::Base64: | 9 yum update -y 10 yum install -y httpd 11 systemctl start httpd 12 systemctl enable httpd 13 echo \u0026#34;Hello World from user data\u0026#34; \u0026gt; /var/www/html/index.html cfn-init \u0026 cfn-signal \u0026 cfn-hup AWS::CloudFormation::Init 目的是讓 EC2 的設定可讀性更高， 需要放在 metadata section init 的 log 會寫在 /var/log/cfn-init.log cfn-init \u0026amp; cfn-signal 流程 CloudFormation 先建立 EC2 Instance ，如果有設定 WaitCondition 這時 CloudFormation 會等待 EC2 這邊的 signal EC2 上面執行 User Data 時執行 cfn-init，這時 cfn-init 會去 CloudFormation 拉 metadata 的設定回來並執行 cfn-signal 用於執行完 cfn-init 告訴 CloudFormation 成功與否 沒有收到 Signal 怎麼辦 確認 Script 是否有安裝 可以disable rollback，進機器看 /var/log/cfn-init.log 和 /var/log/cloud-init-output.log 由於 Signal 必須透過 Internet 通知 CloudFormation ，確認 EC2 可以 Access Internet. cfn-hup : 是一個 daemon 去檢查是否有 metadata 要更新， Default Interval 是 15 分鐘 1Resource: 2 EC2Instance: 3 Type: \u0026#34;AWS::EC2::Instance\u0026#34; 4 Properties: 5 ImageId: ami-1234567 6 InstanceType: t2.micro 7 UserData: 8 Fn::Base64: | 9 yum update -y aws-cfn-bootstrap 10 # Start cfn-init 11 /opt/aws/bin/cfn-init -s ${AWS::StackId} -r MyInstance --region ${AWS::Region} || error_exit \u0026#39;Failed to run cfn-init\u0026#39; 12 13 # start the cfn-hup daemon 14 /opt/aws/bin/cfn-hup || error_exit \u0026#34;Failed to start cfn_hup\u0026#34; 15 # Start cfn-signal to the wait condition 16 /opt/aws/bin/cfn-signal -e $? --stack ${AWS::StackId} --resource SampleWaitCondition --region ${AWS::Region} 17 18Metadata: 19 Comment: Install a simple Apache HTTP page 20 AWS:CloudFormation::Init: 21 config: 22 packages: 23 yum: 24 httpd: [] 25 files: 26 \u0026#34;/var/www/html/index.html\u0026#34;; 27 content: | 28 \u0026lt;h1\u0026gt;Hello World from Ec2 Instance\u0026lt;/h1\u0026gt; 29 mode: \u0026#39;000644\u0026#39; 30 \u0026#34;/etc/cfn/cfn-hup.conf\u0026#34;: 31 content: !Sub | 32 [main] 33 stack=${AWS::StackId} 34 region=${AWS::Region} 35 interval=2 36 mode: \u0026#34;000400\u0026#34; 37 owner: \u0026#34;root\u0026#34; 38 group: \u0026#34;root\u0026#34; 39 40 \u0026#34;/etc/cfn/hooks.d/cfn-auto-reloader.conf\u0026#34;: 41 content: !Sub | 42 [cfn-auto-reloader-hook] 43 triggers=post.update 44 path=Resources.WebServerHost.Metadata.AWS::CloudFormation::Init 45 action=/opt/aws/bin/cfn-init -v --stack ${AWS::StackName} --resource WebServerHost --region ${AWS::Region} 46 mode: \u0026#34;000400\u0026#34; 47 owner: \u0026#34;root\u0026#34; 48 group: \u0026#34;root\u0026#34; 49 commands: 50 hello: 51 command: \u0026#34;echo \u0026#39;hello world\u0026#39;\u0026#34; 52 services: 53 sysvinit: 54 httpd: 55 enabled: \u0026#39;true\u0026#39; 56 ensureRunning: \u0026#39;true\u0026#39; 57 58SampleWaitCondition: 59 CreationPolicy: 60 ResourceSignal: 61 Timeout: PT1M #等一分鐘 62 Count:2 #要兩個成功的 Signal 63 Type: AWS::CoudFormation::WaitCondition CloudFormation Rollback Stack 建立失敗時，Stack 正常狀態會是 ROLLBACK_COMPLETE ，並且只能刪除不能更新 預設 : 所有的資源會 rollback ，但 Stack 還在，可以看原因 OnFailure=Rollback 可以 Disable rollback，所以可以做 troubleshooting OnFailure=DO_NOTHING 可以刪除整個 Stack OnFailure=Delete Stack 更新失敗 Stack 如果 rollback 成功 Stack 狀態會是 UPDATE_ROLLBACK_COMPLETE ，可以嘗試更新或刪除 Stack 如果 rollback 失敗 Stack 狀態會是 UPDATE_ROLLBACK_FAIL，可以嘗試修復問題再繼續 rollback Nested Stacks 可以重複使用其他 Stack 當作整個 Stack 一部分 1Resources: 2 myStack: 3 Type: AWS::CloudFormation::Stack 4 Properties: 5 TemplateURL: 6 xxx.com/... 7 Parameters: 8 key: value ChangeSet 可以在 CloudFormation 更新新的Template 之前先評估有什麼資源會變動，並確認是否要繼續執行，但執行了並不代表一定會成功。 Drift CloudFormation 建立的資源是沒有預防人為手動更新的 Drift 是用來檢查哪些資源跟當初 CloudFormation 建立的不一樣，並且告訴你哪些不同 \"不是所有的資源 Drift 都有支援。\" Deletion Policy 用來控制當 Stack 被刪除時特定資源要做的事情 三種 Policy DeletionPolicy=Retain: 預防資源被刪除 DeletionPolicy=Snapshot: 先將資料備份再刪除 Support: EBS Volume, ElasticCache, Cluster, ElasticCache, ReplicationGroup, RDS DBInstance, RDS DBCluster, Redshift Cluster DeletionPolicy=Delete 刪除資源，但並非都會刪除成功，例如 S3 Bucket 裡面有 Object 就會刪除失敗 RDS 預設 Snapshot , 其他預設 Delete Termination Protection 用於保護 Stack 不會被不小心刪除 Creation Policy \u0026 Update Policy 像 Auto Scaling Group 可以需要啟多個 Ec2 Instance，這時 Creation Policy 就可以設定在 Auto Scaling Group，要收時間內收多少個 Signal 才算成功 UpdatePolicy 如果直接更新 template 中的 user data，Auto Scaling Group 裡面的 EC2 還會是舊的 user data。 UpdatePolicy Attribute 可以使用在三種 AWS Resource auto scaling group 有三種 Policy\nAutoScalingReplacingUpdate: WillReplace可以用來決定建立全新的 Auto Scaling Group 取代舊，還是單純建立新的 Instance 來取代現有的 Instance 但 Auto Scaling Group 還是舊的。 AutoScalingRollingUpdate: 在 Auto Scaling Group，將現有的 EC2 Instance 停掉，並建立新的取代 AutoScalingScheduledAction 1Resources: 2 AutoScalingGroup: 3 Type: AWS::AutoScaling::AutoScalingGroup 4 Properties: 5 AvailabilityZones: 6 Fn::GetsAZs: 7 Ref: \u0026#34;AWS::Region\u0026#34; 8 LaunchConfigurationName: 9 Ref: LaunchConfig 10 Desiredcapacity: \u0026#39;3\u0026#39;\u0026#39; 11 MinSize: \u0026#39;1\u0026#39; 12 MaxSize: \u0026#39;4\u0026#39; 13 CreationPolicy: 14 ResourceSignal: 15 Count: \u0026#39;3\u0026#39; 16 Timeout: PT15M 17 UpdatePolicy: 18 ## Example1 start 19 AutoScalingRollingUpdate: 20 MinInstancesInService: \u0026#39;1\u0026#39; 21 MaxBatchSize: \u0026#39;2\u0026#39; 22 #how much time to wait for the signal 23 PauseTime: PT1M 24 WaitOnResourceSignals: \u0026#39;true\u0026#39; 25 ## 預防CloudFormation 有排程去 update min,max or desired size 26 AutoScalingScheduledAction: 27 IgnoreUnmodifiedGroupSizeProperties: \u0026#39;true 28 ## Example1 end 29 ## Example1 and Example2 不會同時存在 30 31 ## Example 2 start 32 ## 會建立全新的 Auto Scaling Group 取代舊得 33 AutoScalingReplacingUpdate: 34 WillReplace: \u0026#39;true\u0026#39; 35 ## Example 2 end 36 37LaunchConfig: 38 Type: AWS::AutoScaling::LaunchConfiguration 39 Properties: 40 ImageId: ami-aaa 41 InstanceType: t2.micro 42 UserData: 43 Fn::Base64: | 44 yum update -y 45 yum install -y httpd 46 systemctl start httpd 47 systemctl enable httpd 48 echo \u0026#34;Hello World from user data\u0026#34; \u0026gt; /var/www/html/index.html lambda alias\nCodeDeployLambdaAliasUpdate 1UpdatePolicy: 2 CodeDeployLambdaAliasUpdate: 3 AfterAllowTrafficHook: String 4 ApplicationName: String 5 BeforeAllowTrafficHook: String 6 DeploymentGroupName: String elastic cache replication group\nUseOnlineResharding 1UpdatePolicy: 2EnableVersionUpgrade: Boolean Depends ON 控制資源建立的順序，以下面為例，EC2 Instance 需要在 RDS 建立好以後才建立 1Resources: 2 Ec2Instance: 3 Type: AWS::EC2::Instance 4 Properties: 5 ImageId: 6 Fn::FindInMap: 7 - RegionMap 8 - Ref: AWS::Region 9 - AMI 10 DependsOn: myDB 11 myDB: 12 Type: AWS::RDS::DBInstance Stack Policy 像是 IM Policy ，可以用來控制哪些 Resource 可以做什麼，哪些不能做什麼 1{ 2 \u0026#34;Statement\u0026#34; : [ 3 { 4 \u0026#34;Effect\u0026#34; : \u0026#34;Allow\u0026#34;, 5 \u0026#34;Action\u0026#34; : \u0026#34;Update:*\u0026#34;, 6 \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, 7 \u0026#34;Resource\u0026#34; : \u0026#34;*\u0026#34; 8 }, 9 { 10 \u0026#34;Effect\u0026#34; : \u0026#34;Deny\u0026#34;, 11 \u0026#34;Action\u0026#34; : \u0026#34;Update:*\u0026#34;, 12 \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34;, 13 \u0026#34;Resource\u0026#34; : \u0026#34;LogicalResourceId/ProductionDatabase\u0026#34; 14 } 15 ] 16} StackSets 可以一次更動多個 Region 或多個 Account 的 Stack 只有 Administrator Account 可以建立 StackSets Trust Account 可以更新 StackSets 每次更動 StackSets 設定，全部的 Stack 都會被更新 可以刪除整個 StackSets 或單獨刪除 StackSets 裡面的一個 Stack Custom Resource 由於不是所有的 AWS Resource, CloudFormation 都有支援，所以有時需要透過 Lambda Function 去 call api 當 CloudFormation 在 Create, Update or delete 時都會觸發 Lambda Function Delete S3 Custom Resource Lambda Function 1Resources: 2 LambdaExecutionRole: 3 Type: AWS::IAM::Role 4 Properties: 5 AssumeRolePolicyDocument: 6 Version: \u0026#39;2012-10-17\u0026#39; 7 Statement: 8 - Effect: Allow 9 Principal: 10 Service: 11 - lambda.amazonaws.com 12 Action: 13 - sts:AssumeRole 14 Path: \u0026#34;/\u0026#34; 15 Policies: 16 - PolicyName: root 17 PolicyDocument: 18 Version: \u0026#39;2012-10-17\u0026#39; 19 Statement: 20 - Effect: Allow 21 Action: 22 - \u0026#34;s3:*\u0026#34; 23 Resource: \u0026#34;*\u0026#34; 24 - Effect: Allow 25 Action: 26 - \u0026#34;logs:CreateLogGroup\u0026#34; 27 - \u0026#34;logs:CreateLogStream\u0026#34; 28 - \u0026#34;logs:PutLogEvents\u0026#34; 29 Resource: \u0026#34;*\u0026#34; 30 31 EmptyS3BucketLambda: 32 Type: \u0026#34;AWS::Lambda::Function\u0026#34; 33 Properties: 34 Handler: \u0026#34;index.handler\u0026#34; 35 Role: 36 Fn::GetAtt: 37 - \u0026#34;LambdaExecutionRole\u0026#34; 38 - \u0026#34;Arn\u0026#34; 39 Runtime: \u0026#34;python3.7\u0026#34; 40 # we give the function a large timeout 41 # so we can wait for the bucket to be empty 42 Timeout: 600 43 Code: 44 ZipFile: | 45 #!/usr/bin/env python 46 # -*- coding: utf-8 -*- 47 import json 48 import boto3 49 from botocore.vendored import requests 50 51 def handler(event, context): 52 try: 53 bucket = event[\u0026#39;ResourceProperties\u0026#39;][\u0026#39;BucketName\u0026#39;] 54 55 if event[\u0026#39;RequestType\u0026#39;] == \u0026#39;Delete\u0026#39;: 56 s3 = boto3.resource(\u0026#39;s3\u0026#39;) 57 bucket = s3.Bucket(bucket) 58 for obj in bucket.objects.filter(): 59 s3.Object(bucket.name, obj.key).delete() 60 61 sendResponseCfn(event, context, \u0026#34;SUCCESS\u0026#34;) 62 except Exception as e: 63 print(e) 64 sendResponseCfn(event, context, \u0026#34;FAILED\u0026#34;) 65 66 67 def sendResponseCfn(event, context, responseStatus): 68 response_body = {\u0026#39;Status\u0026#39;: responseStatus, 69 \u0026#39;Reason\u0026#39;: \u0026#39;Log stream name: \u0026#39; + context.log_stream_name, 70 \u0026#39;PhysicalResourceId\u0026#39;: context.log_stream_name, 71 \u0026#39;StackId\u0026#39;: event[\u0026#39;StackId\u0026#39;], 72 \u0026#39;RequestId\u0026#39;: event[\u0026#39;RequestId\u0026#39;], 73 \u0026#39;LogicalResourceId\u0026#39;: event[\u0026#39;LogicalResourceId\u0026#39;], 74 \u0026#39;Data\u0026#39;: json.loads(\u0026#34;{}\u0026#34;)} 75 76 requests.put(event[\u0026#39;ResponseURL\u0026#39;], data=json.dumps(response_body)) 77 78Outputs: 79 StackSSHSecurityGroup: 80 Description: The ARN of the Lambda function that empties an S3 bucket 81 Value: !GetAtt EmptyS3BucketLambda.Arn 82 Export: 83 Name: EmptyS3BucketLambda Custom Resource with lambda function 1--- 2AWSTemplateFormatVersion: \u0026#39;2010-09-09\u0026#39; 3 4Resources: 5 myBucketResource: 6 Type: AWS::S3::Bucket 7 8 LambdaUsedToCleanUp: 9 Type: Custom::cleanupbucket 10 Properties: 11 ServiceToken: !ImportValue EmptyS3BucketLambda 12 BucketName: !Ref myBucketResource CloudFormation Request Example 1{ 2 \u0026#34;RequestType\u0026#34; : \u0026#34;Create\u0026#34;, 3 \u0026#34;ResponseURL\u0026#34; : \u0026#34;http://pre-signed-S3-url-for-response\u0026#34;, 4 \u0026#34;StackId\u0026#34; : \u0026#34;arn:aws:cloudformation:us-west-2:123456789012:stack/stack-name/guid\u0026#34;, 5 \u0026#34;RequestId\u0026#34; : \u0026#34;unique id for this create request\u0026#34;, 6 \u0026#34;ResourceType\u0026#34; : \u0026#34;Custom::TestResource\u0026#34;, 7 \u0026#34;LogicalResourceId\u0026#34; : \u0026#34;MyTestResource\u0026#34;, 8 \u0026#34;ResourceProperties\u0026#34; : { 9 \u0026#34;Name\u0026#34; : \u0026#34;Value\u0026#34;, 10 \u0026#34;List\u0026#34; : [ \u0026#34;1\u0026#34;, \u0026#34;2\u0026#34;, \u0026#34;3\u0026#34; ] 11 } 12} ","date":"January 12, 2023","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/cloudformation-certification-note/","smallImg":"","tags":[{"title":"CloudFormation","url":"/tags/cloudformation/"}],"timestamp":1673481600,"title":"CloudFormation Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":" CloudTail 主要用於監控和稽核 AWS 資源的 API Call Trails 每個 Region 上限五個 Type All Region : 所有的 Region Event Log 存在一個 S3 Bucket One Region : 指定特定 Region Event Log Organization Trail : 可以 Log 整個 AWS Organization 的 Event，只有 management account. 也可以 Cross Account Trail，原理是設定 S3 Bucket Policy 給予每個 AWS Account 權限，每個 Tail 的 Log 放入同一個 S3 可以發送 SNS Events Type Management events: AWS 服務操作，又分為 Read, Write 兩種 Type 預設Log， 最近 90 的 Log 是免費的，可以直接在 Event History 內查看 Type example Read: EC2 的 DescribeSecurityGroups Write: EC2 的 TerminateInstances Data event : 操作特定 AWS 服務裡的資源，例如 S3 GetObject, DynamoDB PutItem or Lambda Invoke 預設沒啟用，須額外收費 如果是全球性的服務例如 IAM, STS 等等，Log 是放到 US East (N. Virginia) Region Event History 可以根據時間區間或以下屬性做 filter Event name, User name, Resource name, Event source, Event ID, and Resource type. Security 有 Log File Validation ，可以檢查刪除和修改 刪除會顯示 not found 錯誤 修改會顯示 hash value doesn\u0026rsquo;t match 可以整合 CloudWatch Log ，去監控特定事件，發出 Alert S3 預設使用 AWS AES key 加密，可以改用 KMS AWSCloudTrail_FullAccess 限制只有少數人，擁有這個權限 ","date":"December 20, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/cloudtail-certification-note/","smallImg":"","tags":[{"title":"CloudTail","url":"/tags/cloudtail/"}],"timestamp":1671494400,"title":"CloudTail Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":" Route53 是 AWS 的 Domain Name System (DNS)，名字中有 53 的原因是因為 DNS 的 Port 是 53。 Route53 也是一個 DNS Register ，可以在上面購買 Domain Name TTL (Time to Live) : 單位為秒，告訴 Browser 去 Cache Response 的 Record 多少時間。 主要 Component Hosted Zone 包含所有 Record 資訊 會自動建立 Name Server 和 SOA records Public hosted Zone : 解析互聯網的 Request Private hosted Zone : 解析Amazon上內部的 Request VPC 需要設定 enableDnsHostnames \u0026amp; enableDnsSupport Name Server 主要轉換 Hostname to IP DNS Basic Records Record Name 描述 A. Hostname to IPv4 AAAA. Hostname to IPv6 CNAME Hostname to Hostname Alias Hostname to AWS resource MX. Email PTR 反向解析 A record IPv4 to Hostname NS. Name Server SOA 主要記錄網域名稱伺服器的名稱和負責人資訊 Alias V.S. Cname 功能 Cname Alias Example app.domain.com =\u0026gt; xxx.otherDomain.com app.domain.com =\u0026gt; elbxx.amazon.com ROOT DOMAIN 只能是 non root domain Ex: 不可以是 domain.com =\u0026gt; xxx.otherDomain.com non root \u0026amp; root domain 都可以 Routing Policy Policy 描述 是否有 Health Check Simple Routing Policy 如果有多筆值 ，會隨機返回一個 X Weight Routing Policy 根據 Weight (%) 來分流 V Latency Routing Policy AWS 會返回延遲最小的值 V Failover Routing Policy 有 Primary 和 Secondary，如果 Primary health check pass 就會返回 Primary 否則返回 Secondary V GeoLocation Routing Policy 根據 User IP 地理位置 來決定返回哪個值 V Geo proximity Routing Policy 根據 User 地址位置外加 Bias 值 Ex:us-west-1 \u0026amp; us-east-1 都在 us ，如果有設定 bias ， bias 高的會有比較多的 request V Multi Value Routing Policy 回覆多筆值 ，瀏覽器自己選一個值去發送請求 (request) V Health Check Type endpoint IP or Domain 支援協議 : TCP, HTTP, HTTPS 預設檢查區間 : 30 秒，最快可以 10 秒 進階可以設定根據 Response 內容前 5120 Bytes 是否有包含預期的 String 有 N 次檢查不過 =\u0026gt; Unhealthy Status 已經有 N 次檢查過 =\u0026gt; healthy Status 可以產生 Latency 圖 大約有 15 檢查者（checker) 從不同地方檢查 ，所以 endpoint 不能是 private 的 (如VPC內 calculated health check 根據其他 Health check 來計算 cloudWatch alarms Others 可以只用第三方 DNS Register 註冊的 Domain ，將第三方的 Domain 的 Name Server 設定為 Route53 的 Name Server。 Router53 Domain 指向 S3 - bucket name 需要跟 url 一樣 for http : 建立 Alias Record 指向 S3, 並且 S3 需要是 Public 和 開啟 website 功能 for https : 需要使用 CloudFormation ","date":"December 5, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/route53-certification-note/","smallImg":"","tags":[{"title":"Route53","url":"/tags/route53/"}],"timestamp":1670198400,"title":"Route53 Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":" Lambda 是 AWS 無伺服器的運算服務，以下幾點為 AWS 端的責任 Capacity Provisioning OS Patching Auto Scaling High Availability Basic Setting Memory usage 會影響 CPU timeout 設定，最多十五分鐘 role to execute the function 收費根據以下三點 Request 數量 Lambda Function 處理 request 的時間 執行 Lambda Function 的資源 Memory \u0026amp; CPU size Components of Lambda Function: Source Code 存在 S3 Runtimes: 執行環境 Layers: 可以放 dependency file. 預設限制 75 GB and 5 Layers Event Source: 觸發 Lambda 的 Event Downstream resources: 這個 Lambda Function 要 Access 的資源 Log Streams: Lambda 已經整合 CloudWatch Environment variables Versions and aliases Event Source Data Source S3, DynamoDB, Kinesis, Cognito, Aurora Endpoint API Gateway, Step Function, IOT Repository CloudWatch, CloudFormation, CloudTail, CodeCommit Message Service SES, SNS, SQS CloudWatch Log Streams Invocations: 五分鐘區間，Lambda 被建立的次數 Duration: 執行時間，有提供平均、最大和最小 Error count and success rate (%): 成功和失敗比率 Throttles: 多少個 request 失敗是因為瓶頸 IteratorAge: For stream event sources, the age of the last item in the batch when Lambda received it and invoked the function. Async delivery failures: 非同步時多少 request 進入錯誤 和寫到 dead-letter queue，可以放到 SNS or SQS. Concurrent executions: 同時有多少個 ㄑunction 正在執行 Environment variables 可以透過 KMS 加 可也從 SSM 取得 Versions and aliases 只可以更改或update $LATEST Aliases 可以設定 Weight 來分流到不同版本 Security IAM Resource Policy: 執行 Lambda Function 的權限 IAM Execution Role: Lambda call 其他 AWS 服務需要的權限 Lambda 可以在特定的 VPC 內運行 Concurrency 預設每個 Region 上限是 1000，所以 Lambda Function 共用的，可申請調高 當達到瓶頸時，Lambda 會返回 429 too many requests 可以設定以下兩種 Concurrency Reserved Concurrency: 特定 Function 保留執行數量，也是這個 Function 最大上限，但其他 Function 不能使用這數量 Provisioned Concurrency: 預先初始化的數量 Synchronous v.s. Asynchronous Synchronous: Lambda 會回覆 Response 執行結果 Asynchronous: Lambda 會回覆 Client 已經收到，並會執行，失敗會進入到 dead-letter queue Warm Start v.s. Cold Start 整合其他 AWS 服務 Amazon EFS : Lambda Function 可以 mount EFS 當 Local File System Amazon Gateway API : 提供 Http or Https API X-Ray: 追中整個 Request Data Flow. AWS CodePipeline: 客製化 Task Lambda@Edge: 整合 CloudFront ，可以在Edge 做客製化例如透過Lambda 在Edge 就做身份驗證 Parameter Store : 當多個 Lambda Function 需要共用參數。 ","date":"November 13, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/lambda-certification-note/","smallImg":"","tags":[{"title":"LAMBDA","url":"/tags/lambda/"}],"timestamp":1668297600,"title":"Lambda Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":" 可以用來管理 EC2 或是 On-Prime 的機器 需要安裝 SSM Agent 在機器上 AWS Linux AMI 和部分 Ubuntu AMI 預設已經裝好 Agent 了。 EC2 需要有 IAM Rule 的權限根 SSM 溝通 Patch 自動化 支援 Windows or Linux 可以整合 CloudWatch 和 AWS Config Resource Group 不只是適用於 EC2，也可以適用於其他 AWS 服務如 S3, Lambda 等等 使用 AWS Tag 的功能，根據 Key Value 將 Resource grouping 起來。 Ex: Environment 的 value 等於 Production 時候 也可以根據 CloudFormation Stack 來 Grouping Documents 一個 Documents 定義一些 Parameters \u0026amp; Actions (執行一些 commands) Documents 可以是 Json 或 Yaml 格式 兩種Type Run Command (Script) \u0026amp; Automation (AWS API) Run Command Run command 可以配合 Resource Group 一次對多台機器執行 Documents (Script) ，也可以手動指定特定機器執行 有 Rate 控管可以控管一次同時更新幾台 resource 。也有 Error 控管， 更新過程中失敗多少 resource 就中止。 Resource 可以使用百分比或指定固定數量來定義。 可以透過 IAM \u0026amp; CloudTail 知道誰執行的 EC2 是透過 SSM Agent 執行的，EC2 可以不需要 Allow SSH 執行結果可以在 Console 上看到，或存到 S3 或 CloudWatch Logs 可以透過 SNS 發送 Status 可以整合倍 EventBridge Trigger Automation 主要用於簡化維護和部署 EC2 或 AWS 其他服務 Automation runbook 就是 Documents 主要執行一些 AWS Resource 的 API ，例如 EC2 的 stop。 可以被 Trigger 的方式 AWS Console, Cli or SDK EventBridge 透過 Maintain Windows 排成 AWS Config Remediation 可以用來建立 AMI，AWS 有提供 AWS-UpdateLinuxAmi 和 AWS-UpdateWindowsAmi Parameter Store 可以安全地存取 Configuration \u0026amp; Secrets ，並且有版本控制 可以透過 KMS 加密 透過 IAM 和 Path 控管 可以整合 CloudFormation 有 CloudWatch Event get-parameters cli 如果有加密資料預設返回的是密文，需另透過 KMS 解密。但也可以透過 \u0026ndash;with-decryption 這個參數直接返回明文，需要有 KMS 權限 Parameter policy 可以設定 TTL 去 通知 或 delete parameters 三種 Policy Expiration : 指定時間刪除 Parameter ExpirationNotification : 可以設定快過期通知 NoChangeNotification : 可以設定通知，如果 Parameters 在指定時間內都未更新 Example 1{ 2 \u0026#34;Type\u0026#34;:\u0026#34;Expiration\u0026#34;, 3 \u0026#34;Version\u0026#34;:\u0026#34;1.0\u0026#34;, 4 \u0026#34;Attributes\u0026#34;:{ 5 \u0026#34;Timestamp\u0026#34;:\u0026#34;2018-12-02T21:34:33.000Z\u0026#34; 6 } 7} 8 9{ 10 \u0026#34;Type\u0026#34;:\u0026#34;ExpirationNotification\u0026#34;, 11 \u0026#34;Version\u0026#34;:\u0026#34;1.0\u0026#34;, 12 \u0026#34;Attributes\u0026#34;:{ 13 \u0026#34;Before\u0026#34;:\u0026#34;15\u0026#34;, 14 \u0026#34;Unit\u0026#34;:\u0026#34;Days\u0026#34; 15 } 16} 17 18{ 19 \u0026#34;Type\u0026#34;:\u0026#34;NoChangeNotification\u0026#34;, 20 \u0026#34;Version\u0026#34;:\u0026#34;1.0\u0026#34;, 21 \u0026#34;Attributes\u0026#34;:{ 22 \u0026#34;After\u0026#34;:\u0026#34;20\u0026#34;, 23 \u0026#34;Unit\u0026#34;:\u0026#34;Days\u0026#34; 24 } 25} 兩種付費模式 功能\\模式 Standard Advanced 每個 Region parameter 上限 10,000 100,000 parameters size 上限 4k 8k parameters policy x v storage cost free $0.05 per parameter / mother standard throughput free $0.05/ 10,000 API high throughput (1000 api / second) $0.05/10,000 API $0.05/10,000 API Inventory 收集 EC2 or On-premises 機器上的資訊包含 :已安裝的軟體, OS drivers 和 設定 或 正在執行的 services。並可以透過這些資料做稽核 可以設定資料更新的時間區間為 分、秒或小時 可以將資料存在 S3 透過 Athena 來分析 可以建立客製化 Inventory ，拉特定資訊 State Manager 定義一個 State (Configration)，讓所有指定的機器維持在定義的 State 例如 State 可以是 關閉 ssh (port 22) Patch Manager 自動更新和修補機器 可以做 OS 升級，Application 升級，或者一些 Security 相關的升級 可以是一次性，或者透過 Maintain Windows 來排程。 可以掃描所有管理的機器並產出 compliance report Patch Baseline : 可以定義哪些 patch 應該 或 不應該 裝在機器上 Patch Group : 將多台機器 Grouping 起來並執行 Patch Baseline 一台機器只能有一個 Patch Group，一個 Patch Group 只能綁定一個 Patch Baseline 透過 AWS Tag key \u0026ldquo;Patch Group\u0026rdquo; 去 Grouping Maintenance Window 排程去執行任務 例如 更新 Instance 上的 操作系統、軟體等等 Maintenance Window 包含了 排程(Schedule) 期間(Duration) 一組機器 一組要執行的任務 任務(task) 可以是 Run Command Automation Lambda Step Function Session Manager 可以建立安全的 Shell 到 EC2 or On-premises，不需要開始 SSH (port 22) 會 Log 所有的指令 支援 Windows 、 Linux 或 MacOS Session Log 可以存在 S3 或 CloudWatch 可以透過IAM 限制哪個 User/Group 可以連到哪個 Instance 或是 Reousrce Tag ","date":"October 27, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/ssm-certification-note/","smallImg":"","tags":[{"title":"SystemsManager","url":"/tags/systemsmanager/"}],"timestamp":1666828800,"title":"Systems Manager (SSM) Certification Note"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"Sup 立式划槳體驗 因為預訂了日出團的 Sup 所以一大早五點就起床，騎車到集合地點，結果發現只有我跟我女友而已，算是直接被我們包場了！教練是一位女生，她很細心的教我們怎麼划槳怎麼前進後退控制方向還有轉彎，接著我們穿好救生衣就出發到海邊～到海邊以後，現場就有許多其他團的人都在準備出發，教練簡單在出發前再複習划槳動作確認我們都會划後，我們就坐在 Sup 上慢慢划出海！划大約十分鐘後太陽就漸漸升起，教練開始用她的手機幫我們拍照，我們的手機因為怕落水都放在岸上～不過因為這團只有我們所以教練就專門為我們拍照 xD 拍完照後開始嘗試站起來在 Sup 上划，但我挑戰多次都失敗站起來，最後最長也只站了大約十秒鐘而倒了 QAQ\n洪媽媽早餐 划完 Sup 後，教練推薦我們可以吃洪媽媽早餐。因為 Sup 體驗只有一小時，所以結束時還不到八點，想說應該沒什麼人，結果到現場人山人海! 洪媽媽早餐是採取自助式的，拿自己想要吃的然後到櫃檯結帳。看了一圈不知道吃什麼，就買了當地特色早點琉球粿。現場也沒有提供位子吃，所以我們就帶回民宿去吃。由於今天太早起來，吃完以後就犯睏稍微補眠一下 xD\n蜜仔琉部 睡醒來後在 Google Map 找了一下評價不錯的蜜仔琉部當午餐！到了現場還沒開門但卻已經很多人在排隊了，因為我們並還不是在第一批可以進去用餐的，只能先登記候位。接著我們到一旁的 7-11 等候，不錯的是這間 7-11 比較大間，有二樓提供桌椅可以坐著等。等餐廳通知我們能到店用餐後，才發現餐廳店門上已經掛著暫停候位的牌子，還好沒有睡太晚，不然就吃不到了！\n今日分別點了: 蕃茄海鮮義大利麵、蒜香蝦蝦飯和熱烏龍奶茶。蜜仔琉部的料很敢給，蕃茄海鮮義大利麵前面一排放滿了蝦子，後面還有一隻螃蟹。而蒜香蝦蝦飯的蝦也鋪滿在飯上面～熱烏龍奶茶還特別有拉花。整體很好吃，所以我覺得 CP 值很高。\n花園鰻雞蛋糕 原本這間雞蛋糕是昨天就要想吃的，但我們騎車騎了老半天都沒有找到，當下有在 IG 上私訊老闆剛好也沒有看到 QAQ 等老闆回覆時我們已經回到民宿了，所以有跟老闆訂今天下午的，只是沒想到蜜仔琉部吃的很飽。到現場時老闆剛好正在做我們的雞蛋糕，做出來的形狀就是花園鰻的樣子，由於肚子吃太飽了，所以感覺味道就一般。\n小琉球環島 接著我們就騎著車慢慢沿著海線繞小琉球環島一圈，過程中還遇到路霸羊羊，還好我們是騎機車就從一旁繞過去，如果是開車的話就比較麻煩了。最後稍微晃了一下免稅店，原本打算買瓶酒，但現場人實在太多，不想排隊就打消念頭了！\n王匠生魚片 繞完一圈，我們就坐船回屏東東港碼頭，想說碼頭的海鮮都很新鮮，我們就在一旁的華僑市場 228 攤的王匠生魚片點了份生魚片～真的超新鮮的～ 吃完就回台北，過完吃的一天行程。\n","date":"October 23, 2022","img":"/posts/travel/2022_kaohsiung_liuqiu_island_day3/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/travel/2022_kaohsiung_liuqiu_island_day3/feature_hu06c3fc70fa611124d49e20071a89ee2a_582238_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/travel/2022_kaohsiung_liuqiu_island_day3/","smallImg":"/posts/travel/2022_kaohsiung_liuqiu_island_day3/feature_hu06c3fc70fa611124d49e20071a89ee2a_582238_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"TRAVEL","url":"/tags/travel/"}],"timestamp":1666483200,"title":"2022 高雄 小琉球 三天兩夜之 Day3"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"搭船到小琉球 原本在網路上已經有購買拼車，是從高雄車站到屏東東港碼頭~ 但產品描述沒有很清楚，我們以為方案是從高雄車站拼車直接出發到碼頭，但沒想到中途是還要先去高鐵站接人！外加我們已經跟民宿訂好潜水體驗，我們不能搭太晚的船班，所以最後只好改搭計程車前往碼頭。第二個不幸的是原本以為買了幾點的時間就一定會搭上那艘船，但因為現場人太多了，所以滿了就發船，我們最後沒有搭上11:20的藍白一號！我們就趕快和民宿老闆說有可能會敢不上原本預訂的潜水體驗，不過老闆還很好心的跟我們說沒關係，慢慢來～好加在，因為人太多了，也有加開班次，所以有搭上藍白二號！\n海龜相遇 這是第一次體驗潜水，過去只有浮淺經驗而已。在潜水之前有做跟健康方面的問卷調查，教練看到我有填寫氣喘，然後有詢問了我一些基本的問題，認為沒什麼問題後就放我過了～ 接著教練就開始教我們怎麼使用氧氣瓶在水底呼吸，然後教一些在水底使用的手勢以便溝通。接著換裝完畢就到海邊。在等到揹氧氣瓶的時候，要帶我的教練還特別跑來問我說 會不會緊張，我說原本不會，但被你一問，反而緊張起來了！接著換我揹氧氣瓶，氧氣瓶比我想像中的還要重許多！在走路去海邊的過程中，讓我更加擔心。不過後來下水看到海龜們太治癒了，都完全都不緊張了，而且海底竟然還有國旗🇹🇼最後看到教練幫我們拍的照片，就覺得值得啦！\n小琉球騎車趴趴走 潜水完上來第一件事情就是肚子好餓，在沖洗完以後就跑去吃老李蔥油餅～剛下船要去民宿的路上就看到很多人在排隊，只是當時趕著要去潜水體驗所以就只好先無視XD 老李蔥油餅很特別，跟我們一般時吃得扁扁橢圓形的不太一樣，它竟然是長條形的。\n吃完後又沿著海邊分別跑去了美人洞、花瓶石和旭日亭\n晚餐與民宿 晃了一下就已經接近晚上了，民宿有包晚餐，結果我們不小心把時間記錯了，整整晚了半個小時才到，到的時候已經差不多客滿了！艾倫馬上開啟肥仔模式開吃！晚上小琉球沒什麼地方可以去，就回到民宿結束今天這回合～\n","date":"October 22, 2022","img":"/posts/travel/2022_kaohsiung_liuqiu_island_day2/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/travel/2022_kaohsiung_liuqiu_island_day2/feature_hu26db14124b797375e13e490a88b8c727_171262_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/travel/2022_kaohsiung_liuqiu_island_day2/","smallImg":"/posts/travel/2022_kaohsiung_liuqiu_island_day2/feature_hu26db14124b797375e13e490a88b8c727_171262_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"TRAVEL","url":"/tags/travel/"}],"timestamp":1666396800,"title":"2022 高雄 小琉球 三天兩夜之 Day2"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"台北到高雄 一大清早七點多，艾倫就醒來洗漱(普通時上班都沒這麼早起來），就搭著捷運到台北火車站，準備坐高鐵南下。 第一站: 耶魯小鎮餐廳 到高雄的第一站，當然是先吃午餐！\n由於之前有次很想吃在加拿大時常吃的 Poutine，所以那時候在網上查詢時，那時就查到高雄這有位在加拿大居住很久的台灣人，在高雄開的加拿大餐廳。\n由於天氣實在太熱，所以艾倫只點了最想吃的 Poutine 和木碗沙拉。\nPoutine 義式生火腿乳酪沙拉 吃完後離開餐廳剛好遇到街道消毒，滿地的🪳到處跑！真的是崩潰，而且我感覺好像有蟑螂飛到我的手上…. 我趕快甩了一下，但由於地上已經很多🪳了，不是非常確定是不是我的錯覺… 反正趕快跑去隔壁的sogo洗手\n第二站: 金獅湖蝴蝶園 第二站金獅湖蝴蝶園，這是一個完全免費的園區，由於艾倫是請假下去，所以幾乎是包場！ 裡面的大白斑蝴蝶超多，就一直瘋狂拍 第三站: 逍遙園 一個1939年的老別館，後來重建過後開放參觀，裡面保留部分日治時代的裝潢 ![逍遙園2]逍遙園2.webp?width=1024px#center)\n第四站: 果貿社區 一個很特別的國宅，竟然是弧形兩排圍成一圈！ 第五站: 駁二藝術特區 剛好遇上最後一週的台灣設計展！原本是想說晚餐點隨便晃晃的，看到這指示牌後就知道要在這待很久\n入島沒多久就看到火車，有種來到遊樂園的感覺\n一個很適合拍網紅照的設計\n一個很酷的文字設計，正面看是 Japan ，但轉過來就變成台灣\n中間有個很酷的酒吧，時間到會換顏色\n未來的台灣，覺得設計很立體，很酷炫\n現場實在還有太多太多，可惜時間不夠，因為本來就只是打算來晃晃，不是為了設計展而來，但如果認真逛，可以逛一整天呢！\n第六站: 瑞豐夜市 艾倫不是第一次來到瑞豐夜市，但卻是第一次逛瑞豐夜市！\n大學時曾來過一次，第一次來的時候被瑞豐夜市上了一課，原來不是所有台灣的夜市都是每天都開\n因為在駁二逛太久了，所以在駁二吃了樂檸漢堡填肚子，沒有太餓就買了東山鴨頭回飯店吃，結果！忘了南部都吃甜的，好不習慣 QAQ\n終點站: Sam 的家 最後一站，今日住宿 85 大樓 Sam 的家，整體住的還不錯，隔音還行，不會聽到隔壁的吵鬧。\n","date":"October 21, 2022","img":"/posts/travel/2022_kaohsiung_liuqiu_island_day1/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/travel/2022_kaohsiung_liuqiu_island_day1/feature_hu354d1c4cabe196d8fc2ab26c8d4ca830_22302_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/travel/2022_kaohsiung_liuqiu_island_day1/","smallImg":"/posts/travel/2022_kaohsiung_liuqiu_island_day1/feature_hu354d1c4cabe196d8fc2ab26c8d4ca830_22302_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"TRAVEL","url":"/tags/travel/"}],"timestamp":1666310400,"title":"2022 高雄 小琉球 三天兩夜之 Day1"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"Basic Beanstalk 是 PAAS 服務，可以透過 Config (.ebextensions) 設定去建立環境，例如基本的 Three Tire Architecture : Client -\u0026gt; Server -\u0026gt; DB，而我們只需要專注在 Application 上的開發 Beanstalk 本身是免費的，只需要付原本底下的資源費用 例如 EC2, ELB 等等 支援多個 Programming Language ，也支援 Docker 有 Deployment 策略 和 Rollback 策略 可以備份現在的設定 (Save Configuration) 環境設定的順序 高到低 直接環境設定 Save Configuration .ebextensions 設定 Default Value 可以設定 Management Updated 可以排成固定時間去做 patch 可以選擇是直接更新舊的，還是先建立一台新的機器安裝好去取代 Swap URL ，透過此功能做到 Blue/Green Deployment ，底層是更改 Router53 Record Multi-Container 底層是用ECS 做到 Basic Of Components Application Application Version Deploy Code 放在 S3，指向特定 S3 Object Version Version 有上限，可以透過 Application Life Cycle Policy 去刪除舊的 Version 可以設定上限多少 Version 要存和保留多少天 也可以設定 Source 是否要保留在 S3 Environment Tire Web Server: Worker: 在上面執行一些程式，例如可以是SQS 的 Puller ，將 Queue 裡面資料拉下來處理。有 Auto Scaling Group 可以根據 SQS Queen Number 去做 Auto Scaling Environment Types 單一 Instance Environment Load-balancing, Autoscaling Environment: for web server Autoscaling Only : for worker Tire . ebextensions 建立 Resource 注意 Resource 如果透過 Beanstalk 一起建立的話，砍掉環境時也會跟著一起砍掉，所以 Storage 的部分最好分開建立，例如 RDS。 1Resources: 2 DynamoDBTable: 3 Type: AWS::DynamoDB::Table 4 Properties: 5 KeySchema: 6 HashKeyElement: 7 AttributeName: id 8 AttributeType: S 9 # create a table with the least available rd and wr throughput 10 ProvisionedThroughput: 11 ReadCapacityUnits: 1 12 WriteCapacityUnits: 1 13 14 NotificationTopic: 15 Type: AWS::SNS::Topic 16 17Outputs: 18 NotificationTopicArn: 19 Description: Notification topic ARN 20 Value: { \u0026#34;Ref\u0026#34; : \u0026#34;NotificationTopic\u0026#34; } 21 22option_settings: 23 aws:elasticbeanstalk:application:environment: 24 # these are assigned dynamically during a deployment 25 NOTIFICATION_TOPIC: \u0026#39;`{\u0026#34;Ref\u0026#34; : \u0026#34;NotificationTopic\u0026#34;}`\u0026#39; 26 DYNAMODB_TABLE: \u0026#39;`{\u0026#34;Ref\u0026#34; : \u0026#34;DynamoDBTable\u0026#34;}`\u0026#39; 27 AWS_REGION: \u0026#39;`{\u0026#34;Ref\u0026#34; : \u0026#34;AWS::Region\u0026#34;}`\u0026#39; Command v.s Container Command commands : 是在 Ec2 Instance 上執行，並且在 Application Code unpacked之前，按照英文名字順序執行 container_commands : 是在 Application code unpacked 之後，但在部署之前，可以用來修改 source code leader_only : 由 Beanstalk 決定單一 instance 當 Leader 執行，並且會比其他沒有 leader_only 的 command 早執行，主要用在只能或只需要執行一次的 Command。 1 create_hello_world_file: 2 command: touch hello-world.txt 3 cwd: /home/ec2-user 4 5container_commands: 6 modify_index_html: 7 command: \u0026#39;echo \u0026#34; - modified content\u0026#34; \u0026gt;\u0026gt; index.html\u0026#39; Deployment Policy Policy 描述 推失敗影響 推機速度 推幾時是否有 Downtime 是否需要修改 DNS Record Rollback 方式 All at once 一次全部機器直接推機 Downtime 最快 有 否 需重新推舊的Version Rolling 一次下掉幾台線上機器，裝好新的code 在重新上線。 只有正在推的那幾台會壞掉，線上有可能會部分機器是新的 Code ，部分機器是舊的 Code 比 All at once 慢 無 否 需重新推舊的Version Rolling with an additional batch 跟 Rolling 差不多，差別在於是先建立全新的機器推完機以後，在取代線上的 除了一開始推壞沒上線已外，其他跟 Rolling Policy 一樣 比 Rolling 慢 無 否 需重新推舊的Version Immutable 建立全新的 Auto Scaling Group，然後將流量轉到新的 Auto Scaling Group 比較沒有，因為可以先測試全新的 Auto Scaling Group 才切換 慢 無 無 切回流量到舊的 Auto Scaling Group Traffic Splitting 根據權重慢慢的將流量切到新的機器上 取決於流量的權重 慢 無 無 將權重切回到舊的 Blue/Green 透過 DNS Record 切換流量 比較小，因為是全新的一組機器 Ready 才切 慢 無 是 重新設定 DNS Record 指向舊的機器 ","date":"October 4, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/beanstalk-certification-note/","smallImg":"","tags":[{"title":"Beanstalk","url":"/tags/beanstalk/"}],"timestamp":1664841600,"title":"Beanstalk Certification Note"},{"categories":[{"title":"LIFE","url":"/categories/life/"}],"content":"購買契機 艾倫之前在海外就讀大學，大學時期是使用 Amazon 的閱讀器 Kindle。由於 Kindle 的中文書一直很少，所以艾倫回台後一直有考慮更換其他平台的閱讀器。今日去誠品書局取線上預購書時，剛好看到剛推出的 Kobo Clare 2E 正在打活動送1200的購書金，加上遇上誠品南西店的週年慶，而且剛好現場有現貨。最重要這款 Kobo 的大小剛好跟我原本的 Kindle 一樣都是6寸大小，就這樣噴了 5000 塊新台幣。\n活動和優惠 Kobo Clare 2E 1200 購書金 在九月三十號以前購買 Kobo Clara 2E 有購書金\n誠品南西週年慶 800 禮卷 活動資訊: 全館 （不含美妝香氛專櫃）當日累計滿5,000送800\n內含｜全館$500電子抵用券×1張+指定服配$200電子抵用券×1張＋指定餐飲$100電子抵用券×1張\n雖然指定服配對艾倫沒有用，但由於艾倫還算經常去誠品吃飯和買書，所以全館 500 和指定 100 餐飲卷算還行。 誠品金卡續卡 100 元 艾倫剛好上個月才續金卡會員，有收到 100 元禮卷剛好可以折抵\nKobo Clara 2E 4500 + 原廠的磁感應保護殼 899 - 誠品 100 續卡金 = 5299\nKobo Clara 2E 開箱 戰利品合照 內盒中的 Kobo Clara Kobo Clara 2E(左) v.s Kindle (右) 裝上殼的 Kobo Clara 2E OverDrive 借書 Kobo 有整合 OverDrive ，而 OverDrive 有整合台北市立圖書館，所以可以直接在 Kobo 上面借一些書。不過目前 OverDrive 的書籍比較少，而且都是英文書為主。 注意: 需要有台北市立圖書館的會員\n第一步：到設定頁面 第二步: 點選 OverDrive 第三步: 點選 OverDrive 旁邊的 開始 第四步: 登入 OverDrive 如果有註冊台北市立圖書館的話\n卡號預設是身份證字號 密碼是生日日期（月和日四碼） 第五步: 在探索裡面有 OverDrive 選項 第六步: 艾倫下載完一本書的閱讀範例 ","date":"September 25, 2022","img":"/posts/unboxing/kobo_clara_2e/feature.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"/posts/unboxing/kobo_clara_2e/feature_hu9befe0ed2921d1478d88b4ddbb902b46_1868084_500x0_resize_q75_h2_box_2.webp","permalink":"/posts/unboxing/kobo_clara_2e/","smallImg":"/posts/unboxing/kobo_clara_2e/feature_hu9befe0ed2921d1478d88b4ddbb902b46_1868084_180x0_resize_q75_h2_box_2.webp","tags":[{"title":"開箱文","url":"/tags/%E9%96%8B%E7%AE%B1%E6%96%87/"}],"timestamp":1664064000,"title":"Kobo Clare 2E 開箱文"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":" CodeDeploy 是 AWS 部署服務，類似 Ansible, Chef, Puppet 等等 要部署的機器上面需要安裝 CodeDeploy Agent, Agent 會一直從 CodeDeploy 拉需要執行的動作 Support Ec2, Lambda, ECS Basic Step of EC2 需要部署的機器上面需要安裝 CodeDeploy Agent Agent 會一直嘗試從 CodeDeploy 拉需要做的工作 CodeDeploy 會提供 appspec.ymal 要安裝的程式會從 S3 (IAM Role 需要 S3 權限）或 Github 等地方拉下來，並開始安裝 CodeDeploy Agent 會回覆成功或失敗 部署 EC2 如果 Source 從 S3 ， IAM Role 需要 S3 權限 和 需要有 Versioning Deployment Type In Place: 現有的機器會下線，安裝好新版本，再重新上線。 下線的數量取決於 Deployment configuration Environment : Auto Scaling Group, EC2 或 On-premises Blue/Green: 會建立新的 Instance 取代舊的，必須要有 ELB 在 EC2 前面 預設 Deployment configuration CodeDeployDefault.AllAtOnce CodeDeployDefault.HalfAtTime CodeDeployDefault.OneAtTime Trigger v.s. Cloud Watch Event Trigger 是 CodeDeploy 內建，可以根據特定事件發送 SNS Cloud Watch Event 由 CloudWatch 監控事件，觸發其他 AWS 服務 Rollback Manual Rollback : 手動直接部署舊的版本 Automatic Rollback 有兩種選擇 Rollback when deployment failed : 任何一個部署失敗，就自動 rollback 全部 Rollback when alarms thresholds are met: 這邊整合 Cloud Watch Alarm 部署 On-Premises Instance 用 IAM User (只適合單台機器） 建立有 S3 權限的 IM User ，並取得 access key 在機器上建立 codedeploy.onpremises.yml 將 access key 放入 安裝 AWS CLI \u0026amp; CodeDeploy Agent call register api 1 aws deploy register-on-premises-instance --instance-name AssetTag12010298EX --iam-user-arn arn:aws:iam::444455556666:user/CodeDeployUser-OnPrem 可以對 CodeDeploy 上的 on-premises instance 加上 tags ，並透過 tag 建立 deployment group 用 IAM Role 建立 IAM Role 擁有 S3 權限 建立 IAM User 有 STS 權限，可以 assume-role 在機器上建立 codedeploy.onpremises.yml 1--- 2iam_session_arn: iam-session-arn 3aws_credentials_file: credentials-file 4region: supported-region call register-on-premises-instance api 1aws deploy register-on-premises-instance --instance-name name-of-instance --iam-session-arn arn:aws:sts::account-id:assumed-role/role-to-assume/session-name 可以對 CodeDeploy 上的 on-premises instance 加上 tags ，並透過 tag 建立 deployment group 部署 Lambda Function Deployment configuration Canary: 分兩次切流量，可以設定百分比決定一次要切多少流量到新的版本，當第一次正常沒問題就切剩下的全部流量到新的版本 Linear: 固定時間區間和固定百分比增長流量到新的版本 All-at-once: 一次全部切換 appspec.ymal 1version: 0.0 2os: operating-system-name 3files: 4 source-destination-files-mappings 5permissions: 6 permissions-specifications 7hooks: 8 deployment-lifecycle-event-mappings EC2 or On-Premises Instance Hook Basic ApplicationStop: 服務停止前 DownloadBundle: 下載新版本的檔案到機器上臨時文件夾 BeforInstall : 開始安裝前，可以先安裝一些或執行程式 Install: 從臨時文件夾安裝到實際文件夾 AfterInstall : 可以修改一些設定或修改一些檔案權限等 ApplicationStart: 服務重啟 ValidateService: 驗證服務 如果有 ELB BeforeBlockTraffic: 從 ELB 下掉之前 BlockTraffic: 停止流量到 Instance AfterBlockTraffic: : 從 ELB 下掉之後 BeforeAllowTraffic: 在上回 ELB 之前 AllowTraffic: 開始接流量 AfterAllowTraffic: 在上回 ELB 之後 實際順序 BeforeBlockTraffic BlockTraffic AfterBlockTraffic ApplicationStop DownloadBundle BeforeInstall Install AfterInstall ApplicationStart ValidateService BeforeAllowTraffic AllowTraffic AfterAllowTraffic Lambda Function Hook BeforeAllowTraffic BlockTraffic AfterBlockTraffic Environment Variable APPLICATION_NAME DEPLOYMENT_ID DEPLOYMENT_GROUP_NAME : 程式可以根據 Group 來判斷要做的事情，例如不同環境 DEPLOYMENT_GROUP_ID LIFECYCLE_EVENT: Hook 名字 ","date":"September 18, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/codedeploy-certification-note/","smallImg":"","tags":[{"title":"CodeDeploy","url":"/tags/codedeploy/"}],"timestamp":1663459200,"title":"CodeDeploy Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"Basic Stage 裡面可以有許多 Action， Stage 跟 Stage 之間是可以關聯的 runOrder 可以用來決定順序性， 預設是1 ，同樣的 runOrder 代表同時跑 Artifacts: S3 預設使用 AWS/S3 key 加密，但可以選擇使用 KMS 也可以建立一個 S3 的 Action ， Copy artifacts 到其他 S3 Bucket CodePipeline 可以透過 ColudFormation 建立 Action Approval Action: 可以設定需要 Manual Approval 才可以進去執行\nSource Action : GitHub, CodeCommit, S3, ECR\nCodePipeline 監測改變選擇 根據 CloudWatch Events CodePipeline 週期性去檢查 Build Action : CodeBuild, and Jenkins\nDeploy Action: AWS CodeDeploy, Beanstalk, CloudFormation, ECS\n可以建立不同 Region 的同時部署 CloudFormation 可以執行 Create or update a stack Delete a stack Replace a failed stack Create or replace a change set execute a change set 特定指定 S# template Invoke Action : 觸發 Lambda Function\nTest Action: CodeBuild, Jenkins and or open source\n可以設定 Input artifacts and output artifacts Custom Action: 需要建立一個 Job Worker 去執行程式\nExample sequenceDiagram CodePipeline-\u003e\u003e+CodeCommit: Trigger loop CodeCommit-\u003e\u003e CodeCommit: package source code end CodeCommit-\u003e\u003e+S3 : push to artifacts CodeCommit-\u003e\u003e+CodePipeline:Success CodePipeline-\u003e\u003e+CodeBuild: Trigger CodeBuild-\u003e\u003e+S3: pull artifacts loop CodeBuild-\u003e\u003e CodeBuild: build end CodeBuild-\u003e\u003e+S3: push to artifacts CodeBuild-\u003e\u003e+CodePipeline:Success CodePipeline-\u003e\u003e+CodeDeploy: Trigger CodeDeploy-\u003e\u003e+Instance: Deploy ","date":"September 18, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/codepipeline-certification-note/","smallImg":"","tags":[{"title":"CodePipeline","url":"/tags/codepipeline/"}],"timestamp":1663459200,"title":"CodePipeline Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"CodeBuild Basic AWS 託管 Build Service類似 Jenkins。可以編譯，跑單元測試，或者打包 package 到 artifacts. 根據 運行力 和 執行時間來計價 Build Log 可以送到 CloudWatch or S3 CodeBuild 是使用 Docker 技術，所以可以在 Local 執行。也可以客製化個人 Docker Image 去當 Build 環境 Source 可以從 Github, CodeCommit, S3, Bitbucket 和 Github Enterprise 拉 可以設定 Build Timeout 或 Queue Timeout 也可以設定特定 VPC 執行 AWS 有預設 Environment Variable ，也可以客製化個人的環境變數 Cloud Watch Monitor Metrix type Succeeded Builds Sum Failed Builds Sum Build Sum Duration Average 可以根據 Matrix 設定 Alert 通知 CloudWatch Event 可以設定 Scheduler 去觸發 Build 可以聽特定 Event 去 Trigger 其他 AWS 服務 類似 Lambda , SNS 等等 Buildspec Example Java Package to Artifacts 1version: 0.2 2 3env: 4 variables: 5 JAVA_HOME: \u0026#34;/usr/lib/jvm/java-8-openjdk-amd64\u0026#34; 6 parameter-store: 7 LOGIN_PASSWORD: /CodeBuild/dockerLoginPassword 8 9phases: 10 install: 11 commands: 12 - echo Entered the install phase... 13 - apt-get update -y 14 - apt-get install -y maven 15 finally: 16 - echo This always runs even if the update or install command fails 17 pre_build: 18 commands: 19 - echo Entered the pre_build phase... 20 - docker login -u User -p $LOGIN_PASSWORD 21 finally: 22 - echo This always runs even if the login command fails 23 build: 24 commands: 25 - echo Entered the build phase... 26 - echo Build started on `date` 27 - mvn install 28 finally: 29 - echo This always runs even if the install command fails 30 post_build: 31 commands: 32 - echo Entered the post_build phase... 33 - echo Build completed on `date` 34 35reports: 36 arn:aws:codebuild:your-region:your-aws-account-id:report-group/report-group-name-1: 37 files: 38 - \u0026#34;**/*\u0026#34; 39 base-directory: \u0026#39;target/tests/reports\u0026#39; 40 discard-paths: no 41 reportGroupCucumberJson: 42 files: 43 - \u0026#39;cucumber/target/cucumber-tests.xml\u0026#39; 44 discard-paths: yes 45 file-format: CUCUMBERJSON # default is JUNITXML 46artifacts: 47 files: 48 - target/messageUtil-1.0.jar 49 discard-paths: yes 50 secondary-artifacts: 51 artifact1: 52 files: 53 - target/artifact-1.0.jar 54 discard-paths: yes 55 artifact2: 56 files: 57 - target/artifact-2.0.jar 58 discard-paths: yes 59cache: 60 paths: 61 - \u0026#39;/root/.m2/**/*\u0026#39; Buildspec Example Build Docker Image to ECR 1version: 0.2 2 3phases: 4 pre_build: 5 commands: 6 - echo Logging in to Amazon ECR... 7 - aws ecr get-login-password --region $AWS_DEFAULT_REGION | docker login --username AWS --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com 8 build: 9 commands: 10 - echo Build started on `date` 11 - echo Building the Docker image... 12 - docker build -t $IMAGE_REPO_NAME:$IMAGE_TAG . 13 - docker tag $IMAGE_REPO_NAME:$IMAGE_TAG $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG 14 post_build: 15 commands: 16 - echo Build completed on `date` 17 - echo Pushing the Docker image... 18 - docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_DEFAULT_REGION.amazonaws.com/$IMAGE_REPO_NAME:$IMAGE_TAG 使用 Code Build 驗證 Code Commit Pull Request 原始 AWS 文章 Validating AWS CodeCommit Pull Requests with AWS CodeBuild and AWS Lambda\n","date":"September 13, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/codebuild-certification-note/","smallImg":"","tags":[{"title":"CodeBuild","url":"/tags/codebuild/"}],"timestamp":1663027200,"title":"CodeBuild Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"Basic AWS 的 Git Version Control 服務，像是 Github 可以跟 CodeBuild 、 Jenkins 或者其他 CI 整合 可以透過 HTTPS or SSH connect，可以建立 IAM User 並在裡面設定 ssh key https git credential (user name and password) 可以透過 CloudTail 監控哪個 IAM User 在操作什麼 Repository 每個 Repository 沒有 Size 限制 可以建立 Notification Rule ，根據設定的 Event 發出 SNS SNS 必須跟 CodeCommit 在同一個 Region 可以建立 Event Trigger 觸發 SNS 或 Lambda 可以給予其他 AWS Account User 讀取權限 可以透過 KMS 加密 Repository 裡面的 File Pull Request 可以整合 CodeGuru Review，在 pull request 建立時，可以透過 CodeGuru 去分析 Code 並抓出常見問題。 建立 approval rules ，指定的 User 才可以 Merge pull request 1aws codecommit create-pull-request-approval-rule \\ 2--pull-request-id 27 \\ 3--approval-rule-name \u0026#34;Require two approved approvers\u0026#34; \\ 4--approval-rule-content \u0026#34;{\\\u0026#34;Version\\\u0026#34;: \\\u0026#34;2018-11-08\\\u0026#34;,\\\u0026#34;Statements\\\u0026#34;: [{\\\u0026#34;Type\\\u0026#34;: \\\u0026#34;Approvers\\\u0026#34;,\\\u0026#34;NumberOfApprovalsNeeded\\\u0026#34;: 2,\\\u0026#34;ApprovalPoolMembers\\\u0026#34;: [\\\u0026#34;CodeCommitApprovers:123456789012:Nikhil_Jayashankar\\\u0026#34;, \\\u0026#34;arn:aws:sts::123456789012:assumed-role/CodeCommitReview/*\\\u0026#34;]}]}\u0026#34; 也可以建立 approval rules template 並重複使用，綁定在不同 repository 上 1aws codecommit create-approval-rule-template \\ 2--approval-rule-template-name 2-approver-rule-for-main \\ 3--approval-rule-template-description \u0026#34;Requires two developers from the team to approve the pull request if the destination branch is main\u0026#34; \\ 4--approval-rule-template-content \u0026#34;{\\\u0026#34;Version\\\u0026#34;: \\\u0026#34;2018-11-08\\\u0026#34;,\\\u0026#34;DestinationReferences\\\u0026#34;: [\\\u0026#34;refs/heads/main\\\u0026#34;],\\\u0026#34;Statements\\\u0026#34;: [{\\\u0026#34;Type\\\u0026#34;: \\\u0026#34;Approvers\\\u0026#34;,\\\u0026#34;NumberOfApprovalsNeeded\\\u0026#34;: 2,\\\u0026#34;ApprovalPoolMembers\\\u0026#34;: [\\\u0026#34;arn:aws:sts::123456789012:assumed-role/CodeCommitReview/*\\\u0026#34;]}]}\u0026#34; 透過 IAM 限制 Push \u0026 Merge Master 1{ 2 \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, 3 \u0026#34;Statement\u0026#34;: [ 4 { 5 \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, 6 \u0026#34;Action\u0026#34;: [ 7 \u0026#34;codecommit:GitPush\u0026#34;, 8 \u0026#34;codecommit:DeleteBranch\u0026#34;, 9 \u0026#34;codecommit:PutFile\u0026#34;, 10 \u0026#34;codecommit:MergeBranchesByFastForward\u0026#34;, 11 \u0026#34;codecommit:MergeBranchesBySquash\u0026#34;, 12 \u0026#34;codecommit:MergeBranchesByThreeWay\u0026#34;, 13 \u0026#34;codecommit:MergePullRequestByFastForward\u0026#34;, 14 \u0026#34;codecommit:MergePullRequestBySquash\u0026#34;, 15 \u0026#34;codecommit:MergePullRequestByThreeWay\u0026#34; 16 ], 17 \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:codecommit:us-east-2:111111111111:MyDemoRepo\u0026#34;, 18 \u0026#34;Condition\u0026#34;: { 19 \u0026#34;StringEqualsIfExists\u0026#34;: { 20 \u0026#34;codecommit:References\u0026#34;: [ 21 \u0026#34;refs/heads/main\u0026#34;, 22 ] 23 }, 24 \u0026#34;Null\u0026#34;: { 25 \u0026#34;codecommit:References\u0026#34;: \u0026#34;false\u0026#34; 26 } 27 } 28 } 29 ] 30} IAM Policy AWSCodeCommitFullAccess : Admin 權限 AwSCodeCommitPowerUser: 不可以建立和刪除 repository AWSCodeCommitReadOnly: 只可以讀資訊 ","date":"September 13, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/codecommit-certification-note/","smallImg":"","tags":[{"title":"CodeCommit","url":"/tags/codecommit/"}],"timestamp":1663027200,"title":"CodeCommit Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"Basic of VPC 每個 Region 預設上限五個 VPC 支援 IPv4 or IPv6 每個 VPC 可以有五個 CIDR ，每個 CIDR 最大 /16 (65536 IP) , 最小 /28 (16 IP) VPC 是 私有網路，所以只有以下 Range 是允許的 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 要注意，VPC CIDR 不能跟其他已存在網住重疊 AWS 有預留五個 IP ex: 10.0.0.0/24 =\u0026gt; 256 個 IP 減去預設五個，實際只有251 個 IP 可使用 10.0.0.0 : Network Address 10.0.0.1 : 預設給 VPC Router 10.0.0.2 : 預設給 DNS 10.0.0.3 : 先預留，暫時無使用 10.0.0.255 : Network broadcast address，但 AWS 不支援 如果你需要 29 IP， Submask不可以選 /27 ， /27 雖然有 32 個 IP ，但扣除五個預留的以後，只剩下 27 個 IP Route Table VPC 都有一個預設 Main Route Table 每個 Route Table 都有預設 Local Route 如果建立 Subnet 時，沒有指定自定義 Route Table，都會自動使用 Main Route Table Default VPC 新帳號每個 Region 都會有 Default VPC，IP Range 172.31.0.0/16 Default Subnet 的 Subnet Mask 是 /20 Default VPC 已經有 Main Route Table 而且設定好 Internet Gateway 在 Default VPC 啟用的 EC2 會自動 assign Public IPv4 IP Default Network Access List =\u0026gt; Allow all inbound/outbound Traffic 有預設 DHCP Internet Gateway 一個 VPC 只能連結一個 Internet Gateway Internet Gateway 同時也是 Network Address Translation (NAT)，有 IPv4 地址 支援 IPv4 \u0026amp; IPv6 Nat Gateway v.s Instance NAT 主要轉換 Private IP to Public IP，讓 Private Subnet EC2 可以單向連上網路 Private Subnet EC2 \u0026ndash;\u0026gt; NAT \u0026ndash;\u0026gt; IGW \u0026ndash;\u0026gt; Internet 都必須在 Public Subset 只支援 IPv4 功能 NAT Gateway NAT Instance Available AWS 託管服務，建立在一個 AZ，有 HA，但如果只有一個NAT gateway ，有可能因為一整個 AZ 掛掉而沒有網路 自己需要管控 Failover，如果只有一台壞掉就沒有網路 頻寬 從 5Gbps 到最高 45 Gbps. 取決於 Instance Type Maintains AWS 管理 需要自己升級內部軟體和操作系統等等 Cost. 取決於用量和頻寬 取決於 Instance Type Public IP Elastic IP. Elastic IP or Public IP Security Group X V EC2 設定 X 需要關閉 EC2 的 Source/ Destination Check Egree Only Internet Gateway 只支援 IPv6 跟 NAT Gateway 相似，但 NAT Gateway 只支援 IPv4 NCAL v.s Security Group . NCAL Security Group Scope 一個 Subnet 一個 NCAL 一個 Instance 最多五個 Security Group 特性 Stateless: inbound \u0026amp; outbound 都需要特別設定 Stateful: 只驗進出並記錄 request ，讓 response 可以返回 Default VPC 建立的 預設允許所有的 inbound \u0026amp; outbound X 手動建立的 預設不允許任何 inbound \u0026amp; outbound 預設沒有任何 Allow 設定 可以設定 Allow 或 DENY ，另外有 rule 的概念 ，rule range (1-32766) 數字越低越優先，Ex: #100 Allow x, #200 DENY x 最後是 ALLOW 只能設定 Allow 不能 DENY Securit Group 可以 Reference 其他 Security Group VPC Peering 透過 AWS 私有網路連結兩個 VPC 兩個VPC CIDR 不能重疊 VPC Peering 不是 transitive EX : VPC_A \u0026lt;\u0026mdash;VPC Peering\u0026mdash;\u0026gt; VPC_B \u0026lt;\u0026mdash;VPC Peering\u0026mdash;\u0026gt; VPC_C VPC_A 不能透過 VPC_B 連到 VPC_C ，如果需要連線，就要在 VPC_A \u0026amp; VPC_C 中間再建立一個 VPC Peering 才可以互相連到 VPC Peering 不限制在同一個 Region 也不限制在同一個 AWS 帳號下的 VPC VPC Peering 設定完，還需要設定 Route Table 才可以連線 兩個 VPC 不能有重疊的 CIDR VPC Endpoint 主要解決 VPC 內部的 Instance 可以透過 AWS 私有網路不必透過公有網路連到其他AWS 託管服務 如 S3, DynamoDB 等等 兩種 Type Interface : 透過 AWS PrivateLink 去連到 其他 AWS 服務。 Endpoint : Server Side 需要使用 Load Balancer 而 Client Side 需要使用 Elastic Network Ineterface 中間透過 PrivateLink 去連起來 gateway : 提供特定目標，目前只有 S3, DynamoDB ，自動設定 Route Table 設定 Flow Log 擷取傳入及傳出 VPC 中網路界面之 IP 流量相關資訊的功能 VPC Flow log Subnet Flow Log Elastic Network Interface Flow log 日誌可以存在 S3 (可以整合 Athena 去 Query) / CloudWatch Log DNS support in VPC enableDnsSupport 設定預設是 True AWS DNS Server (169.254.169.253 enableDnsHostname 手動建立的預設是 False, Default VPC 預設是 True 如果 ture 會自動給 EC2 Instance 分派 Hostname 如果有 public ip 如果想使用客製化 Private Route53 DNS Domain ，這兩個設定都必須打開 VPN 在公司那邊建立 Customer Gateway （可以是軟體，或一個實體裝置 在AWS這邊建立 Virtual Private Gateway ，並連結在VPC上 透過 site to site VPN Connection 將 VPN Gateway \u0026amp; customer gateway 建起連線 Direct Connect 建立專用網路連線到AWS，AWS 在不同地區都有不同的合作夥伴，所以連線方式像是 公司 \u0026ndash;\u0026gt; 合作夥伴 \u0026ndash;\u0026gt; AWS 專線好處是 : 頻寬高，網路費用比較便宜，並且比較安全 ","date":"September 7, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/vpc-certification-note/","smallImg":"","tags":[{"title":"VPC","url":"/tags/vpc/"}],"timestamp":1662508800,"title":"VPC Certification Note"},{"categories":[{"title":"AWS","url":"/categories/aws/"}],"content":"EC2 Purchase Option On-Demand Instances 用多少付多少，不需要提前預付也也不需要合約，根據秒來計費 不同 Region 有不同的 Instance \u0026amp; CPU 限制數量，可以透過 AWS Support Center 提高上限 Reserved Instances 需要一年或三年的合約 ，以小時計費 付款選項 All Upfront (一次付清) Partial Upfront (部分先付清） No Upfront (用多少付多少） 方案類別 Standard (標準) 折扣較多，但無法更改 Instance Type 可以在 Reserved Instance Marketplace 販賣 Convertible (可轉換) 折扣較少，但隨時可以硬體升降級 不可以在 Reserved Instance Marketplace 販賣 範圍 (Scope) Zonal Instance 只能在指定的 AZ 可以預留 capacity Regional 只能在指定的 Region 同一 Region, 不同 AZ 可以一起折扣 同一系列EC2 根據 正規化因素 在不同硬體規格可以有折扣， 例如 t2.medium 正規化因素為 2 而 t2.small 為 1 ，當你購買一個 t2.medium 的 Reserved Instances，可以折扣在兩個 t2.small 的 instance。 Spot Instance 競價模式: 請求時會自定義一個每小時最高可接受的價格(Spot Price)，而 Spot Price 會隨著市場而變動，當最高價格高於 Spot price ，就有機會獲得 Instance。當然當 Spot Price 低於最高價格， AWS 會隨時終止你的 Instance，所以跑在 Spot Instance 上的服務，需要設計可以隨時可以被終止\n如果因 AWS 而終止，未滿一小時的費用， AWS 不會收取任何費用。 每個 Region 可以限制 20 Spot Instance，可向 AWS 申請調高\nSpot Instance 被終止 EC2 能狀態有三種選擇 :\nHibernate Stop Terminate (default) Spot Block Mode : 可以指定一到六小時內，不會被 AWS 終止\nSpot Request Type\none-time persistent 在 persistent 啟用的狀態下終止 Instance，AWS 會重新分配一個 Instance 給你。 Spot Instance 在被終止前兩分鐘 (grace period)，會有 warning，可以透過 Cloud Watch 或者 透過 EC2 metadata 取得\nAWS 建議每五秒檢查一次 warning EC2 取得 metadata，如果沒有任何 Action 會是 404 1curl : http://169.254.169.254/lasest/meta-data/spot/instance-action Dedicated Hosts \u0026 Instance Dedicated Hosts \u0026amp; Dedicated Instance 都是只在實體機上執行你的程式，但兩者有點小小的差別\nDedicated Hosts 是固定一台 EC2 給你使用，而 Dedicated Instance 只保證這台 EC2 上面的程式不會有其他人的，所以當你重啟 EC2 時，有可能是另一台 EC2。 Dedicated Hosts 可以裝自己的 Software Licenses 而 Dedicated Instance 不行。 Note Dedicate Hosts 有自動容錯功能，發現EC2 壞掉時會自動更換一台新的 EC2，這邊可以整合 AWS License Manager 自動部署新的 Software Licenses Dedicated Hosts 如果購買 On-Demand 是已小時計算 Dedicate Hosts 比 Dedicate Instance 貴 Capacity Reservations 因為 AWS 在 AZ 裡面的實體硬體是有限的，所以是有可能當你啟動 EC2 Instance 時是有可能沒有足夠資源的，這時候只能等待其他人釋放 Instance 或者 選擇不同類型的 Instance。Capacity Reservations 可以讓你先提前先預付某些資源，這樣就不用擔心要啟用 EC2 Instance時沒有資源。在啟用新的 EC2 Instance 時可以直接選擇從 Capacity Reservations 裡面直接扣除，就不需要額外再付費了。但要注意，在 Capacity Reservations 的狀態是啟用時，就已經產生收費。\nSaving Plan Compute Savings Plans 最高省66% 折扣會自動套用在任何 EC2 Instance 上，不管是什麼操作系統、Instance Type 或者在任何 Region EC2 Instance Savings Plans 最高省72% 折扣限制在同一個 Region 下的 Instance Family 可以和 Capacity Reservations 混著使用。 Spot Feet Spot Feet 會根據設定 (launch pools) 嘗試要到足夠的 Spot Instance ，剩餘的會使用 On-Demand Instance 補齊。 可以選擇的策略 lowestPrice: 從 Pool 中選出最便宜的方案 diversified: 分散到多個 Pool 中 capacityOptimized: AWS 會優化最佳 Capacity 去啟用 Spot Instance Instance Type Type 描述 R RAM C CPU M General I I/O G GUP T can burst Burstable Instance (T2/T3) : 當機器閒置時 AWS 會給 Burst Credits (有上限），之後有大量的 CPU 需求時可以得到額外的CPU 並從 Credit 中扣除。 T3 可以無限 Burst ，但當然會需要支付額外的費用 Instance Lifecycle 以下狀態會收費 :\nrunning stop-Hibernate 使用 instance store 當 root volume 的 Instance 是不能 stop 的\nUser Data : EC2 啟用時執行的 Script\n在 EC2 裡面取得 User Data 資訊 1http://169.254.169.254/latest/user-data 16 KB 大小限制 當你停止(Stop) EC2 Instance，之後修改 User Data 以後，再重新啟動 (Start) EC2 Instance，這時候 EC2 Instance 還是會執行舊的 User Data Hibernate : （只限制在使用 EBS 的 Instance) : 在 Instance 停止時，將當下的RAM裡面的狀態複製一份到 EBS，之後重新啟用時，會將 EC2 還原到停止時的狀態。\nEBS 需要是加密的 Hibernate 不能超過六十天 Instance Ram 必須小於 150 GB 特徵\\行為 Reboot Stop/Start Hibernate Terminate 實體機器 同一台實體機器 時通常是不同實體機器 時通常是不同實體機器 X IPV4 Address 兩個固定一樣 Private IPV4: 一樣 Public IPV4: 新的，除非有 Elastic IP address Private IPV4: 一樣 Public IPV4: 新的 除非有 Elastic IP address X Instance store volumes 資料保留 資料刪除 資料刪除 資料刪除 Root device volume 資料保留 資料保留 資料保留 資料預設刪除 RAM 資料刪除 資料刪除 資料保留在 EBS 資料刪除 Placement Group Cluster : 所有的 Instance 放在同一個 AZ ，以提供更快的網路速度 Spread : 將所有的 Instance 放在不同的實體硬體，一個 AZ 最多七個 Instance Partitioned : 將 Ec2 Instance 按照自己的邏輯分開(partition) ，每個 AZ 上限七個 partition Storage 特徵\\Type EBS Instance Store 啟用時間 約一分鐘 正常少於五分鐘 數據保存 預設: 當 Ec2 被 Terminate 時， EBS 也會被砍掉。但可以設定不砍掉，並存留現在有的資料 資料會隨著 Ec2 被被 Terminate 時一起刪除 修改設定 在 EC2 停止時可以被修改 固定的不能修改 SnapShot 支援 snapshot 不支援 snapshot Monitor AWS 提供的 Metrics 包含資訊 CPU Utilization Burst Credit 使用 和 餘額 Network In/Out (bytes) Status Check Instance Status : 檢查 EC2 VM 是否正常 System Status : 檢查硬體設備 \"RAM 不包含在 AWS 提供的 Metrics 模式 Basic : 免費，Metrics 每五分鐘間隔 Detailed : 需要付費，Metrics 每一分鐘間隔 客製化，自己裝 Unified CloudWatch Agent，將想要的 Metrics 或 Log 推到 Cloud Watch 上 CloudWatch Agent 設定可以統一方在 SSM Parameter Store 上 可以取得更詳細的資訊，例如每個 Process 的 CPU 使用量 Others Elastic IP address : 固定 IPv4 Address, 一個 Region 限制五個 Enhanced Network - Elastic Network Adapter: 可以提升網路數度至 100 Gbps - Virtual Function: 可以提升網路數度至 10 Gbps Elastic Fabric Adapter : 高效能運算使用 Troubleshooting 不能啟用新的EC2 InstanceLimitedExceeded Error : 每一個帳號在每一個 Region 都有一些限制，此錯誤代表達到上限，可以跟 AWS 提出將上限提高 InsufficientInstanceCapacity Error : 代表現在 AWS 在這個 AZ 沒有足夠的資源提供，可以等一段時間或者換其他AZ 嘗試。 Instance 直接 Terminate 有可能有以下幾個原因 達到 EBS Volume Limit EBS snapshot 壞掉了 EBS 有加密，但沒有 KMS 權限 AMI 有問題 不能 SSH 到 EC2 \u0026ldquo;Unprotected private key file\u0026rdquo; error : ssh key 需要是400 權限 \u0026ldquo;Too many authentication failures\u0026rdquo; 有可能是 Username 不對 \u0026ldquo;Connection timeout\u0026rdquo; 有可能是 Security Group 沒有設定對 NACL 沒有設定對 Route Table 沒有設定對 沒有 Public IPv4 CPU Loading 太高，機器無法回應 ","date":"September 3, 2022","img":"https://allenhsieh1992.com/images/aws.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/aws/ec2-certification-note/","smallImg":"","tags":[{"title":"EC2","url":"/tags/ec2/"}],"timestamp":1662163200,"title":"EC2 Certification Note"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Given two strings s and t, determine if they are isomorphic.\nTwo strings s and t are isomorphic if the characters in s can be replaced to get t.\nAll occurrences of a character must be replaced with another character while preserving the order of characters. No two characters may map to the same character, but a character may map to itself.\nExample 1:\n1Input: s = \u0026#34;egg\u0026#34;, t = \u0026#34;add\u0026#34; 2Output: true Example 2:\n1Input: s = \u0026#34;foo\u0026#34;, t = \u0026#34;bar\u0026#34; 2Output: false Example 3: Input: s = \u0026ldquo;paper\u0026rdquo;, t = \u0026ldquo;title\u0026rdquo; Output: true\nConstraints:\nConstraints: $$ \\begin{array}{l} 1 \u003c= s.length \u003c= 5 * 10^4 \\\\ t.length == s.length \\\\ s and t consist of any valid ascii character. \\end{array} $$ 我的思路 同時 Loop 兩個 Array ，用兩個 HashMap 同時存已經出現過的字母最新位置，每次都比較目前字母是否已出現過。如果已經出現過是否兩個上次出現過的位子是一樣的，如果有任何不一樣就返回 False。最後如果沒有找到任何不一樣就代表一樣，返回True。\n程式碼 1class Solution { 2 public boolean isIsomorphic(String s, String t) { 3 HashMap\u0026lt;Character, Integer\u0026gt; cacheSCharLastPosition = new HashMap\u0026lt;\u0026gt;(); 4 HashMap\u0026lt;Character, Integer\u0026gt; cacheTCharLastPosition = new HashMap\u0026lt;\u0026gt;(); 5 6 char[] sCharArray = s.toCharArray(); 7 char[] tCharArray = t.toCharArray(); 8 9 for (int i = 0; i \u0026lt; s.length(); i++) { 10 char sChar = sCharArray[i]; 11 char tChar = tCharArray[i]; 12 13 if ((cacheSCharLastPosition.containsKey(sChar) \u0026amp;\u0026amp; cacheTCharLastPosition.containsKey(tChar))) { 14 if (!cacheSCharLastPosition.get(sChar).equals(cacheTCharLastPosition.get(tChar))) { 15 return false; 16 } 17 } else if ((!cacheSCharLastPosition.containsKey(sChar) \u0026amp;\u0026amp; cacheTCharLastPosition.containsKey(tChar)) || 18 (cacheSCharLastPosition.containsKey(sChar) \u0026amp;\u0026amp; !cacheTCharLastPosition.containsKey(tChar))) { 19 return false; 20 } 21 cacheSCharLastPosition.put(sChar, i); 22 cacheTCharLastPosition.put(tChar, i); 23 } 24 return true; 25 } 26} ","date":"June 26, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/easy/205_isomorphic_strings/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1656201600,"title":"演算法 [Java] LeetCode #205. Isomorphic Strings"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Given two strings s and t, return true if s is a subsequence of t, or false otherwise.\nA subsequence of a string is a new string that is formed from the original string by deleting some (can be none) of the characters without disturbing the relative positions of the remaining characters. (i.e., \u0026ldquo;ace\u0026rdquo; is a subsequence of \u0026ldquo;abcde\u0026rdquo; while \u0026ldquo;aec\u0026rdquo; is not).\nExample 1:\n1Input: s = \u0026#34;abc\u0026#34;, t = \u0026#34;ahbgdc\u0026#34; 2Output: true Example 2:\n1Input: s = \u0026#34;axc\u0026#34;, t = \u0026#34;ahbgdc\u0026#34; 2Output: false Constraints:\n0 \u0026lt;= s.length \u0026lt;= 100 0 \u0026lt;= t.length \u0026lt;= 104 s and t consist only of lowercase English letters. 我的思路 這題我就比較直觀， loop 一遍 t，用一個 Varabile 去紀錄現在第幾個字元在 String s 裡面已經被找到了。loop 結束時，確實是否找到的數量等於 String s 的長度，如果是返回 true 否則返回 false\n程式碼 1class Solution { 2 public boolean isSubsequence(String s, String t) { 3 if (s.isEmpty()) { 4 return true; 5 } 6 7 char[] sCharArray = s.toCharArray(); 8 char[] tCharArray = t.toCharArray(); 9 int sPosition = 0; 10 11 for(int i = 0; i \u0026lt; t.length(); i++) { 12 if (tCharArray[i] == sCharArray[sPosition]) { 13 sPosition++; 14 } 15 16 if (sPosition == s.length()) { 17 return true; 18 } 19 } 20 21 return false; 22 } 23} ","date":"June 26, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/easy/392_is_subsequence/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1656201600,"title":"演算法 [Java] LeetCode #392. Is Subsequence"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Given an array of integers nums, calculate the pivot index of this array.\nThe pivot index is the index where the sum of all the numbers strictly to the left of the index is equal to the sum of all the numbers strictly to the index\u0026rsquo;s right.\nIf the index is on the left edge of the array, then the left sum is 0 because there are no elements to the left. This also applies to the right edge of the array.\nReturn the leftmost pivot index. If no such index exists, return -1.\nExample 1:\n1Input: nums = [1,7,3,6,5,6] 2Output: 3 3Explanation: 4The pivot index is 3. 5Left sum = nums[0] + nums[1] + nums[2] = 1 + 7 + 3 = 11 6Right sum = nums[4] + nums[5] = 5 + 6 = 11 Example 2:\n1Input: nums = [1,2,3] 2Output: -1 3Explanation: 4There is no index that satisfies the conditions in the problem statement. Example 3:\n1Input: nums = [2,1,-1] 2Output: 0 3Explanation: 4The pivot index is 0. 5Left sum = 0 (no elements to the left of index 0) 6Right sum = nums[1] + nums[2] = 1 + -1 = 0 Constraints:\n1 \u0026lt;= nums.length \u0026lt;= 104 -1000 \u0026lt;= nums[i] \u0026lt;= 1000 我的思路 現在要從 Array 找 pivot , 就代表有個 index i 左邊所有數字的總和要等於右邊數字的總和。\n用數學表示就會是 leftSum + rightSum + pivot = TotalSum\n因為我們要找 leftSum = rightSum\n所以 leftSum + rightSum + pivot = TotalSum\n=\u0026gt; leftSum + leftSum + pivot = TotalSum\n=\u0026gt; 2 * leftSum = TotalSum - pivot\n=\u0026gt; leftSum = (TotalSum - privot) / 2\n我們先 loop 一遍 Array 求出 totalSum\n接著在 loop 第二次 Array 由左到右，用一個 Varaible leftSum 去計算到 index i 為止左邊累加的總數 ，所以根據剛剛得到的公式，如果 totalSum 減去當下 index i 的值並除二如果等於 leftSum 就代表這個 index 就是 provit。\n如果 loop 完一遍了就代表找不到 provit，那就返回 -1\n程式碼 1class Solution { 2 public int pivotIndex(int[] nums) { 3 int totalSum = 0; 4 for(int num : nums) { 5 totalSum += num; 6 } 7 8 //如果用 int，除2時會導致小數點無條件被捨去而成誤判 9 float leftSum = 0; 10 for(int i = 0; i \u0026lt; nums.length; i++) { 11 if (leftSum == ((float)(totalSum - nums[i]))/2 ) { 12 return i; 13 } 14 leftSum += nums[i]; 15 } 16 return -1; 17 } 18} ","date":"June 25, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/easy/724_find_pivot_index/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1656115200,"title":"演算法 [Java] LeetCode #724. Find Pivot Index"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Roman numerals are represented by seven different symbols: I, V, X, L, C, D and M.\nSymbol Value I 1 V 5 X 10 L 50 C 100 D 500 M 1000 For example, 2 is written as II in Roman numeral, just two one\u0026rsquo;s added together. 12 is written as XII, which is simply X + II. The number 27 is written as XXVII, which is XX + V + II.\nRoman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used:\nI can be placed before V (5) and X (10) to make 4 and 9. X can be placed before L (50) and C (100) to make 40 and 90. C can be placed before D (500) and M (1000) to make 400 and 900. Given an integer, convert it to a roman numeral.\nExample 1:\n1Input: num = 3 2Output: \u0026#34;III\u0026#34; 3Explanation: 3 is represented as 3 ones. Example 2:\n1Input: num = 58 2Output: \u0026#34;LVIII\u0026#34; 3Explanation: L = 50, V = 5, III = 3. Example 3:\n1Input: num = 1994 2Output: \u0026#34;MCMXCIV\u0026#34; 3Explanation: M = 1000, CM = 900, XC = 90 and IV = 4. Constraints:\n1 \u0026lt;= num \u0026lt;= 3999 我的思路 除了千位數，每一個位數先看有沒有 9 和 4 ，如果有就直接 Append 對應的羅馬數字。如果沒有就看有沒有大於五，有就將五的數字羅馬數字加上去，然後再把剩下一加上。\n例如:\n80: 由於 80 的十位數為 8，那就先加上 50(L) ，然後 8 - 5 = 3 ，就代表要加上 3 個 10(X)，最後等於 LXXX 程式碼 1class Solution { 2 public String intToRoman(int num) { 3 StringBuilder result = new StringBuilder(); 4 appendThousandsRoman(num, result); 5 appendHundredsRoman(num, result); 6 appendTensRoman(num, result); 7 appendDigitsRoman(num, result); 8 return result.toString(); 9 } 10 11 public void appendThousandsRoman(int num, StringBuilder result) { 12 int nums_of_thousands_roman = num / 1000; 13 for(int i = 0; i \u0026lt; nums_of_thousands_roman; i++) { 14 result.append(\u0026#34;M\u0026#34;); 15 } 16 } 17 18 public void appendHundredsRoman(int num, StringBuilder result) { 19 int nums_of_hundreds_roman = (num % 1000) / 100; 20 if (nums_of_hundreds_roman == 9) { 21 result.append(\u0026#34;CM\u0026#34;); 22 return; 23 } else if (nums_of_hundreds_roman == 4) { 24 result.append(\u0026#34;CD\u0026#34;); 25 return; 26 } else if (nums_of_hundreds_roman \u0026gt;= 5) { 27 result.append(\u0026#34;D\u0026#34;); 28 nums_of_hundreds_roman -= 5; 29 } 30 31 for(int i = 0; i \u0026lt; nums_of_hundreds_roman; i++) { 32 result.append(\u0026#34;C\u0026#34;); 33 } 34 } 35 36 public void appendTensRoman(int num, StringBuilder result) { 37 int nums_of_hundreds_roman = (num % 100) / 10; 38 if (nums_of_hundreds_roman == 9) { 39 result.append(\u0026#34;XC\u0026#34;); 40 return; 41 } else if (nums_of_hundreds_roman == 4) { 42 result.append(\u0026#34;XL\u0026#34;); 43 return; 44 } else if (nums_of_hundreds_roman \u0026gt;= 5) { 45 result.append(\u0026#34;L\u0026#34;); 46 nums_of_hundreds_roman -= 5; 47 } 48 49 for(int i = 0; i \u0026lt; nums_of_hundreds_roman; i++) { 50 result.append(\u0026#34;X\u0026#34;); 51 } 52 } 53 54 public void appendDigitsRoman(int num, StringBuilder result) { 55 int nums_of_hundreds_roman = num % 10; 56 if (nums_of_hundreds_roman == 9) { 57 result.append(\u0026#34;IX\u0026#34;); 58 return; 59 } else if (nums_of_hundreds_roman == 4) { 60 result.append(\u0026#34;IV\u0026#34;); 61 return; 62 } else if (nums_of_hundreds_roman \u0026gt;= 5) { 63 result.append(\u0026#34;V\u0026#34;); 64 nums_of_hundreds_roman -= 5; 65 } 66 67 for(int i = 0; i \u0026lt; nums_of_hundreds_roman; i++) { 68 result.append(\u0026#34;I\u0026#34;); 69 } 70 } 71} ","date":"June 21, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/medium/12_integer_to_roman/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1655769600,"title":"演算法 [Java] LeetCode #12. Integer to Roman"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Roman numerals are represented by seven different symbols: I, V, X, L, C, D and M.\nSymbol Value I 1 V 5 X 10 L 50 C 100 D 500 M 1000 For example, 2 is written as II in Roman numeral, just two ones added together. 12 is written as XII, which is simply X + II. The number 27 is written as XXVII, which is XX + V + II.\nRoman numerals are usually written largest to smallest from left to right. However, the numeral for four is not IIII. Instead, the number four is written as IV. Because the one is before the five we subtract it making four. The same principle applies to the number nine, which is written as IX. There are six instances where subtraction is used:\nI can be placed before V (5) and X (10) to make 4 and 9. X can be placed before L (50) and C (100) to make 40 and 90. C can be placed before D (500) and M (1000) to make 400 and 900. Given a roman numeral, convert it to an integer.\nExample 1:\n1Input: s = \u0026#34;III\u0026#34; 2Output: 3 3Explanation: III = 3. Example 2:\n1Input: s = \u0026#34;LVIII\u0026#34; 2Output: 58 3Explanation: L = 50, V= 5, III = 3. Example 3:\n1Input: s = \u0026#34;MCMXCIV\u0026#34; 2Output: 1994 3Explanation: M = 1000, CM = 900, XC = 90 and IV = 4. Constraints:\n1 \u0026lt;= s.length \u0026lt;= 15 s contains only the characters (\u0026lsquo;I\u0026rsquo;, \u0026lsquo;V\u0026rsquo;, \u0026lsquo;X\u0026rsquo;, \u0026lsquo;L\u0026rsquo;, \u0026lsquo;C\u0026rsquo;, \u0026lsquo;D\u0026rsquo;, \u0026lsquo;M\u0026rsquo;). It is guaranteed that s is a valid roman numeral in the range [1, 3999]. 我的思路 先用 HashMap 將所有的符號跟值做 Mapping 存起來。\nLoop 一遍 Input 的 String\n如果遇到 I、Ｘ 或 C 先用一個 Varaible previousChar 存起來並且不做任何事情跳過 如果不是就直接把當下代表的數字加上。 然後當發現 previousChar 不等於空時，代表著前一個字母為 I、Ｘ 或 C，這時候有一下兩種可能\n那六種排列組合之一 例如 IV 、 IX、XL、XC、CD 或 CM。 除了以上六種以外，代表著 previousChar 就代表原本數字的意思 (ex I =\u0026gt; 1)，將 previousChar 代表的值直接加回去。 最後由於我們之前一直把 I、Ｘ 或 C 跳過，直到下一個字母確認後，才把它加減上。 但這會造成整個字串最後一個字母沒有處理到，所以在 loop 完字串以後，要確認有沒有沒處理到的 I、Ｘ 或 C，然後再加回去。\n我的思路 1class Solution { 2 HashMap\u0026lt;Character, Integer\u0026gt; romanMap = new HashMap\u0026lt;\u0026gt;() {{ 3 put(\u0026#39;I\u0026#39;, 1); 4 put(\u0026#39;V\u0026#39;, 5); 5 put(\u0026#39;X\u0026#39;, 10); 6 put(\u0026#39;L\u0026#39;, 50); 7 put(\u0026#39;C\u0026#39;, 100); 8 put(\u0026#39;D\u0026#39;, 500); 9 put(\u0026#39;M\u0026#39;, 1000); 10 }}; 11 12 public int romanToInt(String s) { 13 int sum = 0; 14 char previousChar = Character.MIN_VALUE; 15 16 for(char c : s.toCharArray()) { 17 if (previousChar != Character.MIN_VALUE) { 18 if ((previousChar == \u0026#39;I\u0026#39; \u0026amp;\u0026amp; (c == \u0026#39;V\u0026#39; || c == \u0026#39;X\u0026#39;)) || 19 (previousChar == \u0026#39;X\u0026#39; \u0026amp;\u0026amp; (c == \u0026#39;L\u0026#39; || c == \u0026#39;C\u0026#39;)) || 20 (previousChar == \u0026#39;C\u0026#39; \u0026amp;\u0026amp; (c == \u0026#39;D\u0026#39; || c == \u0026#39;M\u0026#39;))) { 21 sum += romanMap.get(c) - romanMap.get(previousChar); 22 previousChar = Character.MIN_VALUE; 23 continue; 24 } else { 25 sum += romanMap.get(previousChar); 26 } 27 } 28 29 if (c == \u0026#39;I\u0026#39; || c == \u0026#39;X\u0026#39; || c ==\u0026#39;C\u0026#39;) { 30 previousChar = c; 31 } else { 32 sum += romanMap.get(c); 33 previousChar = Character.MIN_VALUE; 34 } 35 } 36 37 if (previousChar != Character.MIN_VALUE) { 38 sum += romanMap.get(previousChar); 39 } 40 41 return sum; 42 } 43} ","date":"June 20, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/easy/13_roman_to_integer/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1655683200,"title":"演算法 [Java] LeetCode #13. Roman to Integer"},{"categories":[{"title":"JAVA","url":"/categories/java/"},{"title":"SPRING","url":"/categories/spring/"}],"content":"上次分享了如何透過 Spring CLI 建立 Hello World Application，這邊文章將延續上次的文章繼續產生第一個 endpoint 和產生 Swagger 頁面\n建立第一個 Endpoints 建立一個新的 package contoller 並建立 statusController.java\n1package com.example.springboot_demo.contoller; 2 3import org.springframework.web.bind.annotation.GetMapping; 4import org.springframework.web.bind.annotation.RestController; 5 6 7@RestController //1 8public class statusController { 9 10 @GetMapping(\u0026#34;/status\u0026#34;) //2 11 public String status() { 12 return \u0026#34;ok\u0026#34;; 13 } 14} 備註1 : RestController 等於 @Controller + @ResponseBody，\nResponseBody: Spring 會自動幫你把 Response 轉換成 Json 格式 Controller: 告訴 Spring 這是一個 request 進入點的 Class ，負責調度請求(RequestDispatcher) 備註2 : GetMapping 是 RequestMapping 的 alias 只是一種 Method 指定了是 Http Get Method， RequestMapping 告訴 SpringBoot endpoint 設定，如 path 、header 等等，後面會提到更多，目前先知道當打 /status 這個 endpoint 時，SpringBoot 會找到這個函式並執行。\n測試 現在將 Web Server 啟動，並打 status endpoint，我們會得到我們剛剛所寫的 \u0026ldquo;OK\u0026rdquo;\n1$ curl http:/127.0.0.1:8080/status 2ok 建立 Swagger UI 在 pom.xml 的 dependencies 中加入 pringdoc-openapi-ui 的 dependency\n1\u0026lt;!-- Swagger UI --\u0026gt; 2\u0026lt;dependency\u0026gt; 3 \u0026lt;groupId\u0026gt;org.springdoc\u0026lt;/groupId\u0026gt; 4 \u0026lt;artifactId\u0026gt;springdoc-openapi-ui\u0026lt;/artifactId\u0026gt; 5 \u0026lt;version\u0026gt;1.6.9\u0026lt;/version\u0026gt; 6\u0026lt;/dependency\u0026gt; 這時候將 Application 執行起來，就可以在 /swagger-ui.html 的 path 看到 Swagger UI。\nSwagger UI 可以看到現在 Application Endpoint 資訊，例如這個 endpoint 是什麼 method、需要帶什麼參數，並且會返回樣的資料結構等等。當然這需要一些額外的 Coding 提供資訊，所以這個之後找時間會再細講\n這邊順便介紹一下 application.properties 這個文件，是用來設定 Spring Boot Application 的檔案\n例如我想要自定義剛剛安裝 Swagger 預設的 URL，可以在 application.properties 裡面加以下內容\n1# swagger-ui custom path 2springdoc.swagger-ui.path=/swagger 更多這可以設定什麼可以看官方文件\n","date":"June 19, 2022","img":"https://allenhsieh1992.com/images/spring.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/java/spring/springboot-with-swagger/","smallImg":"","tags":[{"title":"SPRING","url":"/tags/spring/"}],"timestamp":1655596800,"title":"Spring Boot With Swagger"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 A parentheses string is valid if and only if:\nIt is the empty string, It can be written as AB (A concatenated with B), where A and B are valid strings, or It can be written as (A), where A is a valid string. You are given a parentheses string s. In one move, you can insert a parenthesis at any position of the string.\nFor example, if s = \u0026ldquo;()))\u0026rdquo;, you can insert an opening parenthesis to be \u0026ldquo;(()))\u0026rdquo; or a closing parenthesis to be \u0026ldquo;())))\u0026rdquo;. Return the minimum number of moves required to make s valid.\nExample 1:\n1Input: s = \u0026#34;())\u0026#34; 2Output: 1 Example 2:\n1Input: s = \u0026#34;(((\u0026#34; 2Output: 3 Constraints:\n1 \u0026lt;= s.length \u0026lt;= 1000 s[i] is either \u0026lsquo;(\u0026rsquo; or \u0026lsquo;)\u0026rsquo;. 我的思路 建立一個 Stack，loop 整個 String:\n遇到左括弧時將左括弧放入 Stack。 遇到右括弧時檢查 Stack 是否還有左括弧: 如果沒有就代表這邊需要加一個左括弧，所以結果要 +1 如果有就代表這是一個 pair ，那就可以從 Stack 中 pop 掉這個左括弧 最後整個 String loop 過一遍以後，看看 Stack 中是否還有剩餘的左括弧，如果有這些左括弧每一個都需要配一個右括弧，所以返回結果要加上 Stack Size\n程式碼 1class Solution { 2 public int minAddToMakeValid(String s) { 3 Stack\u0026lt;Character\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); 4 int sum = 0; 5 for(char c : s.toCharArray()) { 6 if (c == \u0026#39;(\u0026#39;) { 7 stack.add(c); 8 continue; 9 } 10 11 if (stack.empty()) { 12 sum++; 13 } else { 14 stack.pop(); 15 } 16 } 17 18 return sum + stack.size(); 19 } 20} ","date":"June 19, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/medium/921.minimum_add_to_make_parentheses_valid/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1655596800,"title":"演算法 [Java] LeetCode #921. Minimum Add to Make Parentheses Valid"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Given a string s, remove the vowels \u0026lsquo;a\u0026rsquo;, \u0026rsquo;e\u0026rsquo;, \u0026lsquo;i\u0026rsquo;, \u0026lsquo;o\u0026rsquo;, and \u0026lsquo;u\u0026rsquo; from it, and return the new string.\nExample 1:\n1Input: s = \u0026#34;leetcodeisacommunityforcoders\u0026#34; 2Output: \u0026#34;ltcdscmmntyfrcdrs\u0026#34; Example 2:\n1Input: s = \u0026#34;aeiou\u0026#34; 2Output: \u0026#34;\u0026#34; Constraints:\n1 \u0026lt;= s.length \u0026lt;= 1000 s consists of only lowercase English letters. 我的思路 由於是將一個 String 中所有的母音都移除，所以我們直接建立一個新的 StringBuilder，將 Input loop 一遍，如果不是母音的話就加入到 StringBuilder 裡面，最後返回 String\nNote: 如果不知道為什麼要使用 StringBuilder，可以 google \u0026ldquo;String concat vs StringBuilde\u0026rdquo;。\n程式碼 1class Solution { 2 public String removeVowels(String s) { 3 StringBuilder result = new StringBuilder(); 4 5 for(char c : s.toCharArray()) { 6 if (!isVowels(c)) { 7 result.append(c); 8 } 9 } 10 return result.toString(); 11 } 12 13 public boolean isVowels(char c) { 14 if (c == \u0026#39;a\u0026#39; || 15 c == \u0026#39;e\u0026#39; || 16 c == \u0026#39;i\u0026#39; || 17 c == \u0026#39;o\u0026#39; || 18 c == \u0026#39;u\u0026#39;) { 19 return true; 20 } 21 return false; 22 } 23} ","date":"June 18, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/easy/1119_remove_vowels_from_a_string/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1655510400,"title":"演算法 [Java] LeetCode #1119. Remove Vowels From a String"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 There are n buildings in a line. You are given an integer array heights of size n that represents the heights of the buildings in the line.\nThe ocean is to the right of the buildings. A building has an ocean view if the building can see the ocean without obstructions. Formally, a building has an ocean view if all the buildings to its right have a smaller height.\nReturn a list of indices (0-indexed) of buildings that have an ocean view, sorted in increasing order.\nExample 1:\n1Input: heights = [4,2,3,1] 2Output: [0,2,3] 3Explanation: Building 1 (0-indexed) does not have an ocean view because building 2 is taller. Example 2:\n1Input: heights = [4,3,2,1] 2Output: [0,1,2,3] 3Explanation: All the buildings have an ocean view. Example 3:\n1Input: heights = [1,3,2,4] 2Output: [3] 3Explanation: Only building 3 has an ocean view. Constraints: $$ \\begin{array}{l} 1 \u003c= heights.length \u003c= 10^5 \\\\ 1 \u003c= heights[i] \u003c= 10^9 \\end{array} $$ 我的思路 我們現在要看有多少建築物可以看到右邊的海洋，所以當我在第 i 個建築物時，i 建築物右邊的全部建築物都需要比 i 建築物矮。\n所以我會從最右開始往左看，用一個變數去記錄當下最高建築物的高度，如果當下的建築物沒有比記錄的建築物高，也就代表可以看到海洋。\n由於回傳的結果必須是由左到右的，所以這邊我會先用 Stack 將可看見海洋的建築物存下來，最後在將 Stack 裡面的東西轉換回 Array 返回。\n程式碼 1class Solution { 2 public int[] findBuildings(int[] heights) { 3 // 初始化最右邊的建築物 4 int heightest = heights[heights.length - 1]; 5 Stack\u0026lt;Integer\u0026gt; stack = new Stack(); 6 // 最右邊的放子一定看的到海 7 stack.push(heights.length - 1); 8 9 for(int i = heights.length - 1; i \u0026gt;= 0; i--) { 10 if (heights[i] \u0026gt; heightest) { 11 stack.push(i); 12 heightest = heights[i]; 13 } 14 } 15 16 int size = stack.size(); 17 int[] result = new int[size]; 18 for(int i = 0; i \u0026lt; size; i++) { 19 result[i] = stack.pop(); 20 } 21 return result; 22 } 23} Time complexity: O(N)\nSpace complexity: O(N)\n","date":"June 17, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/medium/1762_buildings_with_an_ocean_view/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1655424000,"title":"演算法 [Java] LeetCode #1762. Buildings With an Ocean View"},{"categories":[{"title":"JAVA","url":"/categories/java/"},{"title":"SPRING","url":"/categories/spring/"}],"content":"前一陣子公司專案讓我有機會使用 Spring Boot 開發，但因為當時專案時間很趕，所以也一直專注在開發上當時開發所需要的技術。由於不熟 Spring Boot or Spring Core，所以用的東西都很基礎。所以我想趁現在好好的充實自己並嘗試寫一個 Spring Boot 系列的文章。\n環境確認 這系列的文章，會以以下的版本為主\nJava 11 Spring Boot 2.7 Apache Maven 3.8.2 建立第一個 Hello World 由於艾倫以前已經使用過 IDE 或 網頁版的 Spring Boot Initializr 初始化，所以這次會以還未使用過的 Spring CLI。\n安裝 Spring CLI 1$ brew tap spring-io/tap 2$ brew install springboot 3 4$ spring --version 5Spring CLI v2.7.0 使用 Spring CLI 初始化專案 1$ spring init -dweb -j 11 -v 1.0.0 -a helloworld 2Using service at https://start.spring.io 3Content saved to \u0026#39;helloworld.zip\u0026#39; 這邊對參數做一些小解釋\n-d: 是 Dependencies，指定專案所需要的 packages，目前先選擇最基本的 web starter -j: 是 Java 版本，這邊我們選擇 Java 11 -v: 此專案的版本初始化 -a: 是 artifact Id 更多的參數或者 dependencies 的選擇，可以透過 spring init -list 看到。\n執行 Spring Boot 建立一個新的資料夾如 demo，將剛剛 Spring CLI 所產生的 ZIP 檔案放入資料夾中，並解壓縮。 在 Terminal 中移動到那個 folder 並在裡面執行 \u0026ldquo;./mvnw spring-boot:run\u0026rdquo; ，最後可以看到以下畫面\n1 . ____ _ __ _ _ 2 /\\\\ / ___\u0026#39;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ 3( ( )\\___ | \u0026#39;_ | \u0026#39;_| | \u0026#39;_ \\/ _` | \\ \\ \\ \\ 4 \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) 5 \u0026#39; |____| .__|_| |_|_| |_\\__, | / / / / 6 =========|_|==============|___/=/_/_/_/ 7 :: Spring Boot :: (v2.7.0) 8 92022-06-12 22:08:28.328 INFO 85059 --- [ main] com.example.helloworld.DemoApplication : Starting DemoApplication using Java 17 on ChangdeMacBook-Pro.local with PID 85059 (/Users/allen/helloworld/target/classes started by allen in /Users/allen/helloworld) 102022-06-12 22:08:28.331 INFO 85059 --- [ main] com.example.helloworld.DemoApplication : No active profile set, falling back to 1 default profile: \u0026#34;default\u0026#34; 112022-06-12 22:08:29.023 INFO 85059 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat initialized with port(s): 8080 (http) 122022-06-12 22:08:29.035 INFO 85059 --- [ main] o.apache.catalina.core.StandardService : Starting service [Tomcat] 132022-06-12 22:08:29.035 INFO 85059 --- [ main] org.apache.catalina.core.StandardEngine : Starting Servlet engine: [Apache Tomcat/9.0.63] 142022-06-12 22:08:29.107 INFO 85059 --- [ main] o.a.c.c.C.[Tomcat].[localhost].[/] : Initializing Spring embedded WebApplicationContext 152022-06-12 22:08:29.107 INFO 85059 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 721 ms 162022-06-12 22:08:29.395 INFO 85059 --- [ main] o.s.b.w.embedded.tomcat.TomcatWebServer : Tomcat started on port(s): 8080 (http) with context path \u0026#39;\u0026#39; 172022-06-12 22:08:29.404 INFO 85059 --- [ main] com.example.helloworld.DemoApplication : Started DemoApplication in 1.627 seconds (JVM running for 1.887) 從上面的訊息來看，可以看到 Spring Application 已經用 Tomcat 起來，且正在聽 8080 port。\n這時我們嘗試打 8080 port\n1 ~  curl http://127.0.0. 2{\u0026#34;timestamp\u0026#34;:\u0026#34;2022-06-12T14:10:55.321+00:00\u0026#34;,\u0026#34;status\u0026#34;:404,\u0026#34;error\u0026#34;:\u0026#34;Not Found\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/\u0026#34;} 會得到 404 Error Msg，這是正常的，因為目前我們還沒有建立任何的 endpoint ～ 但至少確認 Tomcat 有起來。\nSpring CLI 產生檔案 我們可以看到 Spring CLI 已經幫我們產生了以下的檔案\n1$ tree 2. 3├── HELP.md 4├── mvnw 5├── mvnw.cmd 6├── pom.xml 7└── src 8 ├── main 9 │ ├── java 10 │ │ └── com 11 │ │ └── example 12 │ │ └── helloworld 13 │ │ └── DemoApplication.java 14 │ └── resources 15 │ ├── application.properties 16 │ ├── static 17 │ └── templates 18 └── test 19 └── java 20 └── com 21 └── example 22 └── helloworld 23 └── DemoApplicationTests.java DemoApplication.java 我們可以看到 Spring Boot 的進入點 SpringApplication.run。\n如果對 Spring Boot 啟動時做了什麼事情有興趣，可以看看這篇文章 從 SpringBootApplication 談談 Spring Boot 啓動時都做了哪些事？\n1package com.example.helloworld; 2 3import org.springframework.boot.SpringApplication; 4import org.springframework.boot.autoconfigure.SpringBootApplication; 5 6@SpringBootApplication 7public class DemoApplication { 8 9\tpublic static void main(String[] args) { 10\tSpringApplication.run(DemoApplication.class, args); 11\t} 12 13} Pom.xml 1\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; 2\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; 3\txsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; 4\t\u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; 5\t\u0026lt;parent\u0026gt; 6\t\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 7\t\u0026lt;artifactId\u0026gt;spring-boot-starter-parent\u0026lt;/artifactId\u0026gt; 8\t\u0026lt;version\u0026gt;2.7.0\u0026lt;/version\u0026gt; 9\t\u0026lt;relativePath/\u0026gt; \u0026lt;!-- lookup parent from repository --\u0026gt; 10\t\u0026lt;/parent\u0026gt; 11\t\u0026lt;groupId\u0026gt;com.example\u0026lt;/groupId\u0026gt; 12\t\u0026lt;artifactId\u0026gt;helloworld\u0026lt;/artifactId\u0026gt; 13\t\u0026lt;version\u0026gt;1.0.0\u0026lt;/version\u0026gt; 14\t\u0026lt;name\u0026gt;demo\u0026lt;/name\u0026gt; 15\t\u0026lt;description\u0026gt;Demo project for Spring Boot\u0026lt;/description\u0026gt; 16\t\u0026lt;properties\u0026gt; 17\t\u0026lt;java.version\u0026gt;11\u0026lt;/java.version\u0026gt; 18\t\u0026lt;/properties\u0026gt; 19\t\u0026lt;dependencies\u0026gt; 20\t\u0026lt;dependency\u0026gt; 21\t\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 22\t\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; 23\t\u0026lt;/dependency\u0026gt; 24 25\t\u0026lt;dependency\u0026gt; 26\t\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 27\t\u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; 28\t\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; 29\t\u0026lt;/dependency\u0026gt; 30\t\u0026lt;/dependencies\u0026gt; 31 32\t\u0026lt;build\u0026gt; 33\t\u0026lt;plugins\u0026gt; 34\t\u0026lt;plugin\u0026gt; 35\t\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 36\t\u0026lt;artifactId\u0026gt;spring-boot-maven-plugin\u0026lt;/artifactId\u0026gt; 37\t\u0026lt;/plugin\u0026gt; 38\t\u0026lt;/plugins\u0026gt; 39\t\u0026lt;/build\u0026gt; 40 41\u0026lt;/project\u0026gt; 從上面看到，我們繼承了 starter parent，且 dependencies 如預期裡面包含了 web starter 跟我們一開始初始化專案時所要求的一樣。\n最後這邊可以看到，有裝 spring boot maven plugin，這是我們執行 mvn spring-boot:run 所需要的 plugin。\nMaven dependency tree 當我們下 \u0026ldquo;./mvnw dependency:tree\u0026rdquo; 時，我們可以看到整個專案所需要的所包含的 package，也可以看到 package 中所拉到的其他 package 或者我們叫 transitive dependencies。\n以下面的結果為範例，我們可以看到 spring-boot-starter-web 裡面有包含 spring-boot-starter-tomcat。\n1$ ./mvnw dependency:tree 2[INFO] com.example:helloworld:jar:1.0.0 3[INFO] +- org.springframework.boot:spring-boot-starter-web:jar:2.7.0:compile 4[INFO] | +- org.springframework.boot:spring-boot-starter:jar:2.7.0:compile 5[INFO] | | +- org.springframework.boot:spring-boot:jar:2.7.0:compile 6[INFO] | | +- org.springframework.boot:spring-boot-autoconfigure:jar:2.7.0:compile 7[INFO] | | +- org.springframework.boot:spring-boot-starter-logging:jar:2.7.0:compile 8[INFO] | | | +- ch.qos.logback:logback-classic:jar:1.2.11:compile 9[INFO] | | | | \\- ch.qos.logback:logback-core:jar:1.2.11:compile 10[INFO] | | | +- org.apache.logging.log4j:log4j-to-slf4j:jar:2.17.2:compile 11[INFO] | | | | \\- org.apache.logging.log4j:log4j-api:jar:2.17.2:compile 12[INFO] | | | \\- org.slf4j:jul-to-slf4j:jar:1.7.36:compile 13[INFO] | | +- jakarta.annotation:jakarta.annotation-api🫙1.3.5:compile 14[INFO] | | \\- org.yaml:snakeyaml:jar:1.30:compile 15[INFO] | +- org.springframework.boot:spring-boot-starter-json:jar:2.7.0:compile 16[INFO] | | +- com.fasterxml.jackson.core:jackson-databind:jar:2.13.3:compile 17[INFO] | | | +- com.fasterxml.jackson.core:jackson-annotations:jar:2.13.3:compile 18[INFO] | | | \\- com.fasterxml.jackson.core:jackson-core:jar:2.13.3:compile 19[INFO] | | +- com.fasterxml.jackson.datatype:jackson-datatype-jdk8:jar:2.13.3:compile 20[INFO] | | +- com.fasterxml.jackson.datatype:jackson-datatype-jsr310:jar:2.13.3:compile 21[INFO] | | \\- com.fasterxml.jackson.module:jackson-module-parameter-names:jar:2.13.3:compile 22[INFO] | +- org.springframework.boot:spring-boot-starter-tomcat:jar:2.7.0:compile 23[INFO] | | +- org.apache.tomcat.embed:tomcat-embed-core:jar:9.0.63:compile 24[INFO] | | +- org.apache.tomcat.embed:tomcat-embed-el:jar:9.0.63:compile 25[INFO] | | \\- org.apache.tomcat.embed:tomcat-embed-websocket:jar:9.0.63:compile 26[INFO] | +- org.springframework:spring-web:jar:5.3.20:compile 27[INFO] | | \\- org.springframework:spring-beans:jar:5.3.20:compile 28[INFO] | \\- org.springframework:spring-webmvc:jar:5.3.20:compile 29[INFO] | +- org.springframework:spring-aop:jar:5.3.20:compile 30[INFO] | +- org.springframework:spring-context:jar:5.3.20:compile 31[INFO] | \\- org.springframework:spring-expression:jar:5.3.20:compile 將 Tomcat 換成 Jetty 從 dependency tree 我們已經看到 tomcat 是由 web start 拉入的，所以我們可以透過 exclusion 將 tomcat starter 從 web starter 中排除，並手動拉入 jetty starter。\n1\u0026lt;dependencies\u0026gt; 2\t\u0026lt;dependency\u0026gt; 3\t\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 4\t\u0026lt;artifactId\u0026gt;spring-boot-starter-web\u0026lt;/artifactId\u0026gt; 5\t\u0026lt;exclusions\u0026gt; 6\t\u0026lt;!-- 去除Tomcat容器 --\u0026gt; 7\t\u0026lt;exclusion\u0026gt; 8\t\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 9\t\u0026lt;artifactId\u0026gt;spring-boot-starter-tomcat\u0026lt;/artifactId\u0026gt; 10\t\u0026lt;/exclusion\u0026gt; 11\t\u0026lt;/exclusions\u0026gt; 12\t\u0026lt;/dependency\u0026gt; 13\t\u0026lt;!-- 增加Jetty容器 --\u0026gt; 14\t\u0026lt;dependency\u0026gt; 15\t\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 16\t\u0026lt;artifactId\u0026gt;spring-boot-starter-jetty\u0026lt;/artifactId\u0026gt; 17\t\u0026lt;/dependency\u0026gt; 18\t\u0026lt;dependency\u0026gt; 19\t\u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; 20\t\u0026lt;artifactId\u0026gt;spring-boot-starter-test\u0026lt;/artifactId\u0026gt; 21\t\u0026lt;scope\u0026gt;test\u0026lt;/scope\u0026gt; 22\t\u0026lt;/dependency\u0026gt; 23\u0026lt;/dependencies\u0026gt; 這時我們重新執行 ./mvnw spring-boot:run\n1 . ____ _ __ _ _ 2 /\\\\ / ___\u0026#39;_ __ _ _(_)_ __ __ _ \\ \\ \\ \\ 3( ( )\\___ | \u0026#39;_ | \u0026#39;_| | \u0026#39;_ \\/ _` | \\ \\ \\ \\ 4 \\\\/ ___)| |_)| | | | | || (_| | ) ) ) ) 5 \u0026#39; |____| .__|_| |_|_| |_\\__, | / / / / 6 =========|_|==============|___/=/_/_/_/ 7 :: Spring Boot :: (v2.7.0) 8 92022-06-12 22:49:19.224 INFO 87278 --- [ main] com.example.helloworld.DemoApplication : Starting DemoApplication using Java 17 on ChangdeMacBook-Pro.local with PID 87278 (/Users/allen/helloworld/target/classes started by allen in /Users/allen/helloworld) 102022-06-12 22:49:19.226 INFO 87278 --- [ main] com.example.helloworld.DemoApplication : No active profile set, falling back to 1 default profile: \u0026#34;default\u0026#34; 112022-06-12 22:49:19.740 INFO 87278 --- [ main] org.eclipse.jetty.util.log : Logging initialized @1029ms to org.eclipse.jetty.util.log.Slf4jLog 122022-06-12 22:49:19.857 INFO 87278 --- [ main] o.s.b.w.e.j.JettyServletWebServerFactory : Server initialized with port: 8080 132022-06-12 22:49:19.860 INFO 87278 --- [ main] org.eclipse.jetty.server.Server : jetty-9.4.46.v20220331; built: 2022-03-31T16:38:08.030Z; git: bc17a0369a11ecf40bb92c839b9ef0a8ac50ea18; jvm 17+0 142022-06-12 22:49:19.896 INFO 87278 --- [ main] o.e.j.s.h.ContextHandler.application : Initializing Spring embedded WebApplicationContext 152022-06-12 22:49:19.897 INFO 87278 --- [ main] w.s.c.ServletWebServerApplicationContext : Root WebApplicationContext: initialization completed in 633 ms 162022-06-12 22:49:19.958 INFO 87278 --- [ main] org.eclipse.jetty.server.session : DefaultSessionIdManager workerName=node0 172022-06-12 22:49:19.958 INFO 87278 --- [ main] org.eclipse.jetty.server.session : No SessionScavenger set, using defaults 182022-06-12 22:49:19.959 INFO 87278 --- [ main] org.eclipse.jetty.server.session : node0 Scavenging every 600000ms 192022-06-12 22:49:19.966 INFO 87278 --- [ main] o.e.jetty.server.handler.ContextHandler : Started o.s.b.w.e.j.JettyEmbeddedWebAppContext@69da0b12{application,/,[file:///private/var/folders/dx/18qvmm_55hz74r3xdx9wn6x40000gn/T/jetty-docbase.8080.12428220257398218881/],AVAILABLE} 202022-06-12 22:49:19.966 INFO 87278 --- [ main] org.eclipse.jetty.server.Server : Started @1256ms 212022-06-12 22:49:20.187 INFO 87278 --- [ main] o.e.j.s.h.ContextHandler.application : Initializing Spring DispatcherServlet \u0026#39;dispatcherServlet\u0026#39; 222022-06-12 22:49:20.187 INFO 87278 --- [ main] o.s.web.servlet.DispatcherServlet : Initializing Servlet \u0026#39;dispatcherServlet\u0026#39; 232022-06-12 22:49:20.188 INFO 87278 --- [ main] o.s.web.servlet.DispatcherServlet : Completed initialization in 1 ms 242022-06-12 22:49:20.219 INFO 87278 --- [ main] o.e.jetty.server.AbstractConnector : Started ServerConnector@17ca8b92{HTTP/1.1, (http/1.1)}{0.0.0.0:8080} 252022-06-12 22:49:20.220 INFO 87278 --- [ main] o.s.b.web.embedded.jetty.JettyWebServer : Jetty started on port(s) 8080 (http/1.1) with context path \u0026#39;/\u0026#39; 262022-06-12 22:49:20.230 INFO 87278 --- [ main] com.example.helloworld.DemoApplication : Started DemoApplication in 1.274 seconds (JVM running for 1.52) 我們可以看到 Application 現在由 Jetty 9.4 起來～\n","date":"June 8, 2022","img":"https://allenhsieh1992.com/images/spring.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/java/spring/springboot-hello-world/","smallImg":"","tags":[{"title":"SPRING","url":"/tags/spring/"}],"timestamp":1654646400,"title":"透過 Spring CLI 建立 Spring Boot Hello World"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Given a 2D matrix matrix, handle multiple queries of the following type:\nCalculate the sum of the elements of matrix inside the rectangle defined by its upper left corner (row1, col1) and lower right corner (row2, col2). Implement the NumMatrix class:\nNumMatrix(int[][] matrix) Initializes the object with the integer matrix matrix. int sumRegion(int row1, int col1, int row2, int col2) Returns the sum of the elements of matrix inside the rectangle defined by its upper left corner (row1, col1) and lower right corner (row2, col2). Example:\n1Input 2[\u0026#34;NumMatrix\u0026#34;, \u0026#34;sumRegion\u0026#34;, \u0026#34;sumRegion\u0026#34;, \u0026#34;sumRegion\u0026#34;] 3[[[[3, 0, 1, 4, 2], [5, 6, 3, 2, 1], [1, 2, 0, 1, 5], [4, 1, 0, 1, 7], [1, 0, 3, 0, 5]]], [2, 1, 4, 3], [1, 1, 2, 2], [1, 2, 2, 4]] 4Output 5[null, 8, 11, 12] 6 7Explanation 8NumMatrix numMatrix = new NumMatrix([[3, 0, 1, 4, 2], [5, 6, 3, 2, 1], [1, 2, 0, 1, 5], [4, 1, 0, 1, 7], [1, 0, 3, 0, 5]]); 9numMatrix.sumRegion(2, 1, 4, 3); // return 8 (i.e sum of the red rectangle) 10numMatrix.sumRegion(1, 1, 2, 2); // return 11 (i.e sum of the green rectangle) 11numMatrix.sumRegion(1, 2, 2, 4); // return 12 (i.e sum of the blue rectangle) Constraints:\nm == matrix.length n == matrix[i].length 1 \u0026lt;= m, n \u0026lt;= 200 -104 \u0026lt;= matrix[i][j] \u0026lt;= 104 0 \u0026lt;= row1 \u0026lt;= row2 \u0026lt; m 0 \u0026lt;= col1 \u0026lt;= col2 \u0026lt; n At most 104 calls will be made to sumRegion. 我的思路 由於提供了 row1, row2, col1, col2，每次 call sumRegion 的時候，loop 一遍將所有的數字加起來\n程式碼 1class NumMatrix { 2 int[][] matrix; 3 4 public NumMatrix(int[][] matrix) { 5 this.matrix = matrix; 6 } 7 8 public int sumRegion(int row1, int col1, int row2, int col2) { 9 int sum = 0; 10 for(int row = row1; row \u0026lt;= row2; row++) { 11 for(int col = col1; col \u0026lt;= col2; col++) { 12 sum += matrix[row][col]; 13 } 14 } 15 return sum; 16 } 17} 我的思路2 由於從範例可以看到 sumRegion 是在同一個 matrix 重複去計算，所以可以在 call NumMatrix constructor 時事先做一些計算並存起來，以便加快 sumRegion 時的計算。\n現在我打算建立 2D Array cache，而 cache[m][n] 代表的是 [0][0] 到 [m][n] 的所有數字的總和。\n從下面的圖我們可以看到 cache[d1][d2] = A + B + C + D\n如果我們只是想要圖中 D 的面積的話，可以等於\n= (A + B + C + D) - (A + C) - (A + B) + A = cache[d1][d2] - cache[c1][c2] - cache[b1][b2] + cache[a1][a2] ![example]example.webp?width=1024px#center)\n程式碼2 1class NumMatrix { 2 int[][] cache; 3 4 public NumMatrix(int[][] matrix) { 5 int m = matrix.length; 6 int n = matrix[0].length; 7 cache = new int[m][n]; 8 cache[0][0] = matrix[0][0]; 9 10 for(int row = 0; row \u0026lt; m; row++) { 11 for(int col = 0; col \u0026lt; n; col++) { 12 if (row == 0 \u0026amp;\u0026amp; col ==0) { 13 continue; 14 } 15 if(row == 0) { 16 cache[row][col] = cache[row][col-1] + matrix[row][col]; 17 } else if (col == 0) { 18 cache[row][col] = cache[row -1][col] + matrix[row][col]; 19 } else { 20 cache[row][col] = cache[row][col -1] + cache[row -1][col] - cache[row -1][col -1] + matrix[row][col]; 21 } 22 } 23 } 24 } 25 26 public int sumRegion(int row1, int col1, int row2, int col2) { 27 if (row1 == 0 \u0026amp;\u0026amp; col1 == 0) { 28 return cache[row2][col2]; 29 } else if (row1 == 0) { 30 return cache[row2][col2] - cache[row2][col1-1]; 31 } else if (col1 == 0) { 32 return cache[row2][col2] - cache[row1-1][col2]; 33 } else { 34 return cache[row2][col2] - cache[row1-1][col2] - cache[row2][col1-1] + cache[row1-1][col1-1]; 35 } 36 37 } 38} 由於不用每次都從頭計算，在 Leetcode上執行的數度是 程式碼1 的 20倍快\n","date":"June 3, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/medium/304_range_sum_query_2d_immutable/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1654214400,"title":"演算法 [Java] LeetCode #304. Range Sum Query 2D - Immutable"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Given a 2D integer array matrix, return the transpose of matrix.\nThe transpose of a matrix is the matrix flipped over its main diagonal, switching the matrix\u0026rsquo;s row and column indices.\nExample 1:\n1Input: matrix = [[1,2,3],[4,5,6],[7,8,9]] 2Output: [[1,4,7],[2,5,8],[3,6,9]] Example 2:\n1Input: matrix = [[1,2,3],[4,5,6]] 2Output: [[1,4],[2,5],[3,6]] Constraints: $$ \\begin{array}{l} m == matrix.length \\\\ n == matrix[i].length \\\\ 1 \u003c= m, n \u003c= 1000 \\\\ 1 \u003c= m * n \u003c= 105 \\\\ -109 \u003c= matrix[i][j] \u003c= 109 \\end{array} $$ 我的思路 假設現在已經給了 N * M 的 Array ，那就建立一個新的 2D Array M * N。\nLoop 一遍整個 Array，將 要返回的Array[m][n] 設定成 Input Array[n][m];\n程式碼 1class Solution { 2 public int[][] transpose(int[][] matrix) { 3 int[][] result = new int[matrix[0].length][matrix.length]; 4 5 for(int n = 0; n \u0026lt; matrix.length; n++) { 6 for(int m = 0; m \u0026lt; matrix[0].length; m++) { 7 result[m][n] = matrix[n][m]; 8 } 9 } 10 11 return result; 12 } 13} ","date":"June 2, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/easy/867_transpose_matrix/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1654128000,"title":"演算法 [Java] LeetCode #867. Transpose Matrix"},{"categories":[{"title":"LEETCODE","url":"/categories/leetcode/"}],"content":"題目 Given an array nums. We define a running sum of an array as runningSum[i] = sum(nums[0]…nums[i]).\nReturn the running sum of nums.\nExample 1:\n1Input: nums = [1,2,3,4] 2Output: [1,3,6,10] 3Explanation: Running sum is obtained as follows: [1, 1+2, 1+2+3, 1+2+3+4]. Example 2:\n1Input: nums = [1,1,1,1,1] 2Output: [1,2,3,4,5] 3Explanation: Running sum is obtained as follows: [1, 1+1, 1+1+1, 1+1+1+1, 1+1+1+1+1]. Example 3:\n1Input: nums = [3,1,2,10,1] 2Output: [3,4,6,16,17] Constraints: $$ \\begin{array}{l} 1 \u003c= nums.length \u003c= 1000 \\\\ -10^6 \u003c= nums[i] \u003c= 10^6 \\end{array} $$ 我的思路 第 i 個 runningSum 等於 nums[0] + \u0026hellip; + nums[i-1] + nums[i];\n而 nums[0] + nums[i-1] 等於 runningSum[i-1];\n所以可以得到 runningSum[i] = runningSum[i-1] + nums[i];\n程式碼 1class Solution { 2 public int[] runningSum(int[] nums) { 3 int[] runningSum = new int[nums.length]; 4 runningSum[0] = nums[0]; 5 for(int i = 1; i \u0026lt; nums.length; i++) { 6 runningSum[i] = runningSum[i-1] + nums[i]; 7 } 8 return runningSum; 9 } 10} ","date":"June 1, 2022","img":"https://allenhsieh1992.com/images/leetcode.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/leetcode/easy/1480_running_sum_of_1d_array/","smallImg":"","tags":[{"title":"LEETCODE","url":"/tags/leetcode/"}],"timestamp":1654041600,"title":"演算法 [Java] LeetCode #1480. Running Sum of 1d Array"},{"categories":[{"title":"TOOLS","url":"/categories/tools/"}],"content":"使用 Git 當作 Soruce Control 也有一段時間了，但以前都只是基本的了解 Git 基本使用，並沒有深入了解 Git 後面實作原理。最近在 Pluralsight 上看到 Paolo Perrotta 講解 Git 是如何運作的，覺得講得不錯~ 這邊也算是將這次吸收到的知識做個筆記。\nGit Databases Git init 是初始化 Git 的 Databases 或者又稱 Repository ，而 Git 的所有資料都存取在 .git 的目錄下。當執行 git init 後，可以看到 .git 資料夾產生\n1.git 2├── HEAD 3├── config 4├── description 5├── hooks 6│ ├── applypatch-msg.sample 7│ ├── commit-msg.sample 8│ ├── fsmonitor-watchman.sample 9│ ├── post-update.sample 10│ ├── pre-applypatch.sample 11│ ├── pre-commit.sample 12│ ├── pre-merge-commit.sample 13│ ├── pre-push.sample 14│ ├── pre-rebase.sample 15│ ├── pre-receive.sample 16│ ├── prepare-commit-msg.sample 17│ ├── push-to-checkout.sample 18│ └── update.sample 19├── info 20│ └── exclude 21├── objects 22│ ├── info 23│ └── pack 24└── refs 25 ├── heads 26 └── tags 內容追蹤 有執行過 \u0026ldquo;man git\u0026rdquo; 的話，可以看到 Name 那邊寫著 \u0026ldquo;git - the stupid content tracker\u0026rdquo;。這也是 Git 最核心的價值，可以讓我們知道所有檔案的修改紀錄，但這是怎麼做到的呢？\nHash-Obejct Git 使用 SHA1 來 hash 檔案內容，並透過雜湊值的結果，來建立起 Database，以下面為例子\n1$ echo \u0026#34;hello world\u0026#34; | git hash-object --stdin 23b18e512dba79e4c8300dd08aeb37f8e728b8dad Commit 我們可以看到 \u0026ldquo;hello world\u0026rdquo; 的雜湊值是 3b18e512dba79e4c8300dd08aeb37f8e728b8dad。\n這時我們在 local 產生一個 helloWorld.txt ，並 commit \u0026ldquo;first file\u0026rdquo; 進去。\n這時我們看看 .git/objects，這時會發現多了一些 Folder\n1tree .git/objects 2.git/objects 3├── 3b 4│ └── 18e512dba79e4c8300dd08aeb37f8e728b8dad 5├── 48 6│ └── 971f01848a55ac80698bd8c8b999b431f14723 7├── a6 8│ └── 10f3aeab960b6dd657d6f371419954e923bcdf 9├── info 10└── pack Log 這時執行 Git Log 可以看到我們的 Commit 紀錄\n1$ git log 2commit 48971f01848a55ac80698bd8c8b999b431f14723 (HEAD -\u0026gt; master) 3Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 4Date: Tue Feb 22 22:00:22 2022 +0800 5 6 first file 在 Commit 後面有一個雜湊值是 \u0026ldquo;48971f01848a55ac80698bd8c8b999b431f14723\u0026rdquo; ，不知道大家有沒有發現這個數字在哪裡見過？\n答案就是在剛剛的 .git/objects 裡面，前兩位數 \u0026ldquo;48\u0026rdquo; 是資料夾的名字，剩餘的是檔案名稱。\n這時我們來看看檔案裡面有什麼吧\nCat-File 如果大家直接去讀 objects 下面的資料，會發現裡面是一堆不可讀亂碼！檔案的內容是有經過特殊處理過的，但這時可以使用 cat-file 來讀取裡面的資料\n1# 使用方式為 git cat-file options \u0026lt;雜湊值\u0026gt; 2# optins 這次這邊只會 Demo -t 顯示物件類型 -p 物件內容。更多資訊可以直接執行 git cat-file，會有使用教學 3 4$ git cat-file -t 48971f01848a55ac80698bd8c8b999b431f14723 5commit 6 7$ git cat-file -p 48971f01848a55ac80698bd8c8b999b431f14723 8tree a610f3aeab960b6dd657d6f371419954e923bcdf 9author Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645538422 +0800 10committer Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645538422 +0800 11 12first file line5 : 我們可以看到 \u0026ldquo;48971f01848a55ac80698bd8c8b999b431f14723\u0026rdquo; 這個物件代表的是 commit line8 : 我們可以看到雜湊值前面有個 Tree，是代表這個類型。 Tree 記錄該目錄下有哪些檔案(blob) 和 Tree line9-10: 是作者和 Commit 人的資訊 line12: 是 commit 的訊息 那接著來看看 line8 tree 的內容吧\n1$ git cat-file -p a610f3aeab960b6dd657d6f371419954e923bcdf 2100644 blob 3b18e512dba79e4c8300dd08aeb37f8e728b8dad\thelloWorld.txt 這邊可以看到 blob 這個類型，代表紀錄檔案內容，而最後面是檔案名稱。\n大家可以仔細看，helloWorld的雜湊值會跟前面 Hash-Obejct 使用的範例是一樣的，因為 Git 是拿檔案裡面的內容去做 Hash。同樣的值 Hash 出來的雜湊值需要是一樣的。\n1$ git cat-file -p 3b18e512dba79e4c8300dd08aeb37f8e728b8dad 2hello world 版本實現 我們現在在 Local 建立一個 Folder 叫 I_AM_FOLDER 並在裡面建立一個 helloWorld2.txt 但內容跟 helloWorld.txt 一樣，並 commit 看看會發生什麼事情。\n目前資料結構\n1$ tree 2. 3├── I_AM_FOLDER 4│ └── helloWorld2.txt 5└── helloWorld.txt 新的 File Commit 之後的 Log\n1$ git log 2commit 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a (HEAD -\u0026gt; master) 3Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 4Date: Tue Feb 22 22:50:02 2022 +0800 5 6 add helloWorld2.txt 7 8commit 48971f01848a55ac80698bd8c8b999b431f14723 9Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 10Date: Tue Feb 22 22:00:22 2022 +0800 11 12 first file 接下來我們來看看新的 commit 內容吧\n1$ git cat-file -p 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a 2tree bbdf0c43f735049c51bca17ea7543621c38efdd3 3parent 48971f01848a55ac80698bd8c8b999b431f14723 4author Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645541402 +0800 5committer Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645541402 +0800 6 7add helloWorld2.txt Line3: 我們可以看到 parent， parent 代表這個 commit 的父是誰，所以透過這樣的方式，可以知道之前的 commit 內容，這也是 Git 實現版本的方式。 接著我們來看看 tree 裡面的內容\n1$ git cat-file -p bbdf0c43f735049c51bca17ea7543621c38efdd3 2040000 tree 41758064447cf1624a474c3732dc2aead98e701e\tI_AM_FOLDER 3100644 blob 3b18e512dba79e4c8300dd08aeb37f8e728b8dad\thelloWorld.txt 我們可以看到 line2 ， I_AM_FOLDER 的屬性也是 tree。接著我們來看看I_AM_FOLDER 裡面有什麼吧。\n1$ git cat-file -p 41758064447cf1624a474c3732dc2aead98e701e 2100644 blob 3b18e512dba79e4c8300dd08aeb37f8e728b8dad\thelloWorld2.txt 我們可以看到， I_AM_FOLDER 裡面有 helloWorld2.txt ，而 helloWorld2.txt 和 helloWorld.txt 的內容是一樣的，所以不會花額外的空間存取。\n分支實現 當我們使用 git branch 時，可以看到現在所有的分支。而有一個會是當前的分支，前面會備註星號。那 Git 怎麼知道我們現在在哪個分支呢，是透過 .git/HEAD 這個檔案\n1$ git branch 2* master 3 4$ cat .git/HEAD 5ref: refs/heads/master 6 7$ cat .git/refs/heads/master 89c15c7d8323c7f9cd2cb18164e0c8d69c575a15a 9 10$ git log 11commit 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a (HEAD -\u0026gt; master) 12Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 13Date: Tue Feb 22 22:50:02 2022 +0800 14 15 add helloWorld2.txt 16 17commit 48971f01848a55ac80698bd8c8b999b431f14723 18Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 19Date: Tue Feb 22 22:00:22 2022 +0800 20 21 first file line5: ref 後面跟著一個路徑，代表現在分支所在的檔案。 line8: 我們可以看到 master 檔案裡面實際只存了一個雜湊值。 line11: 我們可以看到後面有標記 Head 指向 Master ，而 Master 指向這個 commit 建立新的分支 1$ git branch I_AM_GOING_TO_UPDATE_HELLO_UPDATE 2 3$ git branch 4 I_AM_GOING_TO_UPDATE_HELLO_UPDATE 5 * master 6 7$ cat .git/HEAD 8ref: refs/heads/master 9 10$ tree .git/refs 11.git/refs 12├── heads 13│ ├── I_AM_GOING_TO_UPDATE_HELLO_UPDATE 14│ └── master 15└── tags 16 17$ cat .git/refs/heads/I_AM_GOING_TO_UPDATE_HELLO_UPDAT 189c15c7d8323c7f9cd2cb18164e0c8d69c575a15a 19 20$ cat .git/refs/heads/master 219c15c7d8323c7f9cd2cb18164e0c8d69c575a15a 22 23$ git log 24commit 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a (HEAD -\u0026gt; master, I_AM_GOING_TO_UPDATE_HELLO_UPDATE) 25Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 26Date: Tue Feb 22 22:50:02 2022 +0800 27 28 add helloWorld2.txt 29 30commit 48971f01848a55ac80698bd8c8b999b431f14723 31Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 32Date: Tue Feb 22 22:00:22 2022 +0800 33 34 first file Line1: 我們這邊建立一個新的分支叫做 I_AM_GOING_TO_UPDATE_HELLO_UPDATE Line3 和 line 7: 我們可以看到，現在的 Head 還是指向 Master Line10: 我們可以看到 refs 裡面有新的檔案就是我們 Branch 的名字 Line 17,20 和23: 我們可以看到目前 I_AM_GOING_TO_UPDATE_HELLO_UPDATE \u0026amp; Master 都指向同一個 Git Commit 切換分支 1$ git checkout I_AM_GOING_TO_UPDATE_HELLO_UPDATE 2Switched to branch \u0026#39;I_AM_GOING_TO_UPDATE_HELLO_UPDATE\u0026#39; 3 4$ git branch 5* I_AM_GOING_TO_UPDATE_HELLO_UPDATE 6 master 7 8$ cat .git/HEAD 9ref: refs/heads/I_AM_GOING_TO_UPDATE_HELLO_UPDATE Line1 : 我們使用 checkout 將現在的 Branch 切換到 I_AM_GOING_TO_UPDATE_HELLO_UPDATE Line5\u0026amp; Line7 : 我們可以看到現在分之在 I_AM_GOING_TO_UPDATE_HELLO_UPDATE 新分支 Commit 現在我們嘗試修改 helloWorld.txt 來看看回如何\n1$ cat helloWorld.txt 2hello world2 3 4$ git log 5commit 08e7447af10f14ec4cd6bffc210fddfbae3aa64f (HEAD -\u0026gt; I_AM_GOING_TO_UPDATE_HELLO_UPDATE) 6Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 7Date: Tue Feb 22 23:43:14 2022 +0800 8 9 update helloWorld.txt 10 11commit 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a (master) 12Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 13Date: Tue Feb 22 22:50:02 2022 +0800 14 15 add helloWorld2.txt 16 17commit 48971f01848a55ac80698bd8c8b999b431f14723 18Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 19Date: Tue Feb 22 22:00:22 2022 +0800 20 21 first file Line1: 新的 helloWorld.txt 內容 Line5: 我們可以看到 HEAD 指向 I_AM_GOING_TO_UPDATE_HELLO_UPDATE 和 I_AM_GOING_TO_UPDATE_HELLO_UPDATE 指向最新的 Commit 08e7447af10f14ec4cd6bffc210fddfbae3aa64f Line11: 我們可以看到 Master 現在還是指向上一個 Commit 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a 舊分支 Commit 我們現在切回 master branch 來看看\n1$ git checkout master 2Switched to branch \u0026#39;master\u0026#39; 3 4$ git log 5commit 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a (HEAD -\u0026gt; master) 6Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 7Date: Tue Feb 22 22:50:02 2022 +0800 8 9 add helloWorld2.txt 10 11commit 48971f01848a55ac80698bd8c8b999b431f14723 12Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 13Date: Tue Feb 22 22:00:22 2022 +0800 14 15 first file 16 17$ git log --oneline --graph --decorate --all 18* 08e7447 (I_AM_GOING_TO_UPDATE_HELLO_UPDATE) update helloWorld.txt 19* 9c15c7d (HEAD -\u0026gt; master) add helloWorld2.txt 20* 48971f0 first file 21 22$ cat helloWorld.txt 23hello world Line1: 切換回 master branch Line4: 大家會發現，Log 只顯示當下 Master 相關的 Log ，會看不到 I_AM_GOING_TO_UPDATE_HELLO_UPDATE Branch 相關的 Line17: 我們可以更清楚看到現在的 Commit 結構 Line22: 我們會發現 helloWolrd.txt 恢復成原本舊的還在 Master Branch 的版本。 我們現在一樣來修改 helloWorld.txt 並 commit 看看會發生什麼事情。\n1$ cat helloWorld.txt 2hello world3 3 4$ git log --oneline --graph --decorate --all 5* f7c9f13 (HEAD -\u0026gt; master) master update helloWorld.txt 6| * 08e7447 (I_AM_GOING_TO_UPDATE_HELLO_UPDATE) update helloWorld.txt 7|/ 8* 9c15c7d add helloWorld2.txt 9* 48971f0 first file line4 : 大家應該會發現 9c15c7d 這邊分支成兩個 f7c9f13 和 08e7447。\n合併兩個分支 我們現在來將 I_AM_GOING_TO_UPDATE_HELLO_UPDATE 合併回 master 看看會發生什麼事情\n1$ git checkout master 2Switched to branch \u0026#39;master\u0026#39; 3 4$ git merge I_AM_GOING_TO_UPDATE_HELLO_UPDATE 5Auto-merging helloWorld.txt 6CONFLICT (content): Merge conflict in helloWorld.txt 7Automatic merge failed; fix conflicts and then commit the result. 8 9$ git diff 10diff --cc helloWorld.txt 11index 923e989,1142904..0000000 12--- a/helloWorld.txt 13+++ b/helloWorld.txt 14@@@ -1,1 -1,1 +1,5 @@@ 15++\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; HEAD 16 +hello world3 17++======= 18+ hello world2 19++\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt; I_AM_GOING_TO_UPDATE_HELLO_UPDATE Line4: 由於 I_AM_GOING_TO_UPDATE_HELLO_UPDATE 和 master 都修改過 helloWorld.txt。所以 Git 會不知道要保留哪個版本，而這時就出現了 CONFLICT。 Line9: 從 Git Diff 中我們可以明顯看到， Git 已經幫我們修改檔案，並 Highlight 出兩邊的不同。 現在假設我覺得 master 寫得比較好，所以我保留 master 的內容。\n1$ cat helloWorld.txt 2hello world3 3 4commit 063d5d5307dd178d11bed8ee67a1ed5c614276bf (HEAD -\u0026gt; master) 5Merge: f7c9f13 08e7447 6Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 7Date: Wed Feb 23 09:20:10 2022 +0800 8 9 fix CONFLICT 10 11commit f7c9f13b17ba1fa6641e7c6abb90935321e4f33c 12Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 13Date: Tue Feb 22 23:57:00 2022 +0800 14 15 master update helloWorld.txt 16 17commit 08e7447af10f14ec4cd6bffc210fddfbae3aa64f (I_AM_GOING_TO_UPDATE_HELLO_UPDATE) 18Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 19Date: Tue Feb 22 23:43:14 2022 +0800 20 21 update helloWorld.txt 22 23commit 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a 24Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 25Date: Tue Feb 22 22:50:02 2022 +0800 26 27 add helloWorld2.txt 28 29commit 48971f01848a55ac80698bd8c8b999b431f14723 30Author: Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 31Date: Tue Feb 22 22:00:22 2022 +0800 32 33 first file Line5： 多了 Merge的提示 這時我們來看看最新的 commit 內容吧\n1$ git cat-file -p 063d5d5307dd178d11bed8ee67a1ed5c614276bf 2tree e65ced472fc129e23c9074c2cfd3649d4c43ff29 3parent f7c9f13b17ba1fa6641e7c6abb90935321e4f33c 4parent 08e7447af10f14ec4cd6bffc210fddfbae3aa64f 5author Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645579210 +0800 6committer Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645579210 +0800 7 8fix CONFLICT 9 10$ git cat-file -p f7c9f13b17ba1fa6641e7c6abb90935321e4f33c 11tree e65ced472fc129e23c9074c2cfd3649d4c43ff29 12parent 9c15c7d8323c7f9cd2cb18164e0c8d69c575a15a 13author Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645545420 +0800 14committer Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645545420 +0800 15 16master update helloWorld.txt Line1: 這時可以清楚看到裡面有兩個parent，第一個 parent (line3) 是 master 而第二個 parent (line4) 是 I_AM_GOING_TO_UPDATE_HELLO_UPDATE。所以從這裡這裡知道，我們是從第二個 parent merge 到第一個 parent Line10: 我們再回頭看看原本 master parent 的內容，因為我們保留了 master ，所以 Line11 和 Line2 的雜湊值是一樣的 接下來我們來看一下最新的 Tree 的樣子\n1$ git log --oneline --graph --decorate --all 2* 063d5d5 (HEAD -\u0026gt; master) fix CONFLICT 3|\\ 4| * 08e7447 (I_AM_GOING_TO_UPDATE_HELLO_UPDATE) update helloWorld.txt 5* | f7c9f13 master update helloWorld.txt 6|/ 7* 9c15c7d add helloWorld2.txt 8* 48971f0 first file 可以看到最上面又將兩個 Tree 合併了\nRebase 原理 我將之前的 Merge reset 回去\n1$ git reset f7c9f13 2 3$ git log --oneline --graph --decorate --all 4* f7c9f13 (HEAD -\u0026gt; master) master update helloWorld.txt 5| * 08e7447 (I_AM_GOING_TO_UPDATE_HELLO_UPDATE) update helloWorld.txt 6|/ 7* 9c15c7d add helloWorld2.txt 8* 48971f0 first file rebase 會先找到兩個 branch 開始分差的 commit ，以上面的例子是 9c15c7d。如果要將 I_AM_GOING_TO_UPDATE_HELLO_UPDATE rebase 到 master，會將 9c15c7d 到 I_AM_GOING_TO_UPDATE_HELLO_UPDATE 之間的所有commit 修改，從 Master 之後嘗試做一次，最後在將 master 指向最新的 commit\n1$ git rebase I_AM_GOING_TO_UPDATE_HELLO_UPDATE 2 3Auto-merging helloWorld.txt 4CONFLICT (content): Merge conflict in helloWorld.txt 5error: could not apply f7c9f13... master update helloWorld.txt 6Resolve all conflicts manually, mark them as resolved with 7\u0026#34;git add/rm \u0026lt;conflicted_files\u0026gt;\u0026#34;, then run \u0026#34;git rebase --continue\u0026#34;. 8You can instead skip this commit: run \u0026#34;git rebase --skip\u0026#34;. 9To abort and get back to the state before \u0026#34;git rebase\u0026#34;, run \u0026#34;git rebase --abort\u0026#34;. 10Could not apply f7c9f13... master update helloWorld.txt 由於兩個分支之前都修改過 helloWorld.txt ，所以會有 conflict 。如果沒有 conflict， master 就會 fast forward 到最新的 commit。\n修改完 helloWorld.txt 我們繼續執行 git rebase \u0026ndash;continue\n1$ git rebase --continue 2Successfully rebased and updated refs/heads/master. 3 4$ git log --oneline --graph --decorate --all 5* 08e7447 (HEAD -\u0026gt; master, I_AM_GOING_TO_UPDATE_HELLO_UPDATE) update helloWorld.txt 6* 9c15c7d add helloWorld2.txt 7* 48971f0 first file Merge v.s. Rebase Merge 的好處就是會紀錄所有的修改，包含兩個分支合併時的修改。但是當開發者太多時，同時太多 Merge 會很難追中，這時候反而 rebase 會讓整個 Histroy 看起來比較直觀，但是代價就是不能像 merge 一樣，清楚地知道所有的修改。\nTag 原理 1$ git checkout 08e7447 2 3$ git tag tag1 4 5$ git log --oneline --graph --decorate --all 6* ac766f3 (master) master2 7* 19f9d5c (I_AM_GOING_TO_UPDATE_HELLO_UPDATE) helloWorld 8* 08e7447 (HEAD, tag: tag1) update helloWorld.txt 9* 9c15c7d add helloWorld2.txt 10* 48971f0 first file 11 12$ cat .git/refs/tags/tag1 1308e7447af10f14ec4cd6bffc210fddfbae3aa64f line3: 我們在 08e7447 建立一個 tag 叫 tag1 line8: 我們可以看到 08e7447 後面多了一個 tag line12: 在 .git/refs/tags 檔案夾裡面，可以找到一個檔案叫做 tag1 ，而裡面的雜湊值是我們 tags 的 commit 如果我們想要在 tag 上加上一些有用的描述呢\n1$ git tag tag2 -a -m \u0026#34;i am tag2\u0026#34; 2# -a Make an unsigned, annotated tag object 3 4$ cat .git/refs/tags/tag2 59a9cf462e7960ddbe7a926dbf46c3ffc8afdb363 6 7$ git cat-file -t 9a9cf462e7960ddbe7a926dbf46c3ffc8afdb363 8tag 9 10$ git cat-file -p 9a9cf462e7960ddbe7a926dbf46c3ffc8afdb363 11object 08e7447af10f14ec4cd6bffc210fddfbae3aa64f 12type commit 13tag tag2 14tagger Chang Lin Hsieh \u0026lt;allen@ChangdeMacBook-Pro.local\u0026gt; 1645628590 +0800 15 16i am tag2 line1: 我們建立一個新的 tag object ，並包含了 \u0026ldquo;i am tag2\u0026rdquo; 的資訊 line4: 我們可以看到 tag2 裡面的雜湊值不是我們的 commit 的雜湊值 line9: 我們可以知道 line5 的這個雜湊值是一個 tag 物件 line11,12: 我們可以知道這個 tag 對應到一個 commit 而這個 commit 的雜湊值為 08e7447af10f14ec4cd6bffc210fddfbae3aa64f Tag v.s Branch 當有新的commit 時， Tag 不會指向新的 commit ，而 Branch 會\nRemote v.s Local 當我們在執行 git clone 時，我們是將 Remote 的 .git folder 特定的 Branch 複製下來 (default master)\n1$ cat .git/config 2[core] 3\trepositoryformatversion = 0 4\tfilemode = true 5\tbare = false 6\tlogallrefupdates = true 7\tignorecase = true 8\tprecomposeunicode = true 9[remote \u0026#34;origin\u0026#34;] 10\turl = git@github.com:allen-hsieh1992/blog.git 11\tfetch = +refs/heads/*:refs/remotes/origin/* 12[branch \u0026#34;master\u0026#34;] 13\tremote = origin 14\tmerge = refs/heads/master 15 16$ tree .git/refs/remotes 17.git/refs/remotes 18└── origin 19 ├── HEAD 20 └── master 我以我的 github 為例子\nline9: 我們可以看到，有一個 remote 就 origin 並且他的 url 在下面。 line16: 我們可以看到 refs 資料夾下面多了 remotes 的資料夾 現在我們嘗試在local 加一些commit\n1## before commit 2$ git show-ref master 310275a905f41267b2b2a12f5cd3e3cbee984203a refs/heads/master 410275a905f41267b2b2a12f5cd3e3cbee984203a refs/remotes/origin/master 5 6## after commit 7$ git show-ref master 81251ab4bdd68fdf8a3175719f47565b6c8af44d2 refs/heads/master 910275a905f41267b2b2a12f5cd3e3cbee984203a refs/remotes/origin/master 10 11## after push 12$ git show-ref master 131251ab4bdd68fdf8a3175719f47565b6c8af44d2 refs/heads/master 141251ab4bdd68fdf8a3175719f47565b6c8af44d2 refs/remotes/origin/master line2: line2 我們可以看到在 commit 之前 local \u0026amp; remote 的 master 都是同一個物件。 line7: 當我們 local commit 以後，可以看到 local 的物件已經更新了，但 remote 還是舊的。 line12 ","date":"March 2, 2022","img":"https://allenhsieh1992.com/images/git.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/tools/how_git_works/","smallImg":"","tags":[{"title":"Git","url":"/tags/git/"}],"timestamp":1646179200,"title":"Git 是如何運作的"},{"categories":[{"title":"CONTAINER","url":"/categories/container/"}],"content":"由於公司的 Package Managment 都是客製化的，外加維護的服務沒有 Container 化，所以以前很難在本機上開發。但最近公司開始導入了 Spring Boot ，所以現在想在本機架起一個環境也不像以前這麼繁瑣，也就順便研究一下直接用 Docker 在本機架起一個 Mysql Server，這邊紀錄一下。\n安裝 Mysql Client 透過 Brew 安裝 Mysql Client\n1brew install mysql8-client 安裝好以後，Brew 有提醒要 Export 環境變數，別忘了\n1If you need to have mysql-client first in your PATH, run: 2 echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/mysql-client/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.zshrc 3 4For compilers to find mysql-client you may need to set: 5 export LDFLAGS=\u0026#34;-L/usr/local/opt/mysql-client/lib\u0026#34; 6 export CPPFLAGS=\u0026#34;-I/usr/local/opt/mysql-client/include\u0026#34; 安裝與運行 Mysql8 1$ docker pull mysql/mysql-server:8.0 2$ docker run -itd --name mysql -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql/mysql-server:8.0 name: Container 的名字 p: 本機的 port mapping 到 container 裡面的 port MYSQL_ROOT_PASSWORD: Mysql Root 的密碼 確認 Mysql8 運行正常 1$ docker ps 2CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 38ec7a52cc3ea mysql/mysql-server:8.0 \u0026#34;/entrypoint.sh mysq…\u0026#34; 29 minutes ago Up 26 minutes (healthy) 0.0.0.0:3306-\u0026gt;3306/tcp, :::3306-\u0026gt;3306/tcp, 33060-33061/tcp mysql 要確認 Container 的 Status 是 healthy 喔\n連線 Mysql Server Container 中已經安裝好 Mysql Client 所以可以直接進入到 Container 中連線\n1$ docker exec -it mysql8 mysql -uroot -p 讓 Container 本機可以連線 為了讓 Container 以外的本機可以連線，所以需修改 Mysql User 的權限， Root User 可以接受外面的連線。\n1UPDATE mysql.user SET HOST=\u0026#39;%\u0026#39; WHERE USER = \u0026#39;root\u0026#39; LIMIT 1; 注意，這邊要重啟 Mysql Server 才會生效，艾倫是直接重啟整個 Container\n1docker restart mysql Mac 本機測試連線 這邊要注意，由於 Mysql Server 是在 Contaienr 中運行的，導致本機沒有 mysq.sock 的 file，所以直接運行 mysql client 沒指定 Host 會出現以下錯誤。\n1$ mysql -u root -p 2Enter password: 3ERROR 2002 (HY000): Can\u0026#39;t connect to local MySQL server through socket \u0026#39;/tmp/mysql.sock\u0026#39; (2) 所以這邊需要特別指定 Host 為 127.0.0.1\n1mysql -h 127.0.0.1 -u root -p ","date":"January 28, 2022","img":"https://allenhsieh1992.com/images/docker.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/container/create_mysql_server_by_docker/","smallImg":"","tags":[{"title":"Docker","url":"/tags/docker/"}],"timestamp":1643328000,"title":"使用 Docker 在 Mac 上裝 Mysql Server"},{"categories":[{"title":"JAVA","url":"/categories/java/"}],"content":"使用 Java 也有一段時間了，一直不知道有 java.lang.ref 這包 package 的存在，直到最近在研究 Java Garbage Collection 的時候，才剛好知道原來 Java 的引用還有細分成四個，分別由強到弱為:\n強引用 (Strong Reference) 軟引用 (Soft Reference) 弱引用 (Weak Reference) 虛引用 (Phantom Reference) 強引用 相信大家對強引用一定不陌生，我們正常建立新的物件時所使用的引用都是強引用。當記憶體中的物件有強引用時，Garbage Collection 就一定不會回收此物件。甚至當記憶體不足時 Java Virtual Machine 寧願噴出 OutOfMemoryError 的錯誤，也不會清除它。\n1package com.javacore.ref; 2 3import java.util.ArrayList; 4import java.util.List; 5 6public class StrongRef { 7 static class User {} 8 9 public static void main(String[] args) { 10 List\u0026lt;User\u0026gt; userList = new ArrayList\u0026lt;\u0026gt;(); 11 while (userList != null) { 12 User user = new User(); 13 userList.add(user); 14 } 15 } 16} 上面的 While Loop 的 User(Line12) 就是強引用，雖然 Loop 中 User 會一直指向新的物件，但是 Line13 將 User 加入 List 中也是強引用，所以所有的 User 都會一直保留在記憶體中。我使用 10 MB 的 Heap 執行 (jvm option -Xmx10m)，得到下面的結果，不出意外一下就空間不足了。\n1Exception in thread \u0026#34;main\u0026#34; java.lang.OutOfMemoryError: Java heap space 2\tat java.base/java.util.Arrays.copyOf(Arrays.java:3720) 3\tat java.base/java.util.Arrays.copyOf(Arrays.java:3689) 4\tat java.base/java.util.ArrayList.grow(ArrayList.java:238) 5\tat java.base/java.util.ArrayList.grow(ArrayList.java:243) 6\tat java.base/java.util.ArrayList.add(ArrayList.java:486) 7\tat java.base/java.util.ArrayList.add(ArrayList.java:499) 8\tat com.javacore.ref.StrongRef.main(StrongRef.java:13) 軟引用 軟引用跟強引用最大的不同之處就是，當 Garbage Collection 認為記憶體有壓力時，才會將軟引用的物件給清除。也就代表 Garbage Collection 執行時，不一定會從記憶體清除。 注意:當記憶不足時，JVM 會先嘗試清除軟引用，但如果清除完以後還是不足，還是為噴 OutOfMemoryError\n1package com.javacore.ref; 2 3import java.lang.ref.SoftReference; 4 5public class SoftRef { 6 7 static class User {} 8 9 public static void main(String[] args) { 10 System.out.println(\u0026#34;Available Memory Size \u0026#34; + Runtime.getRuntime().maxMemory()); 11 System.out.println(\u0026#34;Available Memory Size \u0026#34; + Runtime.getRuntime().totalMemory()); 12 13 User user = new User(); 14 SoftReference\u0026lt;User\u0026gt; userSoftReference = new SoftReference\u0026lt;\u0026gt;(user); 15 user = null; 16 17 System.out.println(userSoftReference.get()); 18 System.gc(); 19 System.out.println(userSoftReference.get()); 20 21 byte[] a = new byte[1024 * 1024 * 3]; 22 while (null != userSoftReference.get()) { 23 System.out.println(\u0026#34;Free Memory Size \u0026#34; + Runtime.getRuntime().freeMemory()); 24 byte[] b = new byte[1024 * 1000]; 25 } 26 System.out.println(\u0026#34;The soft reference \u0026#34; + userSoftReference.get()); 27 } 28} 這邊使用 5MB 的 Heap 來執行(JVM Option -Xmx5m)，得到以下的結果。\n1Available Memory Size 6291456 2Available Memory Size 6291456 3com.javacore.ref.SoftRef$User@71be98f5 4com.javacore.ref.SoftRef$User@71be98f5 5Free Memory Size 1222280 6Free Memory Size 185952 7Free Memory Size 185952 8The soft reference null 從上面的 Code 來看\nLine13 一開始強引用 User Line14 建立一個新的軟引用到同一個 User Line15 將原本的強引用給釋放出來，所以 Line13 建立的 User ，已經沒有任何強引用，只剩下 Line14 的軟引用 Line17 嘗試從軟引用拉出資料，執行的結果當下會拿到 User 的物件 Line19 雖然 Line18 強制呼叫 JVM 執行了 Garbage Collection，但由於記憶體沒有壓力，所以還是取得到 User 的物件。 Line21-25 嘗試給記憶體施壓，直到 Garbage Collection 將 User 從記憶體清除 弱引用 弱引用跟軟引用最大的不同點就是，當 Garbage Collection 產生時，不管記憶體是否足夠，都一定會將弱引用的物件給清除掉。\n1package com.javacore.ref; 2 3import java.lang.ref.WeakReference; 4 5public class WeakRef { 6 static class User {} 7 8 public static void main(String[] args) { 9 User user = new User(); 10 WeakReference\u0026lt;User\u0026gt; userWeakReference = new WeakReference\u0026lt;\u0026gt;(user); 11 user = null; 12 13 System.out.println(userWeakReference.get()); 14 System.gc(); 15 System.out.println(userWeakReference.get()); 16 } 17} 從上面的 Code 來看\nLine9 一開始強引用 User Line10 建立一個新的弱引用到同一個 User Line11 將原本的強引用給釋放出來，所以 Line9 建立的 User ，已經沒有任何強引用，只有弱引用 Line13 如果 Garbage Collection 還沒跑的話，弱引用會拿到 User 的物件，所以當拿到 Null 時不要感到意外，因為已經 GC 掉了。 Line15 這時弱引用正常會拿到 Null ，因為我們在 Line14 請JVM 執行了 GC 由於這邊不管記憶體大小都會清除，所以就沒特別限制 Heap 的Size，Code 執行結果如下\n1com.javacore.ref.WeakRef$User@3f0ee7cb 2null ReferenceQueue 在介紹虛引用前，這邊想先介紹 ReferenceQueue。ReferenceQueue 是當物件被 GC 以後，Reference 會被放到這個 Queue。是不是有點抽象，我們用以下的例子來看\n1package com.javacore.ref; 2 3import java.lang.ref.ReferenceQueue; 4import java.lang.ref.WeakReference; 5 6public class ReferenceQueueExample { 7 static class User { 8 } 9 10 public static void main(String[] args) { 11 User user = new User(); 12 ReferenceQueue\u0026lt;User\u0026gt; queue = new ReferenceQueue\u0026lt;\u0026gt;(); 13 WeakReference\u0026lt;User\u0026gt; weakReference = new WeakReference\u0026lt;\u0026gt;(user, queue); 14 15 System.out.println(\u0026#34;try to pull from queue \u0026#34; + queue.poll()); 16 user = null; 17 System.gc(); 18 Object result = null; 19 while (result == null) { 20 System.out.println(\u0026#34;trying to get from queue\u0026#34;); 21 result = queue.poll(); 22 } 23 System.out.println(\u0026#34;try to pull from queue \u0026#34; + result); 24 System.out.println(\u0026#34;try to get from weakReference \u0026#34; + weakReference.get()); 25 } 26} 執行結果可以看出，有時 GC 並不是這麼即時，所以會有需要等一下之後才會放到Queue中。\n1try to pull from queue null 2trying to get from queue. 3trying to get from queue. 4trying to get from queue. 5trying to get from queue. 6try to pull from queue java.lang.ref.WeakReference@7e0ea639 7try to get from weakReference null 虛引用 虛引用跟其他引用不同，它就跟名字如同虛設，在 get() 函式永遠回返回 Null。那它究竟有什麼用？ 它跟前面介紹的 ReferenceQueue 是一起使用的，可以用來追中物件的回收的生命週期。在 Java9 時 finalize 的函式已經被deprecated，建議使用 虛引用加上 ReferenceQueue 取代\n1package com.javacore.ref; 2 3import java.lang.ref.PhantomReference; 4import java.lang.ref.Reference; 5import java.lang.ref.ReferenceQueue; 6 7public class PhantomRef { 8 static class TraceObject {} 9 10 static class PhantomTraceObject extends PhantomReference\u0026lt;TraceObject\u0026gt; { 11 PhantomTraceObject(TraceObject traceObject, ReferenceQueue\u0026lt;? super TraceObject\u0026gt; queue) { 12 super(traceObject, queue); 13 } 14 15 public void cleanup() { 16 System.out.println(\u0026#34;trace object is cleaning up \u0026#34;); 17 } 18 } 19 20 public static void main(String[] args) throws InterruptedException { 21 ReferenceQueue\u0026lt;TraceObject\u0026gt; referenceQueue = new ReferenceQueue(); 22 TraceObject data = new TraceObject(); 23 PhantomTraceObject phantomTraceObject = new PhantomTraceObject(data, referenceQueue); 24 data = null; 25 26 System.gc(); 27 Reference\u0026lt;? extends TraceObject\u0026gt; referenceFromQueue; 28 if ((referenceFromQueue = referenceQueue.remove()) != null) { 29 ((PhantomTraceObject) referenceFromQueue).cleanup(); 30 } 31 } 32} 執行結果如下，line28 可以看到我使用 ReferenceQueue 中的 remove() 而非之前 ReferenceQueue 中的 poll()。 remove() 和 poll() 最大的差別在於，remove() 會卡在那邊等 queue 裡面有資料而 poll() 是拉當下的結果。\n1trace object is cleaning up WeakHashMap 這邊最後要介紹一個特別的 HashMap WeakHashMap，看到Weak大家一定就知道他是弱引用，它是將 Key 當成弱引用，所以存在 Map 裡面的值是會被 GC 的。\n1package com.javacore.ref; 2 3import java.util.WeakHashMap; 4 5public class WeakHashMapExample { 6 static class Process {} 7 static class Thread {} 8 9 public static void main(String[] args) { 10 Process process = new Process(); 11 Thread thread = new Thread(); 12 13 WeakHashMap\u0026lt;Process, Thread\u0026gt; map = new WeakHashMap\u0026lt;Process, Thread\u0026gt;(); 14 map.put(process, thread); 15 process = null; 16 17 System.out.println(\u0026#34;Does map contain the thread: \u0026#34; + map.containsValue(thread)); 18 System.gc(); 19 while (map.containsValue(thread)) { 20 System.out.println(\u0026#34;map still contains the value\u0026#34;); 21 } 22 System.out.println(\u0026#34;The map now is empty \u0026#34; + map.isEmpty()); 23 } 24} 執行的結果如下，從結果可以看出，當 line15 process 沒有強引用以後，map 裡面的內容就會消失。\n1Does map contain the thread: true 2map still contains the value 3The map now is empty true 總結 雖然 Java 裡面有弱引用和軟引用的方式可以當作短暫的緩存，但緩存的時間是不可控的，因為是控制在 Java 的 Garbage Collection。而且大量的緩存也會造成更頻繁的GC。 目前還沒有在實務上使用的經驗，所以如果將來有幸有用到再來分享更多細節。不過目前個人觀點，這應該只適合用在 client Side，Web Server 還是建議使用像 Redis 或 Memcache 這些 Cache 的技術。\n","date":"January 27, 2022","img":"https://allenhsieh1992.com/images/java.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/java/java-reference/","smallImg":"","tags":[{"title":"JavaCore","url":"/tags/javacore/"}],"timestamp":1643241600,"title":"你知道 Java 的四個引用嗎？"},{"categories":[{"title":"JAVA","url":"/categories/java/"}],"content":"什麼是 Garbage Collection 在大學時 Algorithm, OS, 和 Data Structure 等課程都是使用 C 或 C++ 來當作課程教材的語言。而 C 與 C++ 語言可以擁有很大的掌控權力在 Memory 上，但是一處理不好就容易造成 Memory Leak。讓我印象最深刻的是 Operating System 課程，使用 OS161 來當作做作業的練習， 而最後一個作業就是實作 Memory Management。大家那時候最害怕遇到的錯誤訊息就是 \u0026ldquo;I can\u0026rsquo;t handle this\u0026hellip; I think I\u0026rsquo;ll just die now\u0026hellip;\u0026quot;，然後就要開始艱辛的 Debug 路程。\n之後當我接觸 Java 以後，我就回不去了 C 和 C++ 的世界了。因為 Java 已經有一套非常完善的機制幫我們管理記憶體，那就是 Garbage Collection。 Garbage Collection 是一個演算法，會自動將不需要在使用的內存給釋放出來，而我們就不用在管理複雜的記憶體了萬歲~\nGarbage Collection 演算法 Reference Counting 這是最簡單易懂的演算法，每個物件都有個記地址去紀錄目前被多少引用，當引用數量等於零時，就代表這個物件可以被清除掉。\nReference Counting演算法的問題是 Cycle Reference。例如A reference B 和 B reference A，這樣 A 和 B 的引用的數量永遠不可能為零，也代表永遠不會被清除。\nMark \u0026 Sweep Mark \u0026amp; Sweep 演算法一共用兩個階段，如同英文 Mark 和 Sweep 分別代表不同的階段 階段1. Mark: 就是透過根引用開始一一走過一遍目前的記憶體，將所有有被引用的物件地址標記為正在使用。 階段2. Sweep: 在走過一次將地址將所有沒有被標記為還正在使用的記憶體清除。\nMark \u0026amp; Sweep 演算法的問題是記憶碎片(fragmentation)，由於被清除的記憶是隨機的，造成剩下還正在使用的記憶地址是非連續性的。\nCopying Copying 演算法是將記憶體切成兩個區塊(Region)，一次只會有一個區塊在使用，這邊分別使用 \u0026ldquo;激活區塊\u0026rdquo; 和 \u0026ldquo;未激活區塊\u0026rdquo; 來表示。當演算法執行時，會將所有在 \u0026ldquo;激活區塊\u0026rdquo; 中還需要使用的物件複製到 \u0026ldquo;未激活區塊中\u0026rdquo;。在複製的過程中，會將地址重新整理，解決了 Mark \u0026amp; Sweep 演算法中的 Fragmentation 的問題。複製完後 \u0026ldquo;未激活區塊\u0026rdquo; 就會變成新的 \u0026ldquo;激活區塊\u0026rdquo;，而 \u0026ldquo;激活區塊\u0026rdquo; 會變成 \u0026ldquo;未激活區塊\u0026rdquo; 這樣一直循環。\nCopying 演算法的問題是\n由於需要兩個區塊，所以使用的記憶體也是兩倍。 如果每次執行時，需要清理的記憶體很少，那就代表每次需要複製到 \u0026ldquo;未激活區塊\u0026rdquo; 的很多，效能也會很差 Mark-Compact Mark-Compact 演算法是基於 Mark \u0026amp; Sweep 演算法的優化，多增加一個 Compact 階段，將還需要使用的記憶重新整理，解決了記憶碎片，也不像 Copying 演算法依樣需要使用兩倍的記憶體\nJava Garbage Collection Generation Collector Generation 演算法的核心理論在於大部分的物件很快就是被清掉，如果沒被清掉，就不需要這麼頻繁的一直重複確認是否存在。Generation 演算法會將記憶體分為 Young \u0026amp; Old Generation。Young Generation 用於存放所有新物件，在幾次 GC 後還在 Young Generation 未清除的物件，將被升級到 Old Generation。\n如上圖 Java 將記憶體資料結構分為\nYoung Generation 有兩個 survivor 空間，也就是圖上的 S0 \u0026amp; S1 這邊使用 Copying 演算法，將物件在 S0 與 S1 之間複製。 複製到一定次數會被升級到 Olde Generation Eden Space: 這邊用於存新的物件，在第一次 GC 時，沒有被清除就會移到 S0 or S1 Old Generation 這邊使用 Mark-Compact 演算法。 Permanent Generation 這邊用於存取 JVM 長期需要使用的資料，例如 Class, Method 等等。這裡的資料不會被 GC 掉 Generation 演算法中有個特別的資料結構叫做 Card Table，想像如果現在要 GC Young Generation，而 Young Generation 萬一有 Old Generation 裡面的記憶體來引用那要怎麼辦？這樣是否每次在 GC Young Generation 時都要去 Full Scan Old Generation 是否有任何索引？但這樣效能就會很差，而 Card Table 就是用於處理這樣的情況。在 Card Table 中會紀錄現在 Old Generation 的地址是否有引用 Young Generation 的，這樣在 Young Generation GC 時可以透過 Card Table 來增加效能。\nRegion Java9 現在預設的 Garbage Collection G1 是使用 Region 演算法。如上圖，Region 演算法還是有 Generation 的概念，但跟 Generation 演算法不同的地方是，它將記憶體切成多個不同大小(1 MB 到 32 MB 不等)的 Region。由於更多的區塊，所以可以並發GC，而且也因為每個 Region 更小，所以 GC 的數度更快。\nJava 取得 Garbage Collection 資訊 Java 有特別的 Garbage Collection 接口 GarbageCollectorMXBean，以下是範例\n1package com.javacore.gc; 2 3import java.lang.management.GarbageCollectorMXBean; 4import java.lang.management.ManagementFactory; 5import java.util.List; 6 7public class MxBean { 8 9 public static void main(String[] args) { 10 List\u0026lt;GarbageCollectorMXBean\u0026gt; beanList = ManagementFactory.getGarbageCollectorMXBeans(); 11 for (GarbageCollectorMXBean bean: beanList) { 12 System.out.println(\u0026#34;Name: \u0026#34; + bean.getName()); 13 System.out.println(\u0026#34;Number of Collection Count: \u0026#34; + bean.getCollectionCount()); 14 System.out.println(\u0026#34;Collection Time \u0026#34; + bean.getCollectionTime() + \u0026#34;ms\u0026#34;); 15 System.out.println(\u0026#34;Pool Name \u0026#34; + bean.getName()); 16 17 for(String pool : bean.getMemoryPoolNames()) { 18 System.out.println(pool); 19 } 20 System.out.println(); 21 } 22 } 23} getCollectionCount(): 以執行次數 getCollectionTime(): 預計以執行 Total 時間，單位為毫秒 以下是 Open JDK11 預設 G1 執行結果\n1Name: G1 Young Generation 2Number of Collection Count: 0 3Collection Time 0 4Pool Name G1 Young Generation 5G1 Eden Space 6G1 Survivor Space 7G1 Old Gen 8 9Name: G1 Old Generation 10Number of Collection Count: 0 11Collection Time 0 12Pool Name G1 Old Generation 13G1 Eden Space 14G1 Survivor Space 15G1 Old Gen ","date":"January 26, 2022","img":"https://allenhsieh1992.com/images/java.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/java/java-garbage-collection/","smallImg":"","tags":[{"title":"JavaCore","url":"/tags/javacore/"}],"timestamp":1643155200,"title":"Java Garbage Collection 基礎演算法"},{"categories":[{"title":"JAVA","url":"/categories/java/"}],"content":"這新專案我選擇使用了之前沒使用過的 Jersey Client ~ 由於希望分析打到其他服務的 P99 latency，所以我研究了一下怎麼去 log 下來所有的 duration (如果不知道什麼是 P99 latency 可以參考這篇文章 \u0026ldquo;What is P99 latency\u0026quot;)。這邊分享一下，我最後使用的方法，由於不太熟 Jersey Client，所以最後也是花了一點時間才找到使用 ClientRequestFilter \u0026amp; ClientResponseFilter 來解決。\n前置作業 這邊使用 Maven Project 作為範例\n1\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; 2\u0026lt;project xmlns=\u0026#34;http://maven.apache.org/POM/4.0.0\u0026#34; 3 xmlns:xsi=\u0026#34;http://www.w3.org/2001/XMLSchema-instance\u0026#34; 4 xsi:schemaLocation=\u0026#34;http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\u0026#34;\u0026gt; 5 \u0026lt;modelVersion\u0026gt;4.0.0\u0026lt;/modelVersion\u0026gt; 6 7 \u0026lt;groupId\u0026gt;org.example\u0026lt;/groupId\u0026gt; 8 \u0026lt;artifactId\u0026gt;jerseyClient\u0026lt;/artifactId\u0026gt; 9 \u0026lt;version\u0026gt;1.0-SNAPSHOT\u0026lt;/version\u0026gt; 10 11 \u0026lt;dependencies\u0026gt; 12 \u0026lt;dependency\u0026gt; 13 \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; 14 \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; 15 \u0026lt;version\u0026gt;1.18.20\u0026lt;/version\u0026gt; 16 \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; 17 \u0026lt;/dependency\u0026gt; 18 \u0026lt;dependency\u0026gt; 19 \u0026lt;groupId\u0026gt;org.glassfish.jersey.core\u0026lt;/groupId\u0026gt; 20 \u0026lt;artifactId\u0026gt;jersey-client\u0026lt;/artifactId\u0026gt; 21 \u0026lt;version\u0026gt;2.33\u0026lt;/version\u0026gt; 22 \u0026lt;/dependency\u0026gt; 23 \u0026lt;dependency\u0026gt; 24 \u0026lt;groupId\u0026gt;org.glassfish.jersey.inject\u0026lt;/groupId\u0026gt; 25 \u0026lt;artifactId\u0026gt;jersey-hk2\u0026lt;/artifactId\u0026gt; 26 \u0026lt;version\u0026gt;2.28\u0026lt;/version\u0026gt; 27 \u0026lt;/dependency\u0026gt; 28 \u0026lt;/dependencies\u0026gt; 29 \u0026lt;properties\u0026gt; 30 \u0026lt;maven.compiler.source\u0026gt;11\u0026lt;/maven.compiler.source\u0026gt; 31 \u0026lt;maven.compiler.target\u0026gt;11\u0026lt;/maven.compiler.target\u0026gt; 32 \u0026lt;/properties\u0026gt; 33 34\u0026lt;/project\u0026gt; 1package com.demo; 2 3import javax.ws.rs.client.Client; 4import javax.ws.rs.client.ClientBuilder; 5import javax.ws.rs.client.WebTarget; 6import javax.ws.rs.core.MediaType; 7import java.util.concurrent.TimeUnit; 8 9public class MAIN { 10 public static void main(String[] args) { 11 Client client = ClientBuilder.newBuilder() 12 .connectTimeout(30, TimeUnit.SECONDS) 13 .build(); 14 //Filter 在後面的範例中 15 WebTarget webTarget = client.target(\u0026#34;https://google.com\u0026#34;).register(new Filter()); 16 webTarget 17 .request(MediaType.APPLICATION_JSON_TYPE) 18 .get(String.class); 19 } 20} ClientResponseFilter 實作 Interface javax.ws.rs.client.ClientResponseFilter 可以處理所有的每個 Response 的結果 ~ 可以拿到 ClientRequestContext \u0026amp; ClientRequestContext，以下是範例。\n1package com.demo; 2 3import javax.ws.rs.client.ClientRequestContext; 4import javax.ws.rs.client.ClientResponseContext; 5import javax.ws.rs.client.ClientResponseFilter; 6import java.io.IOException; 7 8public class Filter implements ClientResponseFilter { 9 @Override 10 public void filter(ClientRequestContext requestContext, 11 ClientResponseContext responseContext) throws IOException { 12 System.out.println(String.format(\u0026#34;requestUri=\\\u0026#34;%s\\\u0026#34;, method=\\\u0026#34;%s\\\u0026#34;, responseStatus=\\\u0026#34;%s\\\u0026#34;, requestTime=\\\u0026#34;%s\\\u0026#34;, responseTime=\\\u0026#34;%s\\\u0026#34;\u0026#34;, 13 requestContext.getUri(), 14 requestContext.getMethod(), 15 responseContext.getStatus(), 16 requestContext.getDate(), 17 responseContext.getDate())); 18 } 19} 這邊可以看到，ClientRequestContext ＆ ClientResponseContext 都有 getDate() 的函式返回一個 java.util.Date！天真的我一開始以為可以靠這兩個 getDate() 算出這個 response 的 duration，但實際執行結果卻出乎我的意料，requestTime 竟然是 null。\n1requestUri=\u0026#34;https://google.com\u0026#34;, method=\u0026#34;GET\u0026#34;, responseStatus=\u0026#34;200\u0026#34;, requestTime=\u0026#34;null\u0026#34;, responseTime=\u0026#34;Wed Jun 30 22:41:53 CST 2021\u0026#34; ClientRequestFilter 當時有點犯蠢，想說 requestTime 是 Null 就差點放棄，不知道怎麼完全沒想到竟然有 ClientResponseFilter ，那怎麼會沒有 ClientRequestFilter 呢！所以這邊最後靠著 ClientRequestFilter ，在每個 request 送出去前，把系統當下時間塞進去 requestContext ，這樣就可以在 response 回來時拉到當初 request 送出時間。\n1package com.demo; 2 3import javax.ws.rs.client.ClientRequestContext; 4import javax.ws.rs.client.ClientRequestFilter; 5import javax.ws.rs.client.ClientResponseContext; 6import javax.ws.rs.client.ClientResponseFilter; 7import java.io.IOException; 8 9public class Filter implements ClientResponseFilter, ClientRequestFilter { 10 private static final String REQUEST_TIME = \u0026#34;REQUEST_TIME\u0026#34;; 11 12 @Override 13 public void filter(ClientRequestContext requestContext) throws IOException { 14 long currentTimeMillis = System.currentTimeMillis(); 15 requestContext.setProperty(REQUEST_TIME, currentTimeMillis); 16 } 17 18 @Override 19 public void filter(ClientRequestContext requestContext, 20 ClientResponseContext responseContext) throws IOException { 21 long requestTime = (Long) requestContext.getProperty(REQUEST_TIME); 22 long currentTimeMillis = System.currentTimeMillis(); 23 long duration = currentTimeMillis - requestTime; 24 25 System.out.println(String.format(\u0026#34;requestUri=\\\u0026#34;%s\\\u0026#34;, method=\\\u0026#34;%s\\\u0026#34;, responseStatus=\\\u0026#34;%s\\\u0026#34;, duration=\\\u0026#34;%d\\\u0026#34;\u0026#34;, 26 requestContext.getUri(), 27 requestContext.getMethod(), 28 responseContext.getStatus(), 29 duration)); 30 } 31} 透過 ClientResponseFilter \u0026amp; ClientRequestFilter 就可以簡單算出每個 request duration ~ 希望有幫助到看到這邊文章的人\n","date":"June 30, 2021","img":"https://allenhsieh1992.com/images/java.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/java/java-jersey-client-log-request-duration/","smallImg":"","tags":[],"timestamp":1625011200,"title":"Java Jersey Client 取得每個 Request Duration"},{"categories":[{"title":"JAVA","url":"/categories/java/"}],"content":"最近我們部門在開發新的微服務都是使用 Java，但許多同事都是寫習慣 PHP 且之前沒有使用過 Java 。由於像 PHP 這種 Script Language 在處理 Undefined Variable 時，只是提示Warning，導致有的同事沒有良好的檢查 null 的習慣。有的同事抱怨 Null Pointer Exception 花了許多的時間在尋找，所以我決定在這次的新專案中，使用 Optional 來減少 Null Pointer Exception。這邊要特別注意，如果沒有正確的使用 Optional 的話，還是有可能會造成 Null Pointer Exception 喔！\nNull Reference is the Billion Dollar Mistake - Tony Hoare\n建立Optional 物件 大家認為下面的 Example1 運行的結果會是什麼樣的呢？\n1import java.util.Optional; 2 3public class Example1 { 4 public static void main(String[] args) { 5 String sentence = \u0026#34;I am Optional String\u0026#34;; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.of(sentence); 7 System.out.println(optionalSentence.get()); 8 } 9} 執行結果會是 \u0026ldquo;I am Optional String\u0026rdquo;，這邊可以看到 line 6 透過 of() method 建立了 一個 Optional 的物件。但如果 sentence 是 null 的時候，會怎麼樣呢？結果會是 Null Pointer Exception! 因為 of() method 這邊所帶入的 Value 必須是 non-null的，所以建議大家在使用 Optional 時，應該避開使用 of() method，而是使用 ofNullable() method。\n現在我們將 Example1 中的 sentence 改成 null 並且使用 ofNullAble() method 來運行，這時大家覺得結果是怎樣呢？\n1import java.util.Optional; 2 3public class Example2 { 4 public static void main(String[] args) { 5 String sentence = null; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 7 System.out.println(optionalSentence.get()); 8 } 9} 大家是否會認為跟 Example1 一樣，會列印出\u0026quot;I am Optional String\u0026quot;？但實際執行的結果會是 NoSuchElementException : No value present，因為在 call get() method 時內部檢查 Value 是否存在，所以這邊建議在實際使用中，不要使用 get() method，除非你能確認 Value 一定不等於 null。 這邊要順便介紹 Optional 中特別的物件: Optional.empty() ，這邊要特別注意 Optional empty 還是 Optional 物件，只是裡面的 value 是 null，所以 Optional empty 跟 null 是不同的東西。\nOptional 安全取得Value 這邊一開始要介紹Optional 中的 isPresent()，透過 isPresent 我們可以安全地確認 Value 是否存在\n1import java.util.Optional; 2 3public class Example3 { 4 public static void main(String[] args) { 5 String sentence = \u0026#34;I am Optional String\u0026#34;; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 7 if (optionalSentence.isPresent()) { 8 System.out.println(optionalSentence.get()); 9 } else { 10 System.out.println(\u0026#34;value is empty\u0026#34;); 11 } 12 } 13} Example3 因為我們確認了 Value 已經存在 Optional 中了，所以會正常運行，但是否會覺得這樣寫法跟我們以前自己檢查一些值是否是 null 是一樣的呢？ 這邊要介紹 orElse()\n1import java.util.Optional; 2 3public class Example4 { 4 public static void main(String[] args) { 5 String sentence = \u0026#34;I am Optional String\u0026#34;; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 7 String defaultValue = \u0026#34;value is empty\u0026#34;; 8 System.out.println(optionalSentence.orElse(defaultValue)); 9 } 10} 大家可以看到 orElse() 當 Optional 物件的 value 是空的時候，會返回 defaultValue，這樣我們就可以不用寫 if else 了。 但有的人想 return 的 defaultValue 比較複雜怎麼辦? 我們也可以使用 orElseGet() 執行一個函示取得想要的預設值。\n1import java.util.Optional; 2 3public class Example5 { 4 public static void main(String[] args) { 5 String sentence = \u0026#34;I am Optional String\u0026#34;; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 7 System.out.println(optionalSentence.orElseGet(()-\u0026gt; getDefaultValue())); 8 } 9 private static String getDefaultValue() { 10 return \u0026#34;I am default value\u0026#34;; 11 } 12} 大家以前也一定會經常做一些必要的欄位檢查，如果都些值是 Null 就要丟特定的 Exception，這邊可以使用 orElseThrow()\n1import java.util.Optional; 2 3public class Example6 { 4 public static void main(String[] args) throws Exception { 5 String sentence = \u0026#34;I am Optional String\u0026#34;; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 7 System.out.println(optionalSentence.orElseThrow(()-\u0026gt; new myCustomException())); 8 } 9} Optional 安全執行特定函式 在之前的例子中，我們只是單純的想要正確的執行 System.out.println，這邊介紹ifPresent()。\n1import java.util.Optional; 2 3public class Example7 { 4 public static void main(String[] args) throws Exception { 5 String sentence = \u0026#34;I am Optional String\u0026#34;; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 7 optionalSentence.ifPresent(value -\u0026gt; { 8 System.out.println(value); 9 }); 10 } 11} 這邊想稍微提一下 eta-conversion 的概念，但細節大家可以參考這篇 如何理解並使用Java中雙冒號(::)運算操作符 根據eta-conversion 可以寫成以下code\n1import java.util.Optional; 2 3public class Example8 { 4 public static void main(String[] args) { 5 String sentence = \u0026#34;I am Optional String\u0026#34;; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 7 //原本 8 optionalSentence.ifPresent(value -\u0026gt; { 9 System.out.println(value); 10 }); 11 //因為只執行一個函式，所以可以將 {} 拿掉 12 optionalSentence.ifPresent(value -\u0026gt; System.out.println(value)); 13 //因為只有的函式只有一個參數，透過 eta-conversion 可以寫成 14 optionalSentence.ifPresent(System.out::println); 15 } 16} ifPresent() 只能在 Optional 有 value 時執行，有時候我們也希望如果 Optional 有 value 時執行 函式 A，沒有值時 執行函式 B，這時我們就可以透過 ifPresentOrElse()\n1import java.util.Optional; 2 3public class Example9 { 4 public static void main(String[] args) { 5 String sentence = \u0026#34;I am Optional String\u0026#34;; 6 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 7 optionalSentence.ifPresentOrElse(Example9::methodA, Example9::methodB); 8 } 9 10 public static void methodA(String value) { 11 //do something with value 12 } 13 14 public static void methodB() { 15 //do something without value 16 } 17} Optional 進階函式 Filter : 如果 isContainOptional return false，filter 的結果會是 Optional empty\n1import java.util.Locale; 2import java.util.Optional; 3 4public class Example10 { 5 public static void main(String[] args) { 6 String sentence = \u0026#34;I am Optional String\u0026#34;; 7 Optional\u0026lt;String\u0026gt; optionalSentence = Optional.ofNullable(sentence); 8 System.out.println(optionalSentence.filter(Example10::isContainOptional)); 9 } 10 11 public static boolean isContainOptional(String input) { 12 return input.toLowerCase(Locale.ENGLISH).contains(\u0026#34;optional\u0026#34;); 13 } 14} 15 16/* output 17Optional[I am Optional String] 18*/ Map: 如果 Optional 的 Value 有值，這邊才會執行你所定義的 Mapping Function，如果沒有就直接返回 Optional Empty。 我在工作中，經常需要將 DTO 轉換成 Response 物件，會使用 Map 來使用\n1import lombok.AllArgsConstructor; 2import lombok.Getter; 3 4@AllArgsConstructor 5@Getter 6class Person { 7 private String firstName; 8 private String lastName; 9} 1import lombok.AllArgsConstructor; 2import lombok.Getter; 3import lombok.ToString; 4 5@AllArgsConstructor 6@Getter 7@ToString 8public class FullNamePerson { 9 private String fullName; 10} 1import java.util.Optional; 2 3public class Example11 { 4 public static void main(String[] args) { 5 Optional\u0026lt;Person\u0026gt; person = Optional.ofNullable(new Person(\u0026#34;allen\u0026#34;, \u0026#34;hsieh\u0026#34;)); 6 Optional\u0026lt;FullNamePerson\u0026gt; fullNamePerson = person.map(Example11::convert); 7 fullNamePerson.ifPresent(System.out::println); 8 } 9 10 private static FullNamePerson convert(Person person) { 11 return new FullNamePerson(person.getFirstName() + \u0026#34; \u0026#34; + person.getLastName()); 12 } 13} 14 15/* output 16FullNamePerson(fullName=allen hsieh) 17*/ flatMap: 這邊我比較常用在取得 Optional 物件中的 Optional\n1import lombok.AllArgsConstructor; 2import java.util.Optional; 3 4@AllArgsConstructor 5class Person { 6 private String firstName; 7 private String lastName; 8 9 public Optional\u0026lt;String\u0026gt; getFirstName() { 10 return Optional.ofNullable(firstName); 11 } 12 13 public String getLastName() { 14 return lastName; 15 } 16} 1import java.util.Optional; 2 3public class Example12 { 4 public static void main(String[] args) { 5 Optional\u0026lt;Person\u0026gt; person = Optional.ofNullable(new Person(\u0026#34;allen\u0026#34;, \u0026#34;hsieh\u0026#34;)); 6 System.out.println(person.flatMap(Person::getFirstName)); 7 System.out.println(person.map(Person::getLastName)); 8 } 9} 10 11/* output 12Optional[allen] 13Optional[hsieh] 14*/ Class Field 是否使用 Optional 一開始我正在嘗試使用 Optional 時，由於Lombok 的 Getter 不可以設定將正常的 Object 返回 Optional，那時我曾經有在考慮是否要將 Class Field 直接需告成 Optional。最後在研究了一番以後，我發現 class field 不應該須告成 Optional ，以下兩個原因\nOptional is not Serializable，這邊有 Stack Overflow 的討論，大家可以參考 你不能避免別人將 Instance variable set 成 null ，還是有可能造成 Null Pointer Exception 1import lombok.Data; 2import java.util.Optional; 3 4@Data 5class Person { 6 private Optional\u0026lt;String\u0026gt; name; 7 8 Person() { 9 } 10} 1import java.util.Optional; 2 3public class Example13 { 4 public static void main(String[] args) { 5 Person person = new Person(); 6 person.setName(null); 7 8 Optional\u0026lt;String\u0026gt; optionalName = person.getName(); 9 optionalName.ifPresent(System.out::println); 10 } 11} 這邊由於 getName return 的 Optional 是由外面帶入的，並不能控制返回的物件一定是 Optional，所以在 Line 8 的 optionalName 會是 null。當 Line 9 的 ifPresent() 執行時，會造成 Null Pointer Exception。 Optional 的使用是為了減少 null 的情況，所以好的設計是在拿到 Optional 物件時，不需要在檢查是否是 null。這也同時表示函示的參數，不應該有 Optional 帶入，因為有可能會是 Null 的情況\n總結 這邊小小的總結一下我目前使用 Optional 的規則\n避免使用 of() \u0026amp; get() 以免造成 null pointer exception 函式返回的物件，有可能是 null 的情況，選擇使用 Optional 物件返回 Class Field 不使用 Optional 函式參數不已 Optional 物件帶入 ","date":"June 27, 2021","img":"https://allenhsieh1992.com/images/java.webp","lang":"zh-tw","langName":"繁體中文","largeImg":"","permalink":"/posts/java/java-optional-basic/","smallImg":"","tags":[{"title":"JavaCore","url":"/tags/javacore/"}],"timestamp":1624752000,"title":"Java Optional 基本 \u0026 心得分享"}]
